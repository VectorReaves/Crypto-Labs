{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6dd40be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from seaborn import regression\n",
    "sns.set()\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa701747",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_df = pd.read_csv(\"./Resources/coin_Bitcoin.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa078dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>Name</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Marketcap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2712</th>\n",
       "      <td>2713</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2020-10-01 23:59:59</td>\n",
       "      <td>10933.624309</td>\n",
       "      <td>10472.356518</td>\n",
       "      <td>10795.254743</td>\n",
       "      <td>10619.451908</td>\n",
       "      <td>4.002313e+10</td>\n",
       "      <td>1.965121e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2713</th>\n",
       "      <td>2714</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2020-10-02 23:59:59</td>\n",
       "      <td>10657.837986</td>\n",
       "      <td>10416.689205</td>\n",
       "      <td>10619.821216</td>\n",
       "      <td>10575.975042</td>\n",
       "      <td>4.866145e+10</td>\n",
       "      <td>1.957161e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2714</th>\n",
       "      <td>2715</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2020-10-03 23:59:59</td>\n",
       "      <td>10598.940803</td>\n",
       "      <td>10511.129780</td>\n",
       "      <td>10575.100636</td>\n",
       "      <td>10549.328900</td>\n",
       "      <td>4.466027e+10</td>\n",
       "      <td>1.952332e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>2716</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2020-10-04 23:59:59</td>\n",
       "      <td>10686.000098</td>\n",
       "      <td>10534.391837</td>\n",
       "      <td>10550.440671</td>\n",
       "      <td>10669.582543</td>\n",
       "      <td>7.125178e+10</td>\n",
       "      <td>1.974689e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2716</th>\n",
       "      <td>2717</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>2020-10-05 23:59:59</td>\n",
       "      <td>10793.507851</td>\n",
       "      <td>10634.600163</td>\n",
       "      <td>10676.528956</td>\n",
       "      <td>10793.339428</td>\n",
       "      <td>4.753758e+10</td>\n",
       "      <td>1.997696e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       SNo     Name Symbol                 Date          High           Low  \\\n",
       "2712  2713  Bitcoin    BTC  2020-10-01 23:59:59  10933.624309  10472.356518   \n",
       "2713  2714  Bitcoin    BTC  2020-10-02 23:59:59  10657.837986  10416.689205   \n",
       "2714  2715  Bitcoin    BTC  2020-10-03 23:59:59  10598.940803  10511.129780   \n",
       "2715  2716  Bitcoin    BTC  2020-10-04 23:59:59  10686.000098  10534.391837   \n",
       "2716  2717  Bitcoin    BTC  2020-10-05 23:59:59  10793.507851  10634.600163   \n",
       "\n",
       "              Open         Close        Volume     Marketcap  \n",
       "2712  10795.254743  10619.451908  4.002313e+10  1.965121e+11  \n",
       "2713  10619.821216  10575.975042  4.866145e+10  1.957161e+11  \n",
       "2714  10575.100636  10549.328900  4.466027e+10  1.952332e+11  \n",
       "2715  10550.440671  10669.582543  7.125178e+10  1.974689e+11  \n",
       "2716  10676.528956  10793.339428  4.753758e+10  1.997696e+11  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin2020_df = bitcoin_df[(bitcoin_df[\"Date\"] >= '2020-10-01')]\n",
    "bitcoin2020_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "16898c15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SNo</th>\n",
       "      <th>Name</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Marketcap</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-01 23:59:59</th>\n",
       "      <td>2713</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>10933.624309</td>\n",
       "      <td>10472.356518</td>\n",
       "      <td>10795.254743</td>\n",
       "      <td>10619.451908</td>\n",
       "      <td>4.002313e+10</td>\n",
       "      <td>1.965121e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-02 23:59:59</th>\n",
       "      <td>2714</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>10657.837986</td>\n",
       "      <td>10416.689205</td>\n",
       "      <td>10619.821216</td>\n",
       "      <td>10575.975042</td>\n",
       "      <td>4.866145e+10</td>\n",
       "      <td>1.957161e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-03 23:59:59</th>\n",
       "      <td>2715</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>10598.940803</td>\n",
       "      <td>10511.129780</td>\n",
       "      <td>10575.100636</td>\n",
       "      <td>10549.328900</td>\n",
       "      <td>4.466027e+10</td>\n",
       "      <td>1.952332e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-04 23:59:59</th>\n",
       "      <td>2716</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>10686.000098</td>\n",
       "      <td>10534.391837</td>\n",
       "      <td>10550.440671</td>\n",
       "      <td>10669.582543</td>\n",
       "      <td>7.125178e+10</td>\n",
       "      <td>1.974689e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-05 23:59:59</th>\n",
       "      <td>2717</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>10793.507851</td>\n",
       "      <td>10634.600163</td>\n",
       "      <td>10676.528956</td>\n",
       "      <td>10793.339428</td>\n",
       "      <td>4.753758e+10</td>\n",
       "      <td>1.997696e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-02 23:59:59</th>\n",
       "      <td>2987</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>33939.588699</td>\n",
       "      <td>32770.680780</td>\n",
       "      <td>33549.600177</td>\n",
       "      <td>33897.048590</td>\n",
       "      <td>3.872897e+10</td>\n",
       "      <td>6.354508e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-03 23:59:59</th>\n",
       "      <td>2988</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>34909.259899</td>\n",
       "      <td>33402.696536</td>\n",
       "      <td>33854.421362</td>\n",
       "      <td>34668.548402</td>\n",
       "      <td>2.438396e+10</td>\n",
       "      <td>6.499397e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-04 23:59:59</th>\n",
       "      <td>2989</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>35937.567147</td>\n",
       "      <td>34396.477458</td>\n",
       "      <td>34665.564866</td>\n",
       "      <td>35287.779766</td>\n",
       "      <td>2.492431e+10</td>\n",
       "      <td>6.615748e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-05 23:59:59</th>\n",
       "      <td>2990</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>35284.344430</td>\n",
       "      <td>33213.661034</td>\n",
       "      <td>35284.344430</td>\n",
       "      <td>33746.002456</td>\n",
       "      <td>2.672155e+10</td>\n",
       "      <td>6.326962e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-07-06 23:59:59</th>\n",
       "      <td>2991</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>BTC</td>\n",
       "      <td>35038.536363</td>\n",
       "      <td>33599.916169</td>\n",
       "      <td>33723.509655</td>\n",
       "      <td>34235.193451</td>\n",
       "      <td>2.650126e+10</td>\n",
       "      <td>6.418992e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      SNo     Name Symbol          High           Low  \\\n",
       "Date                                                                    \n",
       "2020-10-01 23:59:59  2713  Bitcoin    BTC  10933.624309  10472.356518   \n",
       "2020-10-02 23:59:59  2714  Bitcoin    BTC  10657.837986  10416.689205   \n",
       "2020-10-03 23:59:59  2715  Bitcoin    BTC  10598.940803  10511.129780   \n",
       "2020-10-04 23:59:59  2716  Bitcoin    BTC  10686.000098  10534.391837   \n",
       "2020-10-05 23:59:59  2717  Bitcoin    BTC  10793.507851  10634.600163   \n",
       "...                   ...      ...    ...           ...           ...   \n",
       "2021-07-02 23:59:59  2987  Bitcoin    BTC  33939.588699  32770.680780   \n",
       "2021-07-03 23:59:59  2988  Bitcoin    BTC  34909.259899  33402.696536   \n",
       "2021-07-04 23:59:59  2989  Bitcoin    BTC  35937.567147  34396.477458   \n",
       "2021-07-05 23:59:59  2990  Bitcoin    BTC  35284.344430  33213.661034   \n",
       "2021-07-06 23:59:59  2991  Bitcoin    BTC  35038.536363  33599.916169   \n",
       "\n",
       "                             Open         Close        Volume     Marketcap  \n",
       "Date                                                                         \n",
       "2020-10-01 23:59:59  10795.254743  10619.451908  4.002313e+10  1.965121e+11  \n",
       "2020-10-02 23:59:59  10619.821216  10575.975042  4.866145e+10  1.957161e+11  \n",
       "2020-10-03 23:59:59  10575.100636  10549.328900  4.466027e+10  1.952332e+11  \n",
       "2020-10-04 23:59:59  10550.440671  10669.582543  7.125178e+10  1.974689e+11  \n",
       "2020-10-05 23:59:59  10676.528956  10793.339428  4.753758e+10  1.997696e+11  \n",
       "...                           ...           ...           ...           ...  \n",
       "2021-07-02 23:59:59  33549.600177  33897.048590  3.872897e+10  6.354508e+11  \n",
       "2021-07-03 23:59:59  33854.421362  34668.548402  2.438396e+10  6.499397e+11  \n",
       "2021-07-04 23:59:59  34665.564866  35287.779766  2.492431e+10  6.615748e+11  \n",
       "2021-07-05 23:59:59  35284.344430  33746.002456  2.672155e+10  6.326962e+11  \n",
       "2021-07-06 23:59:59  33723.509655  34235.193451  2.650126e+10  6.418992e+11  \n",
       "\n",
       "[279 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin2020_df.drop(columns = ['SNo'])\n",
    "bitcoin2020_df.set_index('Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6721b5bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnEAAAERCAYAAAAUkfH/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABoWElEQVR4nO3dd3hUVfrA8e+01EnvCUkIvRMgoLSgovSIorgIinVV1kV0V1xUFsXVxUVUREVddd2fqKuICCwbghVQOkFKIJSQRnrvbcr9/TFkJCaBJGRSyPt5Hh+YM3funHu8zLxzyntUiqIoCCGEEEKITkXd3hUQQgghhBDNJ0GcEEIIIUQnJEGcEEIIIUQnJEGcEEIIIUQnJEGcEEIIIUQnJEGcEEIIIUQnJEGcEKJdpaWl0b9/f2bOnMnMmTOJiopi9uzZxMbGAnD8+HEee+wxAI4dO8ayZcta/F5vvPEGmzZtatZrbrjhBiZPnszMmTO55ZZbmD59On//+98xm831js3OzmbOnDktrt9v9e3bl4KCAuvfV69eXef5mJgY7r77bgD279/PkCFDrO04c+ZMbrzxRh555BEKCwtbrU5CiI5D294VEEIIBwcHNm/ebH0cHR3N008/zTfffMPgwYNZs2YNAAkJCWRnZ7f4fRYtWtSi161atYrBgwcDUFNTw913381nn33GXXfdVec4Pz8/Pv/88xbX73I++ugjxo4dy8iRIxt8PiQkpE47mkwmFi5cyL/+9S/+/Oc/26xeQoj2IT1xQogOp6ioCB8fH8DSwzRjxgwyMzNZs2YNhw4d4umnnwZgw4YNTJ8+naioKObPn09mZiYAX3zxBTNmzODmm2/m/vvvJykpCYAlS5bw4YcfAjB48GDefPNN5syZww033MBnn33WpLrZ2dkxYsQIEhMTSUtLY8KECdx///1MnjyZX375hWHDhgFgNBpZsWIFkydPZtq0aTz77LPU1NQA8M4773Drrbcyc+ZM/vCHPzQ5MH3iiSdYvHgxxcXFTTq+rKyMgoIC3NzcmnS8EKJzkZ44IUS7q6qqYubMmQCUlJSQm5vL22+/XeeYgIAAHnvsMbZv386KFSs4deoUq1at4uuvvyYgIIB///vfvPPOO0ydOpUPPviAL774Ak9PTzZu3Mijjz7K//73vzrnq6mpwcPDg88//5y4uDjuvPNObrvtNuzt7S9Z1+zsbH788Ucef/xxALKysnj11VeJiIggLS3Netxnn33GiRMn2Lx5M3Z2dvzpT38iOjoagDNnzvDll1+i1Wr54osvWLp0Ke+///5l2+nmm28mLi6Ov/71r9beyYulpqYyc+ZMjEYjBQUF+Pv7M3XqVO65557LnlsI0flIECeEaHe/HU7ds2cPjz76KFu2bGn0NXv37mXcuHEEBAQAcO+99wKwcuVKpk2bhqenJwCzZs3ipZdeqhNg1Zo4cSIAAwcOpKamhoqKigaDuCeffBIHBwfMZjM6nY7Zs2czefJk0tLS0Gq1hIeH13vNnj17mDlzJg4ODgDW+WyLFi3i+PHj3HbbbQCYzWYqKysv00K/ev7555k5cyZffvklLi4udZ67eDj1q6++4vXXX2fq1KnodLomn18I0XlIECeE6HDGjBlDSEgIx48fx8vLq8FjNBoNKpXK+riqqor09PQGFxwoioLRaKxXXhuw1Z6nsa2kL54T91t2dnZotfU/Sn9blpeXh9lsxmw28+CDDzJ37lzA0iPY1OFRAL1ez6uvvsqDDz7IAw880Ohxt912G0ePHmXRokWsX7++wToKITo3mRMnhOhwkpKSSE9Pp3///nXKNRqNNRi75ppr2Lt3Lzk5OQB8/vnnvPLKK4wfP57o6Gjrqs6vvvoKd3d3QkND2/QaRo8ezdatW6mpqcFsNvP888/zv//9j3HjxrFhwwbKysoAy4rZp556qlnnDg8P57777mPt2rWXPO7JJ58kMzOTTz/9tMXXIYTouOSnmRCi3V08Jw4sQ4wvvPACYWFh1iANLMHL22+/zR//+EfeeustFi9ezIMPPgiAj48Pf//73/Hz8+Pee+/lnnvuwWw24+npyXvvvYda3ba/WefMmUN6ejqzZs1CURRGjRrF3XffjVqtJjs7mzvuuAOVSkVAQAAvv/xys8+/YMEC9u7de8ljXF1defLJJ1mxYgXTp0/H29u7pZcjhOiAVEpj4wdCCCGEEKLDkuFUIYQQQohOSII4IYQQQohOSII4IYQQQohOSII4IYQQQohOSII4IYQQQohO6KpOMRIbG9veVRBCCCGEaLIRI0Y0+dirOoiDuo0RGxvbrMYRLSdt3XakrduWtHfbkbZuO9LWbedSbd3czicZThVCCCGE6IQkiBNCCCGE6IQkiBNCCCGE6IQkiBNCCCGE6IQkiBNCCCGE6IQkiBNCCCGE6IQkiBNCCCGE6IQkiBNCCNFpVdUYeeClb3lz/REMRhOFpVWcTilo72oJ0Sau+mS/Qgghrl6ZeeXkFFTwzf4UjiXkkldUicms8N6SGwnwdm7v6glhU9ITJ4QQotPKzCsH4Hc39cHJQcd1w4NRFDh8KrudayaE7UlPnBBCiE4rK78CgFsm9OKuKf0BOJGYT+zpHKaP69GeVRPC5qQnTgghRKeVlV+Oi5MOvaPOWja8ny/HEvIwGE3tWDMhbE+COCGEEJ1WZn45/l51574N7+dLdY2Jk4mywEFc3SSIE0II0WllNRDEDe7pjVajJvZ0TjvVSoi2IUGcEEKITslkMpNTWIm/l1Odckd7LQN7eHLgRBZms9JOtRPC9iSIE0KIq9ip5AJ2xJ5v72rYRG5RJWazQoBX/VQiN0QEk55bxs9H09uhZkK0DQnihBDiKvbVj2d588ujGIzm9q5Kq6tNL/Lb4VSACcOD6R7gyv9Fx8sCB3HVsmkQ98MPPzBr1iymTp3Kiy++CMCePXuIiopi0qRJvP7669Zj4+PjmTVrFpMnT+bZZ5/FaDQCkJGRwbx585gyZQoLFiygvNzyj7akpISHHnqIqVOnMm/ePHJzc215KUII0SnlFFRSYzBxJrWwvavS6rIKLOlFGgriNGoV90UNJKeggv/tTm7jmgnRNmwWxJ0/f57nnnuOtWvXsmXLFk6ePMnOnTt55plnWLt2LdHR0cTFxbFz504AFi9ezLJly9i+fTuKorB+/XoAli9fzty5c4mJiWHQoEGsXbsWgNWrVxMREcG2bduYPXs2L730kq0uRQghOq3sQkugE3cur51r0vqy8srRadV4uTk0+Pzwvr70DnZnz7GMNq6ZEG3DZkHct99+y7Rp0/D390en0/H666/j6OhIaGgowcHBaLVaoqKiiImJIT09naqqKsLDwwGYNWsWMTExGAwGDh48yOTJk+uUA+zYsYOoqCgAZsyYwa5duzAYDLa6HCGE6HTKKg2UV1o+F48lXB1BnNmssP67M3y4JY6kjGL8PJ1Qq1WNHt/NV09ecWUb1lCItmOzHRtSUlLQ6XQ88sgjZGZmct1119G7d298fHysx/j6+pKdnU1OTk6dch8fH7KzsyksLESv16PVauuUA3Veo9Vq0ev1FBQU4OfnZ6tLEkKITiX3Qi+cj4cjp5ILMBhN6LSadq5Vy1VVG3ntP4fZezzTWhbR/9Kf+d7ujhQUV2E2K5cM9oTojGwWxJlMJg4dOsS6detwcnJiwYIFODg4oFL9+o9IURRUKhVms7nB8to/L/bbxxe/Rq2u37EYGxt7ycfCdqSt2460ddvqLO19Ks3SA9U/SMuuuEq2fLuf7r727Vyr5rm4rbcfLmLvqTImD3cjxMeeb34pIsCl+pL/P8qLyzCZFXbtOYiLY+cNYNtCZ7mvrwat1dY2C+K8vb0ZPXo0np6eANx4443ExMSg0fz6jyg3NxdfX1/8/f3rLEzIy8vD19cXT09PSktLMZlMaDQa6/Fg6cXLy8vD398fo9FIeXk57u7u9eoxYsQI699jY2PrPBa2I23ddqSt21Znau/08nNAPvNmjOKnE99To/ZkxIh+7Vqn1KwStu1J5rYbeuPt7njJYy9ua0VReHvbt4wa4M8f510DwM2TLv9+RvtMog8dICi0N72DPa64/lerznRfd3aXauvmBnc2mxN3/fXX8/PPP1NSUoLJZOKnn35iypQpJCUlkZKSgslkYuvWrURGRhIUFIS9vb218ps3byYyMhKdTkdERATR0dEAbNq0icjISAAmTJjApk2bAIiOjiYiIgKdTtdgXYQQoivKLqjAwU5DgLcz3QNcOdWOK1STMop5d+MxHnt1B1t3JxGzL7nO86dTCjiRmN/o68+lF5NbWMnowf7Nel+vC4FiXlFVs+ssREdns564oUOH8uCDDzJ37lwMBgNjx47lzjvvpEePHixcuJDq6momTJjAlClTAFi1ahVLly6lrKyMgQMHMn/+fACee+45lixZwjvvvENAQACvvfYaAIsWLWLJkiVMnz4dFxcXVq1aZatLEUKITim7oAJfTydUKhXdfF1IOF9U5/ms/HLWbYtnwW1D62wg31o2/HCWDT+cxWxWqKw2otWouHFUCGdTizhyOpe7pvSnvNLA+5uP8/3B89jpNLy3ZGKDPXT7jmeiVsHIAc0L4rzdLOfK72CLG0rKazh8KpvIYd1krp5oMZsFcQC33347t99+e52y0aNHs2XLlnrH9uvXjw0bNtQrDwoKYt26dfXK3d3deffdd1uvskIIcZXJKazA18OyJVWgtzO7j2VgNJnRaiyDMLt+SWfXL+l089Fz5+TWHWatqjGy4Yez+Hk6MaiHF0G+esYNDcLV2Y5PY06x/rvTlFbUsC46nh9j05gxLozt+1L4OPokf5pbf6hpb1wmA3p44aZv3pw+V2c7tBo1eUUdK4j7bPsp/rc7ibScMu6a2r+9qyM6KZsGcUIIIdpPTkEFA8K8AAj0ccZsVsguqCDIRw/AiSTL8OWWnxKZOaEn//0pkUPx2Tg76pgxrsdlV35eyq5f0imvNPDgzEEM7uld57nhfX35/NvT7DmWwQ+x55kYEczDtw7BXqfhqx8TiBrfg97BHlQbzLz6aSw6rZrUrFJ+P3NQs+uhVqvwcnMgv7jjDKeazAq7j2Vgb6fhi+/OEODtzMSRIe1dLdEJybZbQghxFSqrNFBeZbyoJ84SuGXklgGWQOJUcgF9QtwpqzTwl7d+5pOYUxjNCimZJbzyyaEWD0EqisL/dicR6u/CoB5e9Z7vE+KOs4OWj7aepLrGxPSxYQDccWMfXJ3t+OqHBACSsqvZcTiNnb+kY6fTMHpwYIvq4+3u2KFyxZ1IzKOotJqFs8MZEObJR1tPoChKe1dLdEISxAkhxFUkv7iSV9Yd4lC8Jaemn6cliAvwtmxNlXFhv9GUzBIqqoxEjevBsD4+JGeWMGNcGK8tiuSlP4zFYDTz4ZYTLarD6ZRCEtOLmT42rMG0UBqNmiG9fSivNNC/uyc9u7kD4OSgY3hfX04m5aMoCml5NWjUKj7721Q+f3EaPh6XXs3aGC83B/JttLDhy+/P8Nw/9/LYqz+SllPapNf8dCQDBzsN1wzy57rh3SguqyGnsOMEmaLzkCBOCCFaSVW1kZc/Psj57KZ9mdvCzsNp7DqSzuufWVb7+3paAh9XZzucHbTWnriTF4ZSB4R5sfCOYTxx53AeumUwKpWKQG89d9zYh5+OpHP0TPP3pf75aAY6rZrrRgQ3esywvpZ0UTPGhdUp7x/mSWFpNdkFFaTn1xAW6Iq9ToNO2/KvK283S09ca/d2FZZW8XF0PJl55aTllLFlV2KDxyVlFFNcVg2AyWRmz7EMRg3wx8FOS69gdwDOnr/69rYVtidBnBBCtJJ9cZnsPprBgRNZ7VaHX87k4uvhiKerZT/R2uFUlUpFgI/e2hN3IjEfb3dHfD2d8PFw5IaI4Dq9Zrdd3ws7nYaDF3r0mleHHAaGeeFo3/i064kRwTxx53DGDg2qU96/u6e1fun5NfQJufLcbl7uDhiMZkrKa674XBfLvdB79uDMQYwPD2LH4fNUVBlIySxh91HLfq2KovDsO3t4/T+HATgUn01JeQ3jwi1Dw90D3NBq1JxNLWrVuomuQRY2CCFEK/npiOWLO/1Cb1dbqzaYOJGYz7QxYcyM7El8cn6d1ZyB3s6cTilEURROJhUwqGf9+Wq1dFoN3Xz1nG/iEGGt/OJKUrNKmRjReC8cgJ1Oww0NHBPi74qjvZZvD6RSY1ToG3rlQdyvaUaqmr269VJyL6x49XZ3ZNqY7vxw6DxffHuG7w6mUlVjYsyQAMqrjJRW1BB7KoeEtCL+8+1p/L2crKlSdFo1YYGuJKQVtVq9RNchPXFCCNEKyioNHD5t6bWq7e1qaycT8zEYzYT38cHHw5HIYd3qPB/orSe3sIKz54soKKliYAOLDi4W4ufS7KHhIxeGX8P7+Dav8hdo1Cr6hnpYE/+2Rk9cbd651l7cUJu2xMfDkT4hHvQIcmPjjgRKymuoMZgoKq227l8L8I+PD3IurZg5N/W1pnkB6BXsTkJaESazwn+2n5KhVdFkEsQJIUQr2Hc8E6NJIdTfxTrvrK39ciYXrUbd4IpQuJBmRIE3vvgFZwct434zlPlbwX4u5BZWUlFlaHIdjpzJxV1vT/cA12bV/WK1Q6oOOpV1Ve2V8HKzDC3nXwi6UrNKWP7BviseXs0trMTBToPeUYdKpeK263vhaK/ltut7AZZky7VDrkN7e5OVX0GQjzPXDa8bXPcJdqeiysj6787w2Ten2Xk4/YrqJboOCeKEEOIKGYxmfow9j5+nE5HDulFYWt2swKe1/HI6hwFhnjg0Mhct8MIK1dSsUm6faEnncSnBfpYAKi2naUGp2axw5EwuQ3v7XNEuBLVBXJCXXavsZuDu4oBarSIhrRiTyczr/znMofhsjifkXdF5c4sq8PFwtM4ljBzWjc/+NtU6TJxdUEHOhZ64B24eRIC3M/fOGIhGU/ert3ZP1/98cwqA8sq2v3dE5yRz4oQQ4grsPpbBexuPUVhazV1T+xHkeyEfW145vS6kzmgLuYWVJGeWMH9a49n/Ay8k+fV2cyBqfI/LnjPYzwWAtJzSSw5rFpZW8Ze3fqa80kBJeQ3D+vo0s/Z19Q31wE6nIdS3deavadQqJkYE883+FNJzy0hIKwbgXHoRY4e2LPccWNrcx92pTplWo7YuJskprKCswoBOqybU35V/Pn1jg+fp5ueCvZ2G6hoTjvYayipbdwGGuHpJECeEEFfgP9tP4WivZdGcYQzr40tKVglgSarblkHc9v3JqFTUmwd3MRcnO24aFcLowQHY6zSXPWeAlzNajYrUrEvPi1sXHU9uYQUTR4agVqkYPTig2fW/mJODjrcXX0/yufgrOs/FHr19KNUGE7t+SefaQf5k5VeQlFFyRefMLaokLNCtXrmDvRZ3vT3ZBRWUVxrwcXe8ZI+iRq1i7JBAdFo1aTlllFcar6heouuQIE4IIa5AblElE0eGMKKfZYuq3ybVbQsGo5lv9qUQ0d/Pmty3MY/9bliTz6vRqAny0XM+u/Hh1DOphXx7IJVbr+vF/VEDm3zuy/H3ciY9ufU2htdo1PzpzuGM6OfHqAF+vL85jiNnclp8PoPRsnChsQTEvp6OZBdUUFltbFKS4ifuHA7Ai//abx2CFeJyZE6cEEK0UHmlgYoqIz7uv35JO9hp8XZzaNM0I/viMiksrWbamLDLH9xMwZdZofqv/57A3cWeOTf1afX3bm0ajZobIoLRO9kRFuhGQUk1haVN28mhoKSKn4+mU20wAZB3YQeIi//fX8zXw+nCwoYK6/BqUzg76mROnGgy6YkTQogWujhP2MUCffRk5rZdT9y2Pcn4eTpZd0FoTcF+Luw5lkF+cSV5RZX0DfW0Pmc0mYlPLmDWdb1wctC1+nvbUs8gyzBoUnoJHv0cLnv8218e5cDJLFycdMyfNoBAH0uPa2O9bH6eTuyLy8RkVhoN9Bqid9RRJkGcaCLpiRNCiBa6OE/YxYJ89G3WE1dVY+REYh6Rw4LQtMJKzt8K9nPBrMADL37Lk2t+qrM/aE5BBWazQpDPlacBaWthF4K4c+lFlz02KaOYAyezmDgymCAfPe9vjiM50zKf7rcLG2r5eTphNCkoCvg0oydO76ijosqIydy6W4SJq5MEcUII0UK1iVx/29MS6ONM2YWVmraWklmCWYHeF/bgbG0DwjwJ8tFbV3FenJajdt5fba9UZ6J31OHr6URievFlj13/3Rkc7bU8ePMgfn/LYGoMJjZf2CfV273hXjw/z1/bpClz4mo5O1p6NNsjRY3ofCSIE0KIFsotqkSjVuHuUveLPMDL8gWelW/7IdXECyssewS52+T8Xm6OvLtkIk/OG4GXmwPHz+Vbn8vIs/Q21i7m6Gx6BrmRlHHpIC49t4zdxzKYMS4MvZMdvYPdCfV3IaegAncXe3Tahlf5+nr+Grg1Z06c3skSxJVVSBAnLk+COCGEaKHcwkq83B3rDWN6XNh8vrCkaZPmr0RiejHOjjp8m9Hb0xIqlYrBPb05fi4PRbEM9WXmleN4IZ1GZ9QjyI2MvPJL9nrFnctHUeDGUSGApR1uHBUKNL6oAeoGbo311jXE+cLcQlncIJpCgjghhGih3KLKBr/I3V0sQU1RWbXN65CUXkyPQDfrrgG2NKinF0Wl1db5fhl55QR4O7fJe9tC3xAPFAVOpTS+V2nt6tWL/z9fP6IbWo3qksOkdjoNnq72eLo23lvXEL2TZRcNSfgrmkKCOCGEaKHcosoGv8hre6aKSm0bxJnMCkmZJYQFtXyf0uYY3NMbwDqkmplXbt3KqzPqG+qBWgWnkgsaPaagpAoXJ12dQMxNb8+f7hzBbdf3vuT5A7z1+Hs1r31q58RJwl/RFJJiRAghWsBkVshvpCfOTqfB2UFr8yAuI7eMGoPJmi7D1gK8nfF0tScuIY+bRoWQXVDBuCvYtqq9OTnoCA1wJT6p8SCusKTKOjx+sfHDgi57/oV3hFuHnptKfyGIk5440RTSEyeEEC1QVFp1yRxg7i4OFNo4iDt3YWWlrRY1/JZKpWJQT2+OJeSRmVeO2awQ6N350otcrH93T06nFjSa0qOwpBpPl6bPabtYkI+ebr4uzXpNbU+cLGwQTSFBnBBCtEBuYW2OuIZXHrq72Nt8TlxSejE6rZpuvm0XSF03vBtFZdWs/+4M0HlXptbq392TymoTKZkN76NaUFqFh2vbLdxwsNOgUasolxQjogkkiBNCiGbIKzHwweY4Ui9sRdV4T5w9RU3c0qml4pMLCPV3Qatpu4/yEf38CPZzYcfhNKBz5oi7WL/ulh0o4huYF6coiqUnroHhVFtRqVQ4O+qkJ040iQRxQgjRDMeSK9i86xzvbjwG1N9yq5aHi71N58SdSS0kPrmA8eGXn5vVmtRqFbdO6AmAo72m06YXqeXn6YSnq32DixvKKg0YTeYG58TZkl72TxVNJEGcEEI0Q26xEWcHLYoCTg5a6xym33J3sae8ykjNhQ3TW9tXP57F2VHHlNHdbXL+S7luRDc8Xe0J9NF32vQitVQqFQPCvDgUn01+cWWd5wou5Plr6Zy4ltI7yf6pomlkdaoQQjRDbrGBwb28mRnZk5wL2241xF1v+eIvKq3G17PpGfub4nx2KXuPZ3LHxD7tsvG8Tqvh2fuuafbKy45q7uR+HIzP5rXPDvPCw2OsyZtrkzW35Zw4sCT8lZ440RTSEyeEEE1kMJrJLzUS4u/KoJ7e3BAR0uixHjZM+BuzLxmtRs2McT1a/dxN1SfEg76hnu32/q0p2M+Fh28ZzLGEPL7ekWAtLyix/L9ryzlxYEn4KylGRFPYtCfu7rvvpqCgAK3W8jYvvPAC5eXlrFixgurqaqZOncoTTzwBQHx8PM8++yzl5eVERESwfPlytFotGRkZLF68mPz8fMLCwli1ahXOzs6UlJTw5JNPcv78eTw9PVm9ejU+Pj62vBwhRBeXkVeGoli+9C/HumuDDebFnUwqoF+op/U9xJW7cVQI++Ky2PDDWaaN6Y6Tg+6inri2DeKcHWU4VTSNzXriFEUhOTmZzZs3W//r27cvzzzzDGvXriU6Opq4uDh27twJwOLFi1m2bBnbt29HURTWr18PwPLly5k7dy4xMTEMGjSItWvXArB69WoiIiLYtm0bs2fP5qWXXrLVpQghBACpWZYVqaH+TQ/iWporLmZvMscT8uqV1xhMJGcU0yfEvUXnFQ1TqVT87qY+lFca2L4vBbCkF3Gw0+Bo37Yzj2oXNlwtw9XCdmwWxCUmJgJw//33c/PNN/PJJ59w7NgxQkNDCQ4ORqvVEhUVRUxMDOnp6VRVVREeHg7ArFmziImJwWAwcPDgQSZPnlynHGDHjh1ERUUBMGPGDHbt2oXBIL9chBC2cz67FJUKAn0un5ft1623mp9mxGA08c9Nx/n829P1nkvMKMZoUugT4tHs84pL6xPiwZBe3mzaeQ6D0URhSXWb98KBpSfOaFKorrHNohhx9bBZEFdSUsLo0aN5++23+fe//83nn39ORkZGnSFPX19fsrOzycnJqVPu4+NDdnY2hYWF6PV663BsbTlQ5zVarRa9Xk9BQeNbpwghxJVKzSrFw1mLve7yG5pfydZb59KLMRjNnEouwGCs+0V+JtWyWXvfUAnibOH2G3pTUFLFj7FpFJRUtfl8OPh1663ahL9VNUabb+EmOieb9REPGzaMYcOGWR/ffvvtrFmzhhEjRljLFEVBpVJhNpvrLFOvLa/982KNLWdXFAW1un5MGhsbe8nHwnakrduOtHXbOJOSg4+7tsnt7WAHieez2Ly9jPIqM327NZxTDqDGaKa8yoyHXsue+FJr2X+/3U+o769z3/b9ko+Lo4bkhJMkX9HVdA5tfW8rioK/h47PtsVhVhQCPe3avA7ZmZZVz9//dJhfEss5nV6FRgVPzgpEq7FdShf5HGk7rdXWNgviDh06hMFgYPTo0YDlH0ZQUBC5ubnWY3Jzc/H19cXf379OeV5eHr6+vnh6elJaWorJZEKj0ViPB0svXl5eHv7+/hiNRsrLy3F3d69Xj4uDxtjY2DqPhe1IW7cdaeu2YTCaKfh8K32DHJvc3v77fqbaYOLr/aUYjGbuvHlsoz9E/7P9FBt3JPCvv07im7gjuOurKC6vxqD1YsSIvtbj3vvmOwb18u0S/8/b696u1Kazct0hAMYPC2DEiMFt+v5qfQ4bdu/l633FGExm+oR4ciIxn8DQvk1aVNMS8jnSdi7V1s0N7mw2nFpaWsrKlSuprq6mrKyMr7/+mj/96U8kJSWRkpKCyWRi69atREZGEhQUhL29vbXymzdvJjIyEp1OR0REBNHR0QBs2rSJyMhIACZMmMCmTZsAiI6OJiIiAp2u7fMlCSG6hoy8MkxmBV+3pn/OuLvYk3C+iPziKkrKa6zJYxuSnltOVY2JHbFpxCcVEN7Hh1B/V+LO5VuPKSmvITOvXObD2diYIYEEeFm2E2uPOXF6J8s9VlFt5Jl7RvHAzQMBSMspa/O6iI7NZj1x119/PUePHuWWW27BbDYzd+5chg0bxssvv8zChQuprq5mwoQJTJkyBYBVq1axdOlSysrKGDhwIPPnzwfgueeeY8mSJbzzzjsEBATw2muvAbBo0SKWLFnC9OnTcXFxYdWqVba6FCGE4OBJy3zcIG+7Jr+mNlecv5cTWfkVJGWU4OXW8JBq3oXdAr768SyFpdX06+6Ji7Md2/elkJZTyuZdieQVWY6Rlam2pVGrmHV9L97ecLRd5sT5eTrjrrfnrqn9Gd7Pl4oLc+PSckqBgDavj+i4bLpu+vHHH+fxxx+vUzZ69Gi2bNlS79h+/fqxYcOGeuVBQUGsW7euXrm7uzvvvvtuq9VVCCF+a/Xnh+kd7MG0Md35Zn8KA3t44eXS9I/NAC9ntBo1T90dwZ9W7yIxvZiI/n4NHptfXImdTkN+saW3rn93Tzxc7PnvT4ksXLUDjUaFi6OO7gGu9AmWnjhbmzgyhMpqI6MG+rf5e7s62/Hx85OtQ+9ODjq83BykJ07UI9tuCSFEA3IKKvj+4Hl2Hk5Ho1aRmVfOnJv6ALmXfW2tqWPCGD04EB8PR/y9nEjMKG7wOEVRyCuqYuLIYH6MTUOjtuSi83JzwN5OQ4ifC0/dHYH/hSE+YXs6rZpbr+vVbu//27mT3Xz1pEsQJ35DgjghhGjAgZNZAGg1Kt7ecBQnBy1jhgRy4njTgzidVo2Ph2X4NCzQjaT0hoO4kvIajCYzIf4u3HZ9L8qrDGg0atz09rz/9I24ONuh1cguiV1ZN18Xfow932DWBtF1yaeCEKLLS80q4bn395J0UU/Z/hNZBPno+f0tlpWJE4Z3w8Gu5b97ewS5kZlfbp3fdLHauW7ebo7MndyP38/8dTWkh6uDBHCCbr56KqqMLd4BRFydpCdOCNHl7Y3L5PCpHE4k5vPEncMJ7+1D3Lk8bh7fk5tGhWA2K1c8N6pHoBuKAimZpfQPq7txfP6FVave7o3nkRNdW7CvJbVIWk5puyy2EB2TBHFCiC7vfFYZHi72+Ho68fL/HWR4X1+MJkvgplKpmDK6+xW/R1igG2DZNqteEHehJ87LTb6cRcO6+Vm2ekvLKWNIL5/LHC26CumjF0J0eeezS+kR5MbfF4zlhohgDp/OwcXJjn7dPS//4ibydnfAxUln3TbrYnnFVajVKtxdJIgTDfN0dcDRXiMrVEUd0hMnhOjSTGaFtJxShvT2xk6n4fE5wxjUwwsHey0adetNIFepVIwZEsi3B1K5eXwPenZztz6XV1SJp6tDq76fuLqoVCqCfF1IOF+EyazIvSIA6YkTQnRBVTVGtu9LJr+4ktzCCmqMZut2RiqVipuuCWV8eFCrv++90wfg5mzHmvVHMJnM1vL84kq8ZShVXMaIfr7EJxfw5JpdFxL/iq5OgjghRJfyy+kcFvzjB9768iiff3uG1GzLl2GIjfakvJjeyY6HZw0hMb2YP6/ZxYYfzmIwmsgrqsJLFjWIy5g3uR+L7xpBZm4ZH0fHt3d1RAcgQZwQokt57+tjaDUq+oV6sD8uk5TMEgC6tUEQBzB2SCALbhuCRq3i//53ko07EsgvrpRFDeKyVCoVkcO6Ed7Hl+QL963o2iSIE0J0KUVlNUT082P6uB4Ullbzw6HzeLo6oHds+sb2V2ramDBeXTSB4f182bTjHFU1Jrwb2VNViN8K9nMhK7+caoOpvasi2pkEcUKILsNkVqioMuDspCOivx8atYq0nLI2GUptyO3X96as0pL8V4I40VQh/i4oCqRly7y4rk6COCFEl1FRZUBRQO9oh95Rx+Be3gAE+7dPEDeopxd9QtwB8HKX4VTRNCEX7tdUCeK6PAnihBBdRlmFpdfLxckydHrtoAAAgn317VIflUrFvCn98XZ3tK6OFeJyAr31aNQqUrMkiOvqJE+cEKLLKKusAbDOfxs3NJCDJ7MY3s+v3eo0vK8vH/11Uru9v+h8dFo1gT56CeKEBHFCiK6jtidO72QHgJvenud/P7o9qyREi4T4u5CYVtze1RDtTIZThRBdRu0igrZciSqELYT6uZBVUE5VjbG9qyLakQRxQoguwxrEOUkQJzq3EH9XywpV2Uu1S5MgTgjRZZRVWObEOUtPnOjkrCtUsyTpb1cmQZwQossoqzCg06qx12nauypCXJEAb2c8XOz58vuzVFQZ2rs6op1IECeE6DLKKg3oHXWoVKr2rooQV0SrUfPkXSPIyC1jzfojKIrS3lUS7UCCOCFEl1FWWSPz4cRVY0gvH+6eNoDdRzM4fi6vvasj2oEEcUKILqOswoDe0a69qyFEqxk3NBCAnIKKdq6JaA8SxAkhuoyySoMsahBXFTe9PQDFZTXtXBPRHiSIE0J0GWWVBuuWW0JcDRzsNNhp1RSXSxDXFUkQJ4ToMsoraqy7NQhxNVCpVLjq7Skuq27vqoh2IEGcEKJLMJkVyquMsluDuOq46+0kiOuiJIgTQnQJ5bLllrhKuertZTi1i5IgTghhZTIrnM8ube9q2ERZpeVLTlKMiKuNm7MdJRd64moMJgpLqtq5RqKt2DyI+8c//sGSJUsA2LNnD1FRUUyaNInXX3/dekx8fDyzZs1i8uTJPPvssxiNlg19MzIymDdvHlOmTGHBggWUl5cDUFJSwkMPPcTUqVOZN28eubm5tr4MIbqETTsS+MPKH9i+L6W9q9Lqyipqe+JkTpy4urhd1BO3/vszPPbaDkn+20U0K4grKWneHm179+7l66+/BqCqqopnnnmGtWvXEh0dTVxcHDt37gRg8eLFLFu2jO3bt6MoCuvXrwdg+fLlzJ07l5iYGAYNGsTatWsBWL16NREREWzbto3Zs2fz0ksvNateQoiG7TicBsDaDUfYH5fZzrVpXWW1w6nSEyeuMq7OdlTXmKiqNpKcUUJRaTVFpZ1rjlxxWTUbf0zg6bU/k5BW1N7V6TSaFMQlJiYybdo0pk+fTnZ2NlOnTuXcuXOXfE1RURGvv/46jzzyCADHjh0jNDSU4OBgtFotUVFRxMTEkJ6eTlVVFeHh4QDMmjWLmJgYDAYDBw8eZPLkyXXKAXbs2EFUVBQAM2bMYNeuXRgMsnecEFciNauE5MwS5k/rT48gN9asP4LJfPX8mi+vkDlx4urkXpsrrryG7AtJfzPyytuzSs1SbTCx6LUdfLT1BHHn8tl54cekuDxtUw568cUXefbZZ3nllVfw8/PjrrvuYtmyZXz66aeNvmbZsmU88cQTZGZafs3n5OTg4+Njfd7X15fs7Ox65T4+PmRnZ1NYWIher0er1dYp/+25tFoter2egoIC/Pz86tUjNjb2ko+F7Uhbt53WaOsfjxUD4GNfxJBgDRvTaoj+fh+BnlfH8OOJs2UAJCacIjddc0Xnknu77UhbX15uViUA+w8dJSPXMqd1b+wJqgqdm3We9mrr2IRy8ouruHOCF7tPlnLgeCrhQZ2rJ7G5WqutmxTEFRUVMXbsWF555RUA5s2bZx3ybMiXX35JQEAAo0ePZuPGjQCYzeY6m04rioJKpWq0vPbPizW2abWiKKjVDXcqjhgxwvr32NjYOo+F7Uhbt53WaGtFUXj/2+8Z0sub68aNYnBxJRv3foNB68OIEb1aqabtK7HoDFDEmGtGYKdreRAn93bbkbZuGmfvAv6z6ydcvLpRY8wBwF7vw4gR/Zt8jvZqa0VR+OiHHwkLdOXOqLEYtfF89WMCAwYNxdG+SSFKp3Optm5ucNfkOXHV1dXWICo3Nxez2dzosdHR0ezevZuZM2eyZs0afvjhB7788ss6CxByc3Px9fXF39+/TnleXh6+vr54enpSWlqKyWSqczxYevHy8iyb/RqNRsrLy3F3d2/6VQsh6kjJKiU9t5xx4UEAeLk50s1Xz7GExhcNGYwm0nPL2qqKLZaRV8amnecoKKnCTqu+ogBOiI7IzdkynHompdBaltmE4dRjCbls2pnQovc8e77QmrbnShw7m0dKVik3j++JSqViYA8vzGaF0ykFV3zurqBJQdzcuXN54IEHyM/P59VXX+V3v/sdd955Z6PHf/TRR2zdupXNmzfz2GOPccMNN/DBBx+QlJRESkoKJpOJrVu3EhkZSVBQEPb29tboc/PmzURGRqLT6YiIiCA6OhqATZs2ERkZCcCECRPYtGkTYAkYIyIi0OlknosQLVX7gRne+9epDUN6eXMiMR+jqeEfbBt3JLBw1Y/WBQMd1fub4vhwSxz/250kuzWIq5Kb3nJfn061BHGervZk5l36B1ZltZFVn8Ty4ZYTHD3TvAwPRaXVPLnmJ7768WzLKnyR6L1JuOntiBxm+QHZv7snahWcTJIgrimaFMTdfvvtLFq0iKioKIxGI3/729+YO3dus97I3t6el19+mYULFzJt2jR69OjBlClTAFi1ahUrVqxgypQpVFRUMH/+fACee+451q9fz7Rp0zh06BCPP/44AIsWLeLIkSNMnz6dzz77jGXLljWrLkKIus6lF+PkoMXP08laNqS3D1U1Js6mFjX4mtj4HAxGMwnnCxt8viNIyynlUHw21wz0R++ow9fDsb2rJESrc7TXotOqScqwzGsN7+NLZl55vTQjJrPCdwdSKS6rZtPOcxSWVuPqbMcHW+IwN2MR06H4bMxmhVPJV/5vPzG9mCG9fKw95E4OOroHuHEiMf+Kz90VNHnAuX///owcOZITJ05w9uxZDAZDk3q/Zs2axaxZswAYPXo0W7ZsqXdMv3792LBhQ73yoKAg1q1bV6/c3d2dd999t6lVF0JcRmJ6MWGBbqjVv847HdzTG7AMufQP86xzfGW1kTMXfvWfPV9EeB/ftqtsM/z3p0S0GjV/nB2OVqPC0EivohCdmUqlws3ZjrziKlyc7OgR5MYPh85TUl6D24WVqwBHzuTwxhe/4OJkh8FoYuyQQMaFB/KPjw9xOFHNyJFNe7+D8VkAJKQVYjIraNQNz1e/HKPJTE5hJZHDutUpH9DDk28PpGI0mdFqZE+CS2lS67zxxhs899xzZGRk8Pvf/56NGzfy/PPP27hqQoi2YDIrJGWU0DPIrU65q7MdYYGuxDXwi/hEYj4ms4JaZQniOqKyihq+P3SeCcODcHexR+9kh4eLQ3tXSwibcL0QrPl5ORHgbVmVmplfd15cVr4l/YivpyNmBeZP68/YIYH0CHLjSGJFk97HYDTxy+kcXJ3tqKw2kZbT8h1ecgorMJsVAryc6pQP7ulNdY2JVZ/Gkl9c2eLzdwVNCuJ27tzJiy++yDfffMP06dP5+OOPOXXqlK3rJoRoA+k5pdQYTPT4TRAH0DPIneSM+km+j57NRadVM3KAP2dTO+Zw6veHzlNdY+Lm8T3buypC2Jybs2VenJ+nEwFeF4K43yxuyCmoQKdV8+qiCax7fjKBPnpUKhUDwjzJKTI0aUg17lw+ldUmbr+hN8AV/fvPyrMEjgHe+jrl1w4KYO6kvhw4kcXjr+2k2mBq8Xtc7ZrcT+no6MiePXu49tprAaipkc12hbgaJKZb5tE0FMSFBrhSVFY/+/uxs3n07+7JoJ5e5BVXdbi9GhVFIWZvMn1DPRq8LiGuNm4ulp44f08n/L2cUKksQZzBaLIm7c4urMDH3RGNWoWTw6/ToboHuFJjVMgpvHxv3IGTWdhp1Uwd3R1nBy1nGpkz2xS1PYX+v+mJU6tV3Dm5H3+eO4KismrOyQ4OjWpSEOfh4cHzzz9PXFwcY8aMYdWqVdZ0H0KIzu1cejE6rZpgP5d6z4X6W8pSMn/tjSsuqyYxo5ghvb3pHewBwNkO8CGrKArLP9jH1p8TOZGYT1pOGVOuDW3vagnRJmrTjPh5OaPTavBxd+TbA6nMWbqNT2PiAcgtrMDX06nea7sHuAKQnFm/17280kD8hZWildVGfj6aQXgfXxzstfQO9uBMExY2/XI6x7qKvarayPEES4qwrPxy7HQaPF0bnuYwoIdlLu6ZDtrb3xE0KYj7xz/+ga+vL//85z9xdHREpVLxj3/8w9Z1E0K0gcT0YkIDXBucQGz9cM/69cP99IVcVIN7etMzyM0yL+4Kfo23lvTcMg7FZ/Pe18d5e8NRnB201rx3QlztatOM1K4wDwt0o7CkCp1GZV3pmVNQWWcFeq0Q/8aDuPXfneGpt37iwIksNu1IoKi0mtkTLUOpvUMs0y0uNdxZXFbNsn/uZcW/D2A0mXnlk1ieeWc36bllZOaVE+Dl1Ggifw8XB3w9HDmVIkFcY5q0OtXb25uZM2dy4MAB4uPjuf322/H29rZ13YQQNqYoConpxYwdGtjg8+4u9rg629XpiUvLseSfCvFzwcFeS4i/a5N+jdva8XOWL6qwQFeSMkqYMTYMB7urM+O7EL/l5WZJnxN4YVHD43cOx2A08Z9vTrPrcBpV1UaKyqrx9agfxDnaa/HQaxqc/7r/hGUl6uv/OYzRZGbskED6dbf0kPUJ8cBkVkhMK663gr1W7V6uxxLy+PMbu6zTNw6fyiEzv9w6f68xfUI8rPnvRH1N6on76aefuO222/juu+/4/vvvuf322/nuu+9sXTchhI3lFVVRVmkgLLDheWMqlYruAa6kXNQTl5FXhouTnTVx7pBe3hw5k8vJpF9XsZZV1PDm+iPWvFVtIS4hD09XB1b8YRyzJ/bm9gu9BUJ0BePDg3j50XH4XwiK9I46PFwc6B7gSnmV0Zo8t7FciX7uuno9cRl5ZaTnlhE1vgdmRcFgNDN/2q9beQ0I80KjVrEvLrPRetUGcQN7eJGYXkxkeBABXs4cPp1DVn6FdSVtY/qGepJbWNnh5t12FE36mfrGG2/wySef0KuXZQ/Fs2fPsnjxYm688UabVk4IYVu1wVntsGlDQgNc+XZ/CmazglqtIjOvnECfXz94507ux8GT2axcd4g3/nQdbnp7Po05xTf7Uzh4MouVC8dbv1hsRVEU4hLzGNTTG2dHHfOnDbDp+wnR0ei0agb28KpXHnphqPTASUuPWkNz4sASxJ05UUpVjdHag33oZDYAUeN6MGFYEEWl1QT6/LqS1NXZjoj+fuw4nMb86QMazBdXG8Q9fc9IDsVnM3ZIIB9tPcH2fSmYzMrlg7gQy7zb06mFXDso4JLHdkVN6okzGAzWAA6gd+/e1j1NhRCdV+qFIC7Ev/6ihlqh/q5U1ZisH8YZuWXWIRsAZ0cdf5kfQUl5Dcs/2EfsqWyi9yZzzUB/jCYzy/65t97q1taWkVdOQUm1NUGxEMKi9gdabRDX0Jw4sARxZgXOZ/+a9+3gyWyC/fQEeDvTN9STaxoIoq4fEUxBSRXHzja8dVdOQQUuTna46e2ZODIEB3stw/r6WlfMXu4HXo9ubmjUKutcXFFXk4I4BwcHjh8/bn18/PhxHB1l+xohOruUrFI8XR1wucSeot0DLAFecqZlAnNecVWdX+MAPbu585e7I0jLKeX59/fhZK/lsd8NY9kD15JfXMXyD/dRWW202XXUrnYb3EuCOCEu5uyow8fDkdzCSrQaVaMJr/3cLSlHaue/VlQZiEvMY2R//0uef+QAP5wdtMTsS+bDLXGsXHeoznZf2YUV+HnWjReG9PK29tpdbk6cvU5DWKArsaeyOZ9dSlmlgbPnC68od9x3B1JZ/sG+RveF7kyaNJy6ePFiHnnkEUJDLcv1k5KSeOONN2xaMSGE7SVnllxyKBXqrlyr7YFr6IP3mkEBvLpoAm9vOMrU0d1xdbbD1dmTv8yP4KWPDvDKJ4dY9sC1rX8RWBKQerjY1+khFEJYhPq7kltYiY+HU52t9S7modfiaK/lWEIeN44KZf+JLIwmhYgBfpc8t51Ow7jwILbvS7GW3TtjgHUBRXZ+BaEBdXv6nRx09OvuyankgibtZ3zjyBDe23ScP6z8wVo2b0o/5tzU97KvbcjXOxNIzSrlf7uTmBnZuZOBNymIi4iI4H//+x9Hjx7FbDYTHh6Oh4eHresmhLAhk1nhfHYpQy7Te+Vor6V7gCvHE/KsvXIXz4m7WLCfCy8/Oq5O2agB/tw6oSdf/ZhAtcGE/YWNrluLoigcP5fH4J7ejaYqEKIr6x7gyqH47EsGTGq1iokRwcTsS+ae6QP4ekcCwX56BobVn2f3WzMje1JcVs2QXj78c9NxzqYW4evhhKIo5BZWMGpg/d68Wyf0JD7UA00T9kadPq4H1w4OYPexDGoMZrbsOkdadtllX9eQlKwSUrNKcXLQ8tn2U0QOC2qwdzI+qYDvD6WyYNaQJtWxvVwyiPvoo48aLE9OTgbgvvvua/UKCSHaRlZ+OQaj2Trx+VJGDvDjqx8T6Nfd8uMt8Dfb5FxON19L8FdQXHXZiczNlZlfTkFJFYN6Xv7LRoiuKPRCb3tD6UUudnNkT6L3JLFy3SGSMkp47I7wRnvuLhbs58Kz912DwWjmX/89wenUQsYODaSotJoaoxm/BoLHawYFNDjHrjFebo7WLfQOn8pp0u4SDfnpSDpqFSx74FqWvrubT7adYuEd4XWOyS2s5KV/76e4rIYJw7p16Gkalwzizpw5U6+suroae3t7m1VICNE2aue+/HaooyEj+/vz5fdn+WZ/Cm56O5wddZd9zcW83Cy/dPOLK1s9iDueYEltMkgWNQjRoLALQVxjixpqBXg7c+3gAPYcy8TT1Z7rRnRr1vvotGp6BrlZd1ioXQzV2IrYlvLxcGx0IUVWfjnVNSZr4AqW3voTifn0CHLjp1/SGdTTm4E9vJg4MoSdh9N46NbB1hECg9HEyx8foMZgRqdVszcus0MHcZfsI1y+fDkmk4kbbriBFStWsGLFCsrLy1EUhb/97W9tVUchhA2kZJWiUtHgdlu/1SfUA1dnO4rLaprdCwfgeSGIK7iCXE8VVQZqGpjMHHcuD3cXe7r5Nr9eQnQF3fxcuGVCzybtYHLrdZZMFDMje6LTNn/qQ59QDxLSijCZzDYL4nw9nCgoqaq3MMFkMvP8+/v4x7qDdcpPJRfy9Nrd3LN8Oxl55Yy/0A7jhwZRVWMiNj7beuwX353hTGoRj88ZxrA+vuw9nllnoUZHc8kg7s0336S8vJzhw4dby1544QVKSkp48803bV45IYTtpGSV4O/l3KRdDTRqFRH9LROcW9KTVptNPr+4ZUFcWk4pdz+/nduWbOXBl74lI88yH0ZRFOLO5TGoh5fMhxOiERq1igduHkSQz+V/6PQL9eStJ69n5oRelz22IX2C3amuMZGaXWod8vS7zDBuc/l6OGJWIK+osk75j7HnSc8tIz3XMlWk1ulUS6Lj4f18CfZzYcwQyw41g3p64epsx+6jGYDlM/GrH85y3YhujBkSyOjBAeQVVXImtZB/bz3Bt/tT6GguGcT9+OOPvPrqq3h5/TrXxM/Pj5UrV8qODUJ0cimZJdYN7pti5IVVai1ZAersoMVOp2lxT9yHW06gUauYN6UfBSVVbNmVCEBWfgV5xVUderhDiM4mNMC1wcS9TdEn1DJv9kxqEdkFFbjp7XCwb93t72rn9uUW/hrE1W4xptWoMZsV6w89gITzxXi7OfD0PaNY+9QNuDpbUippNGpGDw7gwMksisuqeWv9ERzttTx48yAARg30R61W8eK/DvDVjwmYO2CP3CWDOJ1Oh4ND/VUber0eO7vG80oJITq2kvIa0nLK6BXs3uTXDO/rS3hvH0b0v3TKgYaoVCq83Bxa1BN3+FQOh+KzmXNTH+bc1Jfx4UH8cCiViioDx89dyA8n8+GE6BACvJzRO+o4djaX9Nyyyy6maAmfC3nnaodrwZL7LaewknlT+gF1kxYnpBXRs5t7g+caNzSQqhoTD6/4jtOphTx86xDc9JZ5/67Odgzq4UVRWTV3Te3H5Gu7t/q1XKlLhsdqtZqysjL0+rpdsGVlZRiNtkvcKYSwrdp9Tgf1aHrw4+Sg42+PjGnxe3q6OrSoJ+7//neSAC9nosb3AGDGuDB+OHSez789w4ETWXi6ynw4IToKlUrFgDAvdh1JByxBUmvzcbcEcbkXhmsVRWHr7iR6dXNjxrgwPo4+yfkLKUgqqgxk5JUxYXjDizQG9/TGx8MRnUbNsgevZcBvUqo8MmsIaTmljB7c+tfRGi4ZxM2YMYOlS5fy97//HScnSzRdUVHB0qVLmTRpUptUUAjR+k4k5qPTqukT4t5m7+nl5mBdtVZSXoO9neayOeMqq40kZhRz15R+1knWvYM96Bviwdc7EnB20PLsfdfIfDghOpAn5g7neEIeqdkll93xoSV0Wg2ervbkXBhOPZVcSGpWKX+cHY6DnRZfDydrT1xSRgmKAr26uTV4Lo1GzVtPXo+dToO2gXxwwX4uTVr81V4uOZx6zz334OLiwtixY7njjju4/fbbGTt2LK6urjz66KNtVUchRCsoq6ghIa0IgLjEfPqGerRo9VlLebo6UFBchaIo/OWtn3hl3aHLviYtx/JB/NsP0XlT+jGwhxcrF46X+XBCdDB6Rx2jBwfwuxv70iOo4eDpSvl6OFkXTsTsS8bRXkvkMMuq02A/F2sQV/uZ16uR4VSwjDI0FMB1BpcdTv3b3/7GI488wokTJ1Cr1QwZMgRfX9+2qp8QohUYjCb++s+9JKYXs+IPY0lML2b2xN5tWgcvN0dqjGZSs0pJyykjLaeM+KQC+od5Wo+pMZjYfSwDRYEbIoKtQyK/DeKG9fVlWF/5HBKiq/L1cOLs+SLKKmr4+Ug6E0eF4HhhAUU3Xz1Hz+ZiMiskpBXh6eqAh2vDe8Z2dk1aMhIUFERQ0OXzywghOqaPtp4k4XwRDnYa/v7vA5jNCoN6tO0OB14XPkR3H7Ms59dp1Xy87SSP3j6UHw6dJyWzlPjkAkoralCrVYweHEBaTikatarVEwQLITo3Hw9H9hzPZOOOBGqMZqaO7m59LsTPBYPRTHZBOefSii7ZC9fZdc7+QyFEk8Wdy+O/PyVy8/ge/P6WwRSX1aBRq+gX6nn5F7ei2oS/e45lYKdVM39af+LO5bPgHz/w9Y4EcgorGNHPlzsn9cVsVjh73jLPJdDHudMOdQghbMPX0wmjycxXPyYwYVg3wgJ/Hbat7bn/Zl8KaTll9G7Dub9trXWTtwghOpxjCXmoVHD31P7Y6TT8cOg8GrWq1XM3XU7t1lspWaUMCPNk+tgwzqQWEejjzIyxPXB3sSzrL6uo4T/fnCY+qYC0nFJCmrC3qxCia6lNXWKnVXNf1IA6z3W7EMR99WMCQT56po0Ja/P6tRUJ4oS4yiVnlhDo7WwN2l54aDTtkbLS86I5Kf1CPdFpNTx1d0S94/ROdoT4u3D8XB6Z+RWMHSpTOYQQddWmFZpzU1/rjjC19I46vN0cMJkVlj802prc92okQZwQV7mUzBK6B/7am2V3mbQetmKn0+DipKO0wkC/7pceyu3f3ZNv9qegKE3b21UI0bX4eznz3pKJjc6Xfea+Ubg42eHXyvu2djQy0USIq1hVtZHM/HK6d5AhydpfzP26e1zyuP7dPand4SZYEvkKIRoQ6KNvNEdk72AP/L2u/gVRNg3i3njjDaZNm8b06dP56KOPANizZw9RUVFMmjSJ119/3XpsfHw8s2bNYvLkyTz77LPWHSEyMjKYN28eU6ZMYcGCBZSXlwNQUlLCQw89xNSpU5k3bx65ubm2vBQhOqXU7FIUhTo9ce3J292RAC9nPFwuvdy//4WeOpUKgiSIE0KIBtksiDtw4AD79u1jy5YtfPXVV6xbt45Tp07xzDPPsHbtWqKjo4mLi2Pnzp0ALF68mGXLlrF9+3YURWH9+vUALF++nLlz5xITE8OgQYNYu3YtAKtXryYiIoJt27Yxe/ZsXnrpJVtdihCdVnJmCWDZ0Loj+P3MQTx978jLHhfg7Yyb3g5fDycc7GTWhxBCNMRmQdyoUaP4+OOP0Wq15OfnYzKZKCkpITQ0lODgYLRaLVFRUcTExJCenk5VVRXh4eEAzJo1i5iYGAwGAwcPHmTy5Ml1ygF27NhBVFQUYNkebNeuXRgMBltdjhCdUkpmCfZ2Gvw9O8awQqCPvk4qgMaoVCqmjg7juhEN73cohBDCxgsbdDoda9as4V//+hdTpkwhJycHHx8f6/O+vr5kZ2fXK/fx8SE7O5vCwkL0ej1arbZOOVDnNVqtFr1eT0FBAX5+fra8JCE6leTMEkL9XVCrO9/eovOm9GvvKgghRIdm83GKxx57jN///vc88sgjJCcn15mEqCgKKpUKs9ncYHntnxdrbBKjoiio1fU7FmNjYy/5WNiOtHXbaaitFUXh7PkC+ndzlP8XrUzas+1IW7cdaeu201ptbbMg7ty5c9TU1NC/f38cHR2ZNGkSMTExaDS/pjfIzc3F19cXf3//OgsT8vLy8PX1xdPTk9LSUkwmExqNxno8WHrx8vLy8Pf3x2g0Ul5ejru7e716jBgxwvr32NjYOo+F7Uhbt53G2vp8dimV1emMGBzGiBE926FmVye5t9uOtHXbkbZuO5dq6+YGdzabE5eWlsbSpUupqamhpqaG77//njlz5pCUlERKSgomk4mtW7cSGRlJUFAQ9vb21spv3ryZyMhIdDodERERREdHA7Bp0yYiIyMBmDBhAps2bQIgOjqaiIgIdDqdrS5HiE7DbFbYF5fJX976CUd7LSP6yRQDIYS4GtmsJ27ChAkcO3aMW265BY1Gw6RJk5g+fTqenp4sXLiQ6upqJkyYwJQpUwBYtWoVS5cupaysjIEDBzJ//nwAnnvuOZYsWcI777xDQEAAr732GgCLFi1iyZIlTJ8+HRcXF1atWmWrSxGi09i2J4kvvjtDfnEV3QNcWXLPSIJ8JEWHEEJcjWw6J27hwoUsXLiwTtno0aPZsmVLvWP79evHhg0b6pUHBQWxbt26euXu7u68++67rVdZITq5iioD72+Oo3uAK/dOH8CYIYHttjuDEEII25METEJcJQ7FZ2Mwmnng5kEM7OHV3tURQghhY7LtlhBXiZ+PZuDpam/d7UAIIcTVTYI4Ia4CldVGYuOzGTM4sFPmhBNCCNF8EsQJcRU4FJ9NjdHMmKGB7V0VIYQQbUTmxAnRiZnNCseSKth5Mg5PV3sGhMlcOCGE6CqkJ06ITuzT7afYuLcAdxd7nr3vGjQylCqEEF2G9MQJ0Umdzy5l449nGdzdiRcfnSBz4YQQoouRIE6ITsRgNPHhlhMEejuz/0QW9joNk4e7SQAnhBBdkARxQnQiR8/m8b/dSdbHj9w6GL1DYTvWSAghRHuRIE6ITuSX0znYadWsWhRJWnYZY4YGcuQXCeKEEKIrkiBOiE7k8OkcBvX0JizQjbBAt/aujhBCiHYkq1OF6CRyCitIyyljWF/f9q6KEEKIDkCCOCE6iV9O5wIwrK9PO9dECCFERyBBnBCdxC9ncvBycyDEz6W9qyKEEKIDkCBOiE6gosrAkdM5DOvji0ol6USEEEJIECdEp7B55znKq4xMHdO9vasihBCig5AgToh2ZDCaUBTlkscUl1Xz9c5zjB4cQJ8QjzaqmRBCiI5Ogjgh2klZRQ2PvPw9f3nrZwpKqqzlZ1ILefXTWEoragD4/NvTVNcYuWtKv/aqqhBCiA5I8sQJ0U7+uek4+cVVFJfX8MTrO3nh4dGE+Lnw7sZjnD1fRHZBBSMH+LH15ySmju5OiL9re1dZCCFEByI9cUK0g73HM/gxNo3ZE/vwysLxmBWFf3x8kD3HMjl7vojx4UGcSing4+h4xg4J5OFbB7d3lYUQQnQw0hMnRBsymsx88e0Z1n9/hh6BbtxxYx90WjV/njucZf/cyyufHMLX04kn7hzOqAF+JKQVc++MAWg08ntLCCFEXfLNIEQb+jTmFJ9/e5oJw4J4acEYdFrLP8HwPr7Muq4XJrPCHRN7o9OquW5EMA/OHIRWAjghhBANkJ44IdqI2aywI/Y8Iwf48ae5I+o9f/fU/owc4M+AMM92qJ0QQojORn7iC9FGzp4vJK+4inFDgxp8XqNRM7CHlyTzFUII0SQSxAnRRvYcy0SrUTFqoH97V0UIIcRVQII4IdqAoijsPpbB0N4+6B117V0dIYQQVwEJ4oRoA+fSi8kuqGDskMD2rooQQoirhARxQrSB2PhsVCpkKFUIIUSrsWkQ99ZbbzF9+nSmT5/OypUrAdizZw9RUVFMmjSJ119/3XpsfHw8s2bNYvLkyTz77LMYjUYAMjIymDdvHlOmTGHBggWUl5cDUFJSwkMPPcTUqVOZN28eubm5trwUIa7IsYQ8wgLdcNPbt3dVhBBCXCVsFsTt2bOHn3/+ma+//ppNmzZx4sQJtm7dyjPPPMPatWuJjo4mLi6OnTt3ArB48WKWLVvG9u3bURSF9evXA7B8+XLmzp1LTEwMgwYNYu3atQCsXr2aiIgItm3bxuzZs3nppZdsdSlCXJFqg4n45AKG9PJu76oIIYS4itgsiPPx8WHJkiXY2dmh0+no2bMnycnJhIaGEhwcjFarJSoqipiYGNLT06mqqiI8PByAWbNmERMTg8Fg4ODBg0yePLlOOcCOHTuIiooCYMaMGezatQuDwWCryxGixU4lFWAwmhna26e9qyKEEOIqYrMgrnfv3tagLDk5mW3btqFSqfDx+fWLzNfXl+zsbHJycuqU+/j4kJ2dTWFhIXq9Hq1WW6ccqPMarVaLXq+noKDAVpcjRIsdTchFo1ZJEl8hhBCtyuY7Npw9e5aHH36Yp556Co1GQ3JysvU5RVFQqVSYzeY6CU5ry2v/vFhjiVAVRUGtrh+TxsbGXvKxsJ2O2tbVBjOVNWbcndtmw5K9R3II9NQRf+KYzd6jo7b11Urau+1IW7cdaeu201ptbdNvsdjYWB577DGeeeYZpk+fzoEDB+osQMjNzcXX1xd/f/865Xl5efj6+uLp6UlpaSkmkwmNRmM9Hiy9eHl5efj7+2M0GikvL8fd3b1eHUaM+HV7o9jY2DqPhe105LZe88Uv/Hw0g3f+cgNebo4AZOWX88Oh89w4KgRfDyfrsWWVBiqrjPh4OLbovZIzS8goTGf2Db0ZMaJ/q9T/tzpyW1+NpL3bjrR125G2bjuXauvmBnc2C+IyMzN59NFHef311xk9ejQAQ4cOJSkpiZSUFLp168bWrVu57bbbCAoKwt7e3nphmzdvJjIyEp1OR0REBNHR0URFRbFp0yYiIyMBmDBhAps2beKRRx4hOjqaiIgIdDpJotpVVVQZyMwrp2c390seZzCa2H0sg8pqIx/99yQLfxfOR/89QczeZExmhWMJefx9wVhyCiv4NOYUu49lYDCa6R7gytzJ/Rg9OOCS51cUhQMnsjhwMpv45HzOZ5eh1agZI/nhhBBCtDKbBXEffvgh1dXVvPzyy9ayOXPm8PLLL7Nw4UKqq6uZMGECU6ZMAWDVqlUsXbqUsrIyBg4cyPz58wF47rnnWLJkCe+88w4BAQG89tprACxatIglS5Ywffp0XFxcWLVqla0uRXRwiqKw4v8OcuRMLrde14v50/qj1TQ83fOX07lUVBkZ2MOLnb+kkZhRxPnsMqaN6Y6fpxMfbT3Jh/+NY9cv6VTXmLhpVAj+Xs58eyCF1Z8fpn/3G3F3aThNSGlFDe98dYyfjqSjd9TRJ8SDqaPDGBceiIeLgy2bQAghRBdksyBu6dKlLF26tMHntmzZUq+sX79+bNiwoV55UFAQ69atq1fu7u7Ou+++e+UVFZ3GkTM5HD6di8FgImKAHyP6+QHw7YFUjpzJpX93T77ekUB+cSWL74po8By1AdZf77+Gx179kbyiSp69bxTXDgpAURSOns1jy65EvNwceHVRJMF+LgBE9Pfjj6t+5LNvTrFg1hDScsoI8Ha2Bosms8Ly9/eRkFbE3VP7c9v1vdA0EkgKIYQQraFtZnYLcYUycstY/sF+ADQaFVt3JzGklzehAa58fzCVQT29eOmRsXywJY7o3UksuM1Qb4/SaoOJ/ScyGTc0CGdHHSsXjkdRwNvdMt9NpVLx2O/CWf/dGW67vje+nr/OjQv2c2Ha6O5E70niZGI+KVmlBPu58NAtgxja24ctu85xOrWQP88bwXXDu7VdwwghhOiyJIgTHZ6iKLy78Rh2OjXv/mUieic7tu1JYtOuc5xLK8Jdb8/CO8JRq1VEhgfx358SORSfXS+Y+u5AKpXVJsaHBwFYFzVczMvNkQW3DW2wHnMm9eWno+mYFYX50/qzfV8Kf31vL726uZGaVco1A/2ZMCyo9RtACCGEaIAEcaJDMpnMnEjK50xqETmFFfxyJpeHbhmMh6tlbtnNkT25ObJnvdf1CfHA3cWe/XGZdYK4bXuTee/rYwzp5d3inRPc9Pb8a+kktBo1arWKmyN78t2BVP63OxFHBy0LbhvSaAocIYQQorVJECc6nKSMYp77514KS6utZeG9fZg2pvtlX6tWqxg1wJ+fjqRjMJrQaTXsiD3P2g1HGTnAj7/MH3lFc9XsdBrr3+11GqaPDWPamO4YTQo6rcyBE0II0XYkiBMdzr/+ewKjSWHJ/JGE9/HB0V6LWt30Hq5rBvnzzf4UjiXk4aa35831RxjYw4un7xllk0BLpVKh00oPnBBCiLYlQZzoUI4l5HLkTC4P3DyQsUNbllttaG8fHOw0vPiv/ahVKlz19iyZP1J6yoQQQlxVJIgTHYaiKHwcHY+3mwPTxoS1+Dz2Og1/mT+SuHN5VFQZmT4urNHcbkIIIURnJUGc6DB+jE3jdEohf5wdXmfuWUtE9Pcjor9fK9VMCCGE6HgkiBNt6vi5PNZFx1NYWoXeyY7ZN/Rm9OAAistq+GDzcfp39+SmUSHtXU0hhBCiw5MgTrSZ89mlvPSv/Tg76ujf3YuEtEJW/N9BvN0ccHTQUllt4o+zhzZrEYMQQgjRVUkQJ65IXlElBqMZV2c7nH+zQ8LF8osreeHDfei0Glb8YRy+nk6YTGZ2HUnn4MlszqQWcs/0/oT4u7Zh7YUQQojOS4I40WLn0op4/PWdANjbaVjxh7H0Dvbgy+/PcPB4PoWmFHoEuVNeaWDVp4eorDbxt4dHW7ez0mjUXD8imOtHBLfnZQghhBCdkgRxosV2HE5Dq1Hxh9uG8knMKVZ//guzJ/bh4+h47LQq3vjiiPVYX08nXnloDKEB0tMmhBBCtAYJ4kSLmM0KPx/NYFhfX266JhQPVweWf7CPVz+NpU+IO3eMdsa3W28y88qpqDIwcoA/bnpJ8yGEEEK0Fsl+KlrkTGoheUWV1s3kI/r7MWV0d9z19vzl7pFoNSrCAt0YMySQG0eFSgAnhBBCtDLpiRMt8tORdHRaNdcM9LeW/eG2Ifx+5iDsdBrOJ7Vj5YQQQoguQII40SzVBhN7j2ey85c0hvf1xcnh1xWpKpXqipP0CiGEEKJpJIgTDcorquTAySyc7LUEeDvTJ8SDxPRiXvr3AXILK/H1dOKOG/u0dzWFEEKILkuCuC5KURT++fVx4lMK+PPcEQT7uZBfXMmJxHwOn85h5+E0jCbFenyAlzP5JVW4Oul44aHRDO3tI0l5hRBCiHYkQVwX9fWOBLbuTsJOq+bPb+wkxN+V0ymFgCXn203XhBI1rgcqlWURw/cHzxPi78Kjs4fi4eLQzrUXQgghhARxV6Fqg4njCXkUl1Xj5KAl7lw++05koXfQ4evpSEWVkePn8hgfHsS9Mwbw5vojlJTVcPfU/gzv50tYgCsaza8Ll7v5unBDhOxnKoQQQnQkEsRdZb7dn8K7G49RYzRby7QaNSP6+WI0mUnPLUfvqGPKtd15YOYg7HUa/vbwmHassRBCCCFaQoK4q0hpRQ0fbomjR5Abd07qR4C3M2WVNQR4OaN3smvv6gkhhBCiFUkQdxX58vuzVFQb+ePs8Iu2t3Ju1zoJIYQQwjYkiLsKKIpCXGI+W39O5IaIYNmfVAghhOgCJIjrYMoqDTjYadBqLr8jmslk5vtD5/ny+zNk5Vfg4qRj7uR+bVBLIYQQQrQ3CeLaWVWNkTOphSRllHDgRBbHz+XhYKehf5gXTvZaagxmsgvKMSswZnAAvYLdKS2v4WxaEbGncsgpqKBPiDt3TurLtYMC6uygIIQQQoirlwRx7SS/uJJvD6SyZVcipRU1AAT5ODN7Yh9KK2qITyogx2RGq1Hj5+lMtcHIl9+fwXwh/66jvYYBYV48ePMgrh3kj0oliXeFEEKIrkSCOBsxmRWSM4pxdNAS6K23lv30Sxqbf0ok4XwRACMH+DFtTBg9g9xwd7G/ZDBWWFJFXnElLk52eLs7NmnIVQghhBBXJ5sGcWVlZcyZM4d3332Xbt26sWfPHlasWEF1dTVTp07liSeeACA+Pp5nn32W8vJyIiIiWL58OVqtloyMDBYvXkx+fj5hYWGsWrUKZ2dnSkpKePLJJzl//jyenp6sXr0aHx8fW15Ko/7zzWkKS6pwcbbDxUmH2axwIrGAE4l5lFcZAejf3RNXZzuSMkvIKagg1N+F+dP6c+2gAIL9XJr8Xh6uDni4ym4JQgghhACbdeUcPXqUO++8k+TkZACqqqp45plnWLt2LdHR0cTFxbFz504AFi9ezLJly9i+fTuKorB+/XoAli9fzty5c4mJiWHQoEGsXbsWgNWrVxMREcG2bduYPXs2L730kq0u47JOpxSw+1gGG74/w4dbTvDR1pOk5ZQyLjyIP88dzr3TB1BZbSQzv5zu/q4smT+SNX++ntkT+zQrgBNCCCGEuJjNeuLWr1/Pc889x1NPPQXAsWPHCA0NJTg4GICoqChiYmLo1asXVVVVhIeHAzBr1izWrFnD7NmzOXjwIG+//ba1/K677mLx4sXs2LGDTz/9FIAZM2bwwgsvYDAY0OnaflL/878fDYDZrFBZbcRkVnB1rptY97Yberd5vYQQQghxdbNZEPfb3rGcnJw6Q56+vr5kZ2fXK/fx8SE7O5vCwkL0ej1arbZO+W/PpdVq0ev1FBQU4OfnV68esbGxl3wsbEfauu1IW7ctae+2I23ddqSt205rtXWbLWwwm811Ju0rioJKpWq0vPbPizU26V9RFNTqhkeGR4wYYf17bGxsncfCdqSt2460dduS9m470tZtR9q67VyqrZsb3LXZ8kZ/f39yc3Otj3Nzc/H19a1XnpeXh6+vL56enpSWlmIymeocD5ZevLy8PACMRiPl5eW4u7u31aUIIYQQQrS7Ngvihg4dSlJSEikpKZhMJrZu3UpkZCRBQUHY29tbo8/NmzcTGRmJTqcjIiKC6OhoADZt2kRkZCQAEyZMYNOmTQBER0cTERHRLvPhhBBCCCHaS5sNp9rb2/Pyyy+zcOFCqqurmTBhAlOmTAFg1apVLF26lLKyMgYOHMj8+fMBeO6551iyZAnvvPMOAQEBvPbaawAsWrSIJUuWMH36dFxcXFi1alVbXYYQQgghRIdg8yDuhx9+sP599OjRbNmypd4x/fr1Y8OGDfXKg4KCWLduXb1yd3d33n333datqBBCCCFEJyIp/4UQQgghOiEJ4oQQQgghOiGVoihKe1fCViTnjRBCCCE6k+akermqgzghhBBCiKuVDKcKIYQQQnRCEsQJIYQQQnRCbZYnzlbeeusttm3bBliSAF9zzTXWfHIA2dnZDB06lPfee4/4+HieffZZysvLiYiIYPny5Wi1WjIyMli8eDH5+fmEhYWxatUqnJ2d2+uSOqzmtPVbb73FV199haurKwB33HEH8+bNk7Zuot+29VNPPcXPP//MypUrMZvNDBgwgBdffBE7Ozu5r1tBc9pb7u0r01Bbb9y4kQ8++ACNRsM111zDkiVL0Gq1cm9foea0tdzXV+aNN95g+/btqFQqbr/9du677z727NnDihUrqK6uZurUqTzxxBMArXtfK53Y7t27ld/97ndKdXW1UlNTo8yfP1/55ptvrM/n5OQoEydOVJKSkhRFUZTp06crv/zyi6IoivL0008rn376qaIoivLQQw8pW7duVRRFUd566y1l5cqVbXodnUFz2/rhhx9WDh8+XO880taX11hbR0ZGKgkJCYqiKMrChQuV9evXK4oi9/WVam57y73dcg219XvvvaeMHz9eyc7OVhRFUZ577jnlX//6l6Iocm9fiea2tdzXLbd//35lzpw5isFgUCorK5Xrr79eiY+PVyZMmKCkpqYqBoNBuf/++5UdO3YoitK693WnHk718fFhyZIl2NnZodPp6NmzJxkZGdbnV65cyZw5c+jevTvp6elUVVURHh4OwKxZs4iJicFgMHDw4EEmT55cp1zU1Zy2BoiLi+O9994jKiqKF154gerqamnrJmqsrU0mE2VlZZhMJqqrq7G3t5f7uhU0p71B7u0r0VBb19TUEB4ebt0b+/rrr+e7776Te/sKNaetQe7rKzFq1Cg+/vhjtFot+fn5mEwmSkpKCA0NJTg4GK1WS1RUFDExMa1+X3fqIK53797WhkhOTmbbtm1MmDDB+vjAgQPWLbxycnLw8fGxvtbHx4fs7GwKCwvR6/Votdo65aKu5rR1eXk5/fv3Z/HixXz99deUlJSwdu1aaesmaqytn3/+ee6++27Gjx9PYWEhU6ZMkfu6FTSnveXevjINtfW0adM4evQomZmZmEwmYmJiyMvLk3v7CjWnreW+vnI6nY41a9Ywffp0Ro8eXe/+9fX1JTs7u9Xv604dxNU6e/Ys999/P0899ZS1J+iLL75g7ty52NnZAWA2m1GpVNbXKIqCSqWy/nmx3z4Wv2pKWzs7O/P+++/Ts2dPtFot999/Pzt37pS2bqaL29rZ2ZlVq1axdetWfv75Z4YOHcqKFSvkvm5FTWlvubdbx8Vt3aNHD/785z+zYMEC5s2bR9++fdHpdHJvt5KmtLXc163jscceY+/evWRmZpKcnNzg/dva93WnD+JiY2O59957+fOf/8ytt95qLf/++++ZNm2a9bG/vz+5ubnWx3l5efj6+uLp6UlpaSkmkwmA3Nxca1ezqKupbZ2RkVFnL1xFUdBqtdLWzfDbtj506BB9+vQhJCQEtVrNHXfcwYEDB+S+biVNbW+5t6/cb9u6urqaIUOGsGnTJj7//HP8/PwIDg6We7sVNLWt5b6+MufOnSM+Ph4AR0dHJk2axP79++vcv7Vt19r3dacO4jIzM3n00UdZtWoV06dPt5YXFBRQVVVFcHCwtSwoKAh7e3vrLg6bN28mMjISnU5HREQE0dHRAGzatInIyMi2vZBOoDlt7eDgwCuvvML58+dRFIVPP/2Um266Sdq6iRpq6z59+nDs2DHy8vIAS+A8ePBgua9bQXPaW+7tK9NQW1dUVHDvvfdSVlZGTU0Nn3zyCdOmTZN7+wo1p63lvr4yaWlpLF26lJqaGmpqavj++++ZM2cOSUlJpKSkYDKZ2Lp1K5GRka1+X3fqHRtefPFFvvrqK0JCQqxlc+bMYeDAgbz44ousX7++zvGnTp1i6dKllJWVMXDgQFasWIGdnR3p6eksWbKE/Px8AgICeO2113Bzc2vry+nQmtvW27dv580338RgMDB8+HCWL18ubd1EjbW1g4MD77//PhqNhtDQUF544QU8PT3lvr5CzW1vubdbrrG21mq1/Pvf/8ZoNDJjxgwWLlwIyGf2lWhuW8t9fWXefPNNtm3bhkajYdKkSSxcuJC9e/daU4xMmDCBp59+GpVK1ar3dacO4oQQQgghuqpOPZwqhBBCCNFVSRAnhBBCCNEJSRAnhBBCCNEJSRAnhBBCCNEJSRAnhBBCCNEJSRAnhLgiaWlp9O/fn5kzZzJz5kyioqKYM2eONd/R5bz11lvW/RubauPGjYwYMYKZM2dy8803M23aNB5++GFycnKadZ5z587x0EMPERUVRVRUFHfddReHDh1q1jnAkkfuxRdfvOQxaWlpDBs2rMHn+vbty+rVq+uUxcTEcPfddze7Lo25++67Zd9LIa4y2vaugBCi83NwcGDz5s3Wx+np6dx7771oNBrrhs6N2b9/P7169Wr2e0ZERPDee+9ZHz///POsWbPmssHUxR577DEef/xxbrrpJgAOHjzIww8/zPfff4+7u3uTzzNx4kQmTpzY5OMb8tFHHzF27FhGjhx5RecRQnQdEsQJIVpdUFAQjz32GB9++CGTJ08mKSmJF154gfLycnJzc+nXrx+rV69mw4YNxMXFsXLlSjQaDRMmTGDVqlUcPHgQk8nEgAEDWLp0KXq9/pLvZzAYKCsrIzg4GEVRmDJlCsuWLWPs2LEAPPvss/Tp04d77rmnzutyc3OpqKiwPh45ciSrV69Go9EAcPjwYVatWkVlZSVqtZo//vGPXH/99WzcuJENGzZQWVmJXq/n1ltvZfv27bz33nscOXKEV155hZqaGnJzcxkzZgx///vfL9tmTzzxBIsXL2bz5s31Eny++eabFBYWsmzZsnqP7777bgYOHMiRI0coKCjgjjvuIC8vjwMHDlBZWcnq1avp27cvAN9++y3//Oc/qaqqIioqigULFjTrOtetW3fZ6xBCtB0J4oQQNtGvXz/OnDkDwPr167nllluYOXMmBoOBWbNmsWPHDubNm0dMTAzz5s3jpptu4q233kKj0bBx40ZUKhWvvfYaq1at4vnnn693/kOHDjFz5kwURSE7Oxt7e3ueeOIJVCoVd955J+vXr2fs2LGUlZXxww8/8Je//KXeOZYtW8by5ct55ZVXGDFiBCNHjmTGjBm4uLhQXFzM008/zYcffki3bt3Izs7mjjvusAZECQkJ/PDDD+j1ejZu3Gg958cff8xjjz3GNddcQ3l5ORMnTiQuLu6yPXs333wzcXFx/PWvf2XNmjXNauv09HQ+//xzjh49yh133ME777zDkiVL+Pvf/84nn3zC3/72NwDKy8tZv349VVVVzJ49mwEDBhAeHt7k6xRCdCwSxAkhbEKlUuHg4ADA4sWL2b17N++//z7Jycnk5OTU6QGrtWPHDkpLS9mzZw9g6WHz8vJq8PwXD6eazWbeeecdHnzwQaKjo5k1axZvv/02BQUFxMTEcN111+Hq6lrvHDNmzOCmm24iNjaWgwcP8tVXX/HOO+/wxRdfcO7cOXJzc3n00UfrXNPp06cByzy2hgKbl19+mV27dvHuu++SmJhIdXU1FRUVTRqeff7555k5cyZffvklLi4ulz2+Vu1wcO0exuPHjwcgJCSEAwcOWI+7/fbb0Wq16PV6Jk+ebG3nllynEKL9SRAnhLCJ48eP06dPHwD+9Kc/YTKZmDp1Ktdddx2ZmZk0tOOf2WzmmWeeYcKECYCl56i6uvqy76VWq7n77rtZs2YN+fn5eHt7M2XKFLZs2cJ///tfnnvuuXqvOXfuHF9//TVPPvkkY8aMYcyYMSxatIh7772X7du3ExYWRs+ePfnyyy+tr8nOzsbT05P//ve/ODk5NViXu+66i759+zJ+/HimTp3K0aNHG7zWhuj1el599VUefPBBHnjgAWu5SqWqcw6DwVDndXZ2dnUe63S6Bs9fO0wMoCgKWq0Wk8nUousUQrQ/WZ0qhGh1SUlJrF27lvvvvx+An3/+mUcffZRp06YBcPToUUwmE2AJLIxGIwDjxo3j008/paamBrPZzF//+ldee+21Jr3njh07CAoKwtPTE4B58+bx8ccfoygKQ4YMqXe8t7c369evr7Nis6ioiOzsbOswY0pKCgcPHgQgPj6eyZMnk52d3WgdSkpKOH78OE8++SSTJk0iKyuL1NRUzGZzk64BIDw8nPvuu4+1a9dayzw8PDhx4gSKolBWVsaPP/7Y5PNdbNOmTSiKQnFxMdu2bWP8+PEtuk4hRMcgPXFCiCtWVVXFzJkzAUuvmL29PX/605+47rrrAMuk/UcffRQnJyf0ej0jR44kNTUVgBtuuIHXXnsNg8HAH/7wB/7xj39w6623YjKZ6N+/P0uWLGnwPWvnxKlUKoxGI+7u7rz99tuo1Zbfpv369cPNzY05c+Y0+Ho3Nzf+7//+j1dffZWVK1fi6OiInZ0dDz/8MKNHjwZgzZo1rFy5kurqahRFYeXKlXTr1q3OEOXFXF1deeihh7j11ltxcnLCz8+P4cOHk5KSYh3qbIoFCxawd+9e6+Obb76Zn376iUmTJuHn58eoUaOa3Lt3MRcXF2bNmkVVVRV33XUX1157bYuuUwjRMaiUlnwSCCFEB5eammrNjebo6Nje1RFCiFYnPXFCiKvOG2+8wfr161m+fLkEcEKIq5b0xAkhhBBCdEKysEEIIYQQohOSIE4IIYQQohOSIE4IIYQQohOSIE4IIYQQohOSIE4IIYQQohOSIE4IIYQQohP6fwHrTX5qhjZ7AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bitcoin2020_df.dropna()\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.title(\"Bitcoin Price INR\")\n",
    "plt.xlabel(\"Date By Serial Number\")\n",
    "plt.ylabel(\"Close\")\n",
    "plt.plot(bitcoin2020_df[\"Close\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9b80b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inferred frequency is: D\n",
      "Model Number: 1 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 2 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 3 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 4 with model DatepartRegression in generation 0 of 10\n",
      "Model Number: 5 with model DatepartRegression in generation 0 of 10\n",
      "Model Number: 6 with model DatepartRegression in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 7 with model DatepartRegression in generation 0 of 10\n",
      "Epoch 1/50\n",
      "9/9 [==============================] - 3s 2ms/step - loss: 0.3698\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.3384\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.3096\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2811\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.2557\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2306\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2224\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2135\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.2050\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1956\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1957\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1842\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1869\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1749\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1719\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1813\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1656\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1624\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1614\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1591\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1561\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1502\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1547\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1509\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1383\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1460\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1430\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1396\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1346\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1338\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1305\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1251\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1269\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1190\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1234\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1161\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1227\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1156\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1141\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1143\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 0.1097\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1066\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1097\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1061\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1064\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1027\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1015\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1051\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.1005\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 0.0951\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 7: DatepartRegression\n",
      "Model Number: 8 with model ETS in generation 0 of 10\n",
      "Model Number: 9 with model ETS in generation 0 of 10\n",
      "Model Number: 10 with model GLM in generation 0 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 10: GLM\n",
      "Model Number: 11 with model GLM in generation 0 of 10\n",
      "Model Number: 12 with model GLS in generation 0 of 10\n",
      "Model Number: 13 with model GLS in generation 0 of 10\n",
      "Model Number: 14 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 14: GluonTS\n",
      "Model Number: 15 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 15: GluonTS\n",
      "Model Number: 16 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 16: GluonTS\n",
      "Model Number: 17 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 17: GluonTS\n",
      "Model Number: 18 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 18: GluonTS\n",
      "Model Number: 19 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 19: GluonTS\n",
      "Model Number: 20 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 21 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 22 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 23 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 24 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 25 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 26 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 27 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 28 with model UnobservedComponents in generation 0 of 10\n",
      "Model Number: 29 with model UnobservedComponents in generation 0 of 10\n",
      "Model Number: 30 with model UnobservedComponents in generation 0 of 10\n",
      "Model Number: 31 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 31: VAR\n",
      "Model Number: 32 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 32: VAR\n",
      "Model Number: 33 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 33: VAR\n",
      "Model Number: 34 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 34: VECM\n",
      "Model Number: 35 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 35: VECM\n",
      "Model Number: 36 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 36: VECM\n",
      "Model Number: 37 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 37: VECM\n",
      "Model Number: 38 with model WindowRegression in generation 0 of 10\n",
      "Model Number: 39 with model ZeroesNaive in generation 0 of 10\n",
      "Model Number: 40 with model ZeroesNaive in generation 0 of 10\n",
      "Model Number: 41 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 42 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 43 with model GLS in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 44 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 45 with model GLM in generation 0 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 45: GLM\n",
      "Model Number: 46 with model ETS in generation 0 of 10\n",
      "Model Number: 47 with model FBProphet in generation 0 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 47: FBProphet\n",
      "Model Number: 48 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 48: GluonTS\n",
      "Model Number: 49 with model UnobservedComponents in generation 0 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 49: UnobservedComponents\n",
      "Model Number: 50 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 50: VAR\n",
      "Model Number: 51 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 51: VECM\n",
      "Model Number: 52 with model WindowRegression in generation 0 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 52: WindowRegression\n",
      "Model Number: 53 with model DatepartRegression in generation 0 of 10\n",
      "Model Number: 54 with model MultivariateRegression in generation 0 of 10\n",
      "Model Number: 55 with model UnivariateMotif in generation 0 of 10\n",
      "Model Number: 56 with model MultivariateMotif in generation 0 of 10\n",
      "Model Number: 57 with model SectionalMotif in generation 0 of 10\n",
      "Model Number: 58 with model NVAR in generation 0 of 10\n",
      "Model Number: 59 with model Theta in generation 0 of 10\n",
      "Model Number: 60 with model ARDL in generation 0 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 60: ARDL\n",
      "Model Number: 61 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 61: VAR\n",
      "Model Number: 62 with model VECM in generation 0 of 10\n",
      "Template Eval Error: Exception('Transformer StandardScaler failed on fit') in model 62: VECM\n",
      "Model Number: 63 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 64 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 64: GluonTS\n",
      "Model Number: 65 with model UnivariateMotif in generation 0 of 10\n",
      "Model Number: 66 with model WindowRegression in generation 0 of 10\n",
      "Model Number: 67 with model GLM in generation 0 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 67: GLM\n",
      "Model Number: 68 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 69 with model SectionalMotif in generation 0 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:847: RuntimeWarning: invalid value encountered in true_divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:689: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  result = op(x, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 70 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 70: VECM\n",
      "Model Number: 71 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 71: VECM\n",
      "Model Number: 72 with model MultivariateMotif in generation 0 of 10\n",
      "Model Number: 73 with model GLS in generation 0 of 10\n",
      "Model Number: 74 with model MultivariateMotif in generation 0 of 10\n",
      "Model Number: 75 with model DatepartRegression in generation 0 of 10\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 2s 43ms/step - loss: 101.8718 - val_loss: 76.9212\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 83.7592 - val_loss: 77.2920\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 83.4070 - val_loss: 57.6564\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 80.5546 - val_loss: 21.9186\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 74.4998 - val_loss: 126.0139\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 85.5531 - val_loss: 49.4146\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 79.3853 - val_loss: 70.2683\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 77.2345 - val_loss: 61.6210\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 70.6355 - val_loss: 41.2128\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 75.8657 - val_loss: 58.3381\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 73.4868 - val_loss: 62.0658\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 65.1388 - val_loss: 70.1294\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 65.3575 - val_loss: 71.9280\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 60.7760 - val_loss: 33.9134\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 75: DatepartRegression\n",
      "Model Number: 76 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 76: VECM\n",
      "Model Number: 77 with model MultivariateMotif in generation 0 of 10\n",
      "Model Number: 78 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 79 with model GLS in generation 0 of 10\n",
      "Model Number: 80 with model WindowRegression in generation 0 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'lightgbm'\") in model 80: WindowRegression\n",
      "Model Number: 81 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 82 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 82: GluonTS\n",
      "Model Number: 83 with model ETS in generation 0 of 10\n",
      "Model Number: 84 with model UnobservedComponents in generation 0 of 10\n",
      "Model Number: 85 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 86 with model WindowRegression in generation 0 of 10\n",
      "Model Number: 87 with model SectionalMotif in generation 0 of 10\n",
      "Model Number: 88 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 89 with model SectionalMotif in generation 0 of 10\n",
      "Model Number: 90 with model WindowRegression in generation 0 of 10\n",
      "Model Number: 91 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 91: VECM\n",
      "Model Number: 92 with model GLS in generation 0 of 10\n",
      "Model Number: 93 with model ZeroesNaive in generation 0 of 10\n",
      "Model Number: 94 with model UnobservedComponents in generation 0 of 10\n",
      "Model Number: 95 with model UnivariateMotif in generation 0 of 10\n",
      "Model Number: 96 with model WindowRegression in generation 0 of 10\n",
      "Model Number: 97 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 97: GluonTS\n",
      "Model Number: 98 with model WindowRegression in generation 0 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'lightgbm'\") in model 98: WindowRegression\n",
      "Model Number: 99 with model FBProphet in generation 0 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 99: FBProphet\n",
      "Model Number: 100 with model GLS in generation 0 of 10\n",
      "Model Number: 101 with model UnobservedComponents in generation 0 of 10\n",
      "Model Number: 102 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 102: GluonTS\n",
      "Model Number: 103 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 104 with model UnobservedComponents in generation 0 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 104: UnobservedComponents\n",
      "Model Number: 105 with model NVAR in generation 0 of 10\n",
      "Model Number: 106 with model FBProphet in generation 0 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 106: FBProphet\n",
      "Model Number: 107 with model Theta in generation 0 of 10\n",
      "Model Number: 108 with model UnobservedComponents in generation 0 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 108: UnobservedComponents\n",
      "Model Number: 109 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 109: VECM\n",
      "Model Number: 110 with model MultivariateRegression in generation 0 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'lightgbm'\") in model 110: MultivariateRegression\n",
      "Model Number: 111 with model MultivariateMotif in generation 0 of 10\n",
      "Model Number: 112 with model DatepartRegression in generation 0 of 10\n",
      "Epoch 1/100\n",
      "4/4 [==============================] - 4s 115ms/step - loss: 2256.0593 - val_loss: 2156.4600\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2255.4434 - val_loss: 2155.5403\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 16ms/step - loss: 2254.8931 - val_loss: 2154.8193\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 17ms/step - loss: 2254.2271 - val_loss: 2154.1072\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2253.8784 - val_loss: 2153.4302\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2253.5200 - val_loss: 2152.6870\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2253.3281 - val_loss: 2152.0735\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2252.9761 - val_loss: 2151.2847\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2252.4783 - val_loss: 2150.7346\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2252.2185 - val_loss: 2150.0286\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2251.8413 - val_loss: 2149.3635\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2251.1873 - val_loss: 2148.5442\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2250.8555 - val_loss: 2147.7871\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2250.5527 - val_loss: 2146.9170\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2250.1733 - val_loss: 2146.1504\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2249.4099 - val_loss: 2145.3979\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2249.4531 - val_loss: 2144.4792\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2248.2063 - val_loss: 2143.4812\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2248.2197 - val_loss: 2142.3499\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2247.3184 - val_loss: 2141.2334\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2247.0806 - val_loss: 2140.0630\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2246.0784 - val_loss: 2138.8630\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2245.7683 - val_loss: 2138.1011\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2244.7185 - val_loss: 2137.3594\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2244.1934 - val_loss: 2136.3962\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2243.4836 - val_loss: 2135.4822\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2243.4165 - val_loss: 2134.0676\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2242.6626 - val_loss: 2133.0903\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2242.3892 - val_loss: 2131.7573\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2241.4314 - val_loss: 2130.5950\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2240.5410 - val_loss: 2129.3257\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2240.2832 - val_loss: 2128.0081\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2239.3435 - val_loss: 2126.7549\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2238.8420 - val_loss: 2125.0952\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2237.1621 - val_loss: 2124.0547\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2236.7683 - val_loss: 2122.4434\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2236.8474 - val_loss: 2120.9536\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2235.7825 - val_loss: 2119.2678\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2234.3040 - val_loss: 2117.9587\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2233.1719 - val_loss: 2116.3376\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2232.5464 - val_loss: 2114.9199\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2232.7761 - val_loss: 2113.4822\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2231.4788 - val_loss: 2111.6931\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2229.9338 - val_loss: 2109.7068\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2229.9092 - val_loss: 2107.7256\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2228.2627 - val_loss: 2105.7283\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2227.1599 - val_loss: 2103.5833\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2225.6467 - val_loss: 2102.0491\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2225.7488 - val_loss: 2100.1670\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2224.1084 - val_loss: 2098.2170\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2222.0317 - val_loss: 2095.8035\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2221.5249 - val_loss: 2094.0500\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2221.4084 - val_loss: 2091.8660\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2219.9026 - val_loss: 2089.9778\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2217.3577 - val_loss: 2088.6741\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2217.1211 - val_loss: 2086.9341\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2218.7266 - val_loss: 2085.7358\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2216.0276 - val_loss: 2084.5857\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2216.5681 - val_loss: 2083.2261\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2216.2725 - val_loss: 2082.0864\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2215.4128 - val_loss: 2081.1006\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2213.9595 - val_loss: 2080.5022\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2213.6497 - val_loss: 2079.9902\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2213.9180 - val_loss: 2079.1655\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2212.5693 - val_loss: 2078.5142\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2213.4685 - val_loss: 2077.8706\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2212.8923 - val_loss: 2077.3926\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2211.5886 - val_loss: 2077.0354\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2212.5894 - val_loss: 2076.7290\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2212.6565 - val_loss: 2076.1802\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2211.5981 - val_loss: 2075.9458\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2212.2510 - val_loss: 2075.7085\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2209.8752 - val_loss: 2075.1375\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2209.1323 - val_loss: 2074.8315\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2211.5608 - val_loss: 2074.6318\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2208.7366 - val_loss: 2074.1794\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2211.1428 - val_loss: 2073.8699\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2206.8948 - val_loss: 2073.4504\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2208.8271 - val_loss: 2072.7930\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2209.0242 - val_loss: 2072.3606\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2206.4705 - val_loss: 2071.9922\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2208.6931 - val_loss: 2071.6763\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2207.0322 - val_loss: 2071.3423\n",
      "Epoch 84/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2206.4106 - val_loss: 2070.8542\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2205.5022 - val_loss: 2070.3818\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2204.2717 - val_loss: 2070.0264\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2206.1021 - val_loss: 2069.8127\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2205.2378 - val_loss: 2069.5342\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2204.4441 - val_loss: 2069.3918\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2203.9380 - val_loss: 2069.0605\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2202.8105 - val_loss: 2068.5847\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2200.4995 - val_loss: 2068.1006\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2203.3589 - val_loss: 2067.7124\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2204.2969 - val_loss: 2067.5554\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2198.4133 - val_loss: 2067.0608\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2200.3374 - val_loss: 2066.7354\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2200.8279 - val_loss: 2066.4988\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2202.7239 - val_loss: 2066.2717\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 15ms/step - loss: 2200.3716 - val_loss: 2065.8208\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 14ms/step - loss: 2201.8020 - val_loss: 2065.3762\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 112: DatepartRegression\n",
      "Model Number: 113 with model ZeroesNaive in generation 0 of 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 114 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 115 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 115: GluonTS\n",
      "Model Number: 116 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 117 with model GLS in generation 0 of 10\n",
      "Model Number: 118 with model AverageValueNaive in generation 0 of 10\n",
      "Model Number: 119 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 120 with model NVAR in generation 0 of 10\n",
      "Model Number: 121 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 121: VECM\n",
      "Model Number: 122 with model MultivariateMotif in generation 0 of 10\n",
      "Model Number: 123 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 124 with model ARDL in generation 0 of 10\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 124: ARDL\n",
      "Model Number: 125 with model MultivariateMotif in generation 0 of 10\n",
      "Model Number: 126 with model FBProphet in generation 0 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 126: FBProphet\n",
      "Model Number: 127 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 127: VAR\n",
      "Model Number: 128 with model GluonTS in generation 0 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 128: GluonTS\n",
      "Model Number: 129 with model MultivariateMotif in generation 0 of 10\n",
      "Model Number: 130 with model Theta in generation 0 of 10\n",
      "Model Number: 131 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 131: VAR\n",
      "Model Number: 132 with model NVAR in generation 0 of 10\n",
      "Model Number: 133 with model Theta in generation 0 of 10\n",
      "Model Number: 134 with model DatepartRegression in generation 0 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 134: DatepartRegression\n",
      "Model Number: 135 with model Theta in generation 0 of 10\n",
      "Model Number: 136 with model MultivariateRegression in generation 0 of 10\n",
      "Model Number: 137 with model LastValueNaive in generation 0 of 10\n",
      "Model Number: 138 with model GLM in generation 0 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 138: GLM\n",
      "Model Number: 139 with model UnivariateMotif in generation 0 of 10\n",
      "Model Number: 140 with model VAR in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 140: VAR\n",
      "Model Number: 141 with model ETS in generation 0 of 10\n",
      "Model Number: 142 with model VECM in generation 0 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 142: VECM\n",
      "Model Number: 143 with model SeasonalNaive in generation 0 of 10\n",
      "Model Number: 144 with model GLM in generation 0 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 144: GLM\n",
      "New Generation: 1 of 10\n",
      "Model Number: 145 with model UnivariateMotif in generation 1 of 10\n",
      "Model Number: 146 with model UnivariateMotif in generation 1 of 10\n",
      "Model Number: 147 with model UnivariateMotif in generation 1 of 10\n",
      "Model Number: 148 with model UnivariateMotif in generation 1 of 10\n",
      "Model Number: 149 with model MultivariateMotif in generation 1 of 10\n",
      "Model Number: 150 with model MultivariateMotif in generation 1 of 10\n",
      "Model Number: 151 with model MultivariateMotif in generation 1 of 10\n",
      "Model Number: 152 with model MultivariateMotif in generation 1 of 10\n",
      "Model Number: 153 with model NVAR in generation 1 of 10\n",
      "Model Number: 154 with model NVAR in generation 1 of 10\n",
      "Model Number: 155 with model NVAR in generation 1 of 10\n",
      "Model Number: 156 with model NVAR in generation 1 of 10\n",
      "Model Number: 157 with model SectionalMotif in generation 1 of 10\n",
      "Model Number: 158 with model SectionalMotif in generation 1 of 10\n",
      "Model Number: 159 with model SectionalMotif in generation 1 of 10\n",
      "Model Number: 160 with model SectionalMotif in generation 1 of 10\n",
      "Model Number: 161 with model Theta in generation 1 of 10\n",
      "Model Number: 162 with model Theta in generation 1 of 10\n",
      "Model Number: 163 with model Theta in generation 1 of 10\n",
      "Model Number: 164 with model Theta in generation 1 of 10\n",
      "Model Number: 165 with model AverageValueNaive in generation 1 of 10\n",
      "Model Number: 166 with model AverageValueNaive in generation 1 of 10\n",
      "Model Number: 167 with model AverageValueNaive in generation 1 of 10\n",
      "Model Number: 168 with model ZeroesNaive in generation 1 of 10\n",
      "Model Number: 169 with model ZeroesNaive in generation 1 of 10\n",
      "Template Eval Error: Exception('Transformer QuantileTransformer failed on fit') in model 169: ZeroesNaive\n",
      "Model Number: 170 with model ZeroesNaive in generation 1 of 10\n",
      "Model Number: 171 with model LastValueNaive in generation 1 of 10\n",
      "Model Number: 172 with model LastValueNaive in generation 1 of 10\n",
      "Model Number: 173 with model LastValueNaive in generation 1 of 10\n",
      "Model Number: 174 with model UnobservedComponents in generation 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1368: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 175 with model UnobservedComponents in generation 1 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 175: UnobservedComponents\n",
      "Model Number: 176 with model UnobservedComponents in generation 1 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 176: UnobservedComponents\n",
      "Model Number: 177 with model MultivariateRegression in generation 1 of 10\n",
      "Model Number: 178 with model MultivariateRegression in generation 1 of 10\n",
      "Model Number: 179 with model MultivariateRegression in generation 1 of 10\n",
      "Model Number: 180 with model MultivariateRegression in generation 1 of 10\n",
      "Template Eval Error: ValueError(\"Input contains NaN, infinity or a value too large for dtype('float32').\") in model 180: MultivariateRegression\n",
      "Model Number: 181 with model WindowRegression in generation 1 of 10\n",
      "Model Number: 182 with model WindowRegression in generation 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py:2634: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  c = cov(x, y, rowvar, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 183 with model WindowRegression in generation 1 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 183: WindowRegression\n",
      "Model Number: 184 with model GLS in generation 1 of 10\n",
      "Model Number: 185 with model GLS in generation 1 of 10\n",
      "Model Number: 186 with model GLS in generation 1 of 10\n",
      "Model Number: 187 with model DatepartRegression in generation 1 of 10\n",
      "Epoch 1/50\n",
      "4/4 [==============================] - 3s 164ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/50\n",
      "4/4 [==============================] - 0s 69ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "4/4 [==============================] - 0s 64ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "4/4 [==============================] - 0s 66ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "4/4 [==============================] - 0s 74ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "4/4 [==============================] - 0s 78ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "4/4 [==============================] - 0s 78ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "4/4 [==============================] - 0s 73ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "4/4 [==============================] - 0s 79ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "4/4 [==============================] - 0s 76ms/step - loss: nan - val_loss: nan\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 187: DatepartRegression\n",
      "Model Number: 188 with model DatepartRegression in generation 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done 178 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 189 with model DatepartRegression in generation 1 of 10\n",
      "Model Number: 190 with model ETS in generation 1 of 10\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 191 with model ETS in generation 1 of 10\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend ThreadingBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=11)]: Done 178 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=11)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 192 with model ETS in generation 1 of 10\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 193 with model ETS in generation 1 of 10\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 194 with model SeasonalNaive in generation 1 of 10\n",
      "Model Number: 195 with model SeasonalNaive in generation 1 of 10\n",
      "Model Number: 196 with model SeasonalNaive in generation 1 of 10\n",
      "Model Number: 197 with model SeasonalNaive in generation 1 of 10\n",
      "Model Number: 198 with model GLM in generation 1 of 10\n",
      "Model Number: 199 with model GLM in generation 1 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 199: GLM\n",
      "Model Number: 200 with model GLM in generation 1 of 10\n",
      "Model Number: 201 with model GLM in generation 1 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 201: GLM\n",
      "Model Number: 202 with model GluonTS in generation 1 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 202: GluonTS\n",
      "Model Number: 203 with model GluonTS in generation 1 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 203: GluonTS\n",
      "Model Number: 204 with model GluonTS in generation 1 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 204: GluonTS\n",
      "Model Number: 205 with model GluonTS in generation 1 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 205: GluonTS\n",
      "Model Number: 206 with model VAR in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 206: VAR\n",
      "Model Number: 207 with model VAR in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 207: VAR\n",
      "Model Number: 208 with model VAR in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 208: VAR\n",
      "Model Number: 209 with model VAR in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 209: VAR\n",
      "Model Number: 210 with model VECM in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 210: VECM\n",
      "Model Number: 211 with model VECM in generation 1 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 211: VECM\n",
      "Model Number: 212 with model VECM in generation 1 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 212: VECM\n",
      "Model Number: 213 with model VECM in generation 1 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 213: VECM\n",
      "Model Number: 214 with model FBProphet in generation 1 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 214: FBProphet\n",
      "Model Number: 215 with model FBProphet in generation 1 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 215: FBProphet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:293: DomainWarning: The inverse_power link function does not respect the domain of the Gamma family.\n",
      "  warnings.warn((f\"The {type(family.link).__name__} link function \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 216 with model FBProphet in generation 1 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 216: FBProphet\n",
      "Model Number: 217 with model FBProphet in generation 1 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 217: FBProphet\n",
      "Model Number: 218 with model ARDL in generation 1 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 218: ARDL\n",
      "Model Number: 219 with model ARDL in generation 1 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 219: ARDL\n",
      "Model Number: 220 with model ARDL in generation 1 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 220: ARDL\n",
      "Model Number: 221 with model ARDL in generation 1 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 221: ARDL\n",
      "New Generation: 2 of 10\n",
      "Model Number: 222 with model AverageValueNaive in generation 2 of 10\n",
      "Model Number: 223 with model AverageValueNaive in generation 2 of 10\n",
      "Model Number: 224 with model AverageValueNaive in generation 2 of 10\n",
      "Model Number: 225 with model UnivariateMotif in generation 2 of 10\n",
      "Model Number: 226 with model UnivariateMotif in generation 2 of 10\n",
      "Model Number: 227 with model UnivariateMotif in generation 2 of 10\n",
      "Model Number: 228 with model UnivariateMotif in generation 2 of 10\n",
      "Model Number: 229 with model SectionalMotif in generation 2 of 10\n",
      "Model Number: 230 with model SectionalMotif in generation 2 of 10\n",
      "Model Number: 231 with model SectionalMotif in generation 2 of 10\n",
      "Model Number: 232 with model SectionalMotif in generation 2 of 10\n",
      "Model Number: 233 with model MultivariateMotif in generation 2 of 10\n",
      "Model Number: 234 with model MultivariateMotif in generation 2 of 10\n",
      "Model Number: 235 with model MultivariateMotif in generation 2 of 10\n",
      "Model Number: 236 with model MultivariateMotif in generation 2 of 10\n",
      "Model Number: 237 with model NVAR in generation 2 of 10\n",
      "Model Number: 238 with model NVAR in generation 2 of 10\n",
      "Model Number: 239 with model NVAR in generation 2 of 10\n",
      "Model Number: 240 with model NVAR in generation 2 of 10\n",
      "Model Number: 241 with model MultivariateRegression in generation 2 of 10\n",
      "Model Number: 242 with model MultivariateRegression in generation 2 of 10\n",
      "Model Number: 243 with model MultivariateRegression in generation 2 of 10\n",
      "Template Eval Error: ValueError('Loss squared_error is not supported for HistGradientBoostingRegressor. Accepted losses: least_squares, least_absolute_deviation, poisson.') in model 243: MultivariateRegression\n",
      "Model Number: 244 with model MultivariateRegression in generation 2 of 10\n",
      "Model Number: 245 with model LastValueNaive in generation 2 of 10\n",
      "Template Eval Error: Exception('Transformer HPFilter failed on fit') in model 245: LastValueNaive\n",
      "Model Number: 246 with model LastValueNaive in generation 2 of 10\n",
      "Model Number: 247 with model LastValueNaive in generation 2 of 10\n",
      "Template Eval Error: ValueError('Model LastValueNaive returned NaN for one or more series. fail_on_forecast_nan=True') in model 247: LastValueNaive\n",
      "Model Number: 248 with model SeasonalNaive in generation 2 of 10\n",
      "Model Number: 249 with model SeasonalNaive in generation 2 of 10\n",
      "Model Number: 250 with model SeasonalNaive in generation 2 of 10\n",
      "Model Number: 251 with model SeasonalNaive in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1389: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 252 with model Theta in generation 2 of 10\n",
      "Model Number: 253 with model Theta in generation 2 of 10\n",
      "Model Number: 254 with model Theta in generation 2 of 10\n",
      "Model Number: 255 with model Theta in generation 2 of 10\n",
      "Model Number: 256 with model ZeroesNaive in generation 2 of 10\n",
      "Model Number: 257 with model ZeroesNaive in generation 2 of 10\n",
      "Model Number: 258 with model ZeroesNaive in generation 2 of 10\n",
      "Model Number: 259 with model UnobservedComponents in generation 2 of 10\n",
      "Model Number: 260 with model UnobservedComponents in generation 2 of 10\n",
      "Model Number: 261 with model UnobservedComponents in generation 2 of 10\n",
      "Model Number: 262 with model DatepartRegression in generation 2 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 262: DatepartRegression\n",
      "Model Number: 263 with model DatepartRegression in generation 2 of 10\n",
      "Model Number: 264 with model DatepartRegression in generation 2 of 10\n",
      "Model Number: 265 with model GLS in generation 2 of 10\n",
      "Model Number: 266 with model GLS in generation 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 903388402.304602, tolerance: 183003.16776380903\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 267 with model GLS in generation 2 of 10\n",
      "Model Number: 268 with model WindowRegression in generation 2 of 10\n",
      "Template Eval Error: ValueError('Model WindowRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 268: WindowRegression\n",
      "Model Number: 269 with model WindowRegression in generation 2 of 10\n",
      "Model Number: 270 with model WindowRegression in generation 2 of 10\n",
      "Template Eval Error: ValueError('Some value(s) of y are out of the valid range for family PoissonDistribution') in model 270: WindowRegression\n",
      "Model Number: 271 with model ETS in generation 2 of 10\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 272 with model ETS in generation 2 of 10\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:421: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 273 with model ETS in generation 2 of 10\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 274 with model ETS in generation 2 of 10\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 275 with model GLM in generation 2 of 10\n",
      "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 275: GLM\n",
      "Model Number: 276 with model GLM in generation 2 of 10\n",
      "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 276: GLM\n",
      "Model Number: 277 with model GLM in generation 2 of 10\n",
      "Model Number: 278 with model GLM in generation 2 of 10\n",
      "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 278: GLM\n",
      "Model Number: 279 with model GluonTS in generation 2 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 279: GluonTS\n",
      "Model Number: 280 with model GluonTS in generation 2 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 280: GluonTS\n",
      "Model Number: 281 with model GluonTS in generation 2 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 281: GluonTS\n",
      "Model Number: 282 with model GluonTS in generation 2 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 282: GluonTS\n",
      "Model Number: 283 with model VAR in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 283: VAR\n",
      "Model Number: 284 with model VAR in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 284: VAR\n",
      "Model Number: 285 with model VAR in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 285: VAR\n",
      "Model Number: 286 with model VAR in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 286: VAR\n",
      "Model Number: 287 with model VECM in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 287: VECM\n",
      "Model Number: 288 with model VECM in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 288: VECM\n",
      "Model Number: 289 with model VECM in generation 2 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 289: VECM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 290 with model VECM in generation 2 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 290: VECM\n",
      "Model Number: 291 with model FBProphet in generation 2 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 291: FBProphet\n",
      "Model Number: 292 with model FBProphet in generation 2 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 292: FBProphet\n",
      "Model Number: 293 with model FBProphet in generation 2 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 293: FBProphet\n",
      "Model Number: 294 with model FBProphet in generation 2 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 294: FBProphet\n",
      "Model Number: 295 with model ARDL in generation 2 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 295: ARDL\n",
      "Model Number: 296 with model ARDL in generation 2 of 10\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 296: ARDL\n",
      "Model Number: 297 with model ARDL in generation 2 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 297: ARDL\n",
      "Model Number: 298 with model ARDL in generation 2 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 298: ARDL\n",
      "New Generation: 3 of 10\n",
      "Model Number: 299 with model UnivariateMotif in generation 3 of 10\n",
      "Model Number: 300 with model UnivariateMotif in generation 3 of 10\n",
      "Model Number: 301 with model UnivariateMotif in generation 3 of 10\n",
      "Model Number: 302 with model UnivariateMotif in generation 3 of 10\n",
      "Model Number: 303 with model AverageValueNaive in generation 3 of 10\n",
      "Model Number: 304 with model AverageValueNaive in generation 3 of 10\n",
      "Model Number: 305 with model AverageValueNaive in generation 3 of 10\n",
      "Model Number: 306 with model GLM in generation 3 of 10\n",
      "Model Number: 307 with model GLM in generation 3 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 307: GLM\n",
      "Model Number: 308 with model GLM in generation 3 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 308: GLM\n",
      "Model Number: 309 with model GLM in generation 3 of 10\n",
      "Model Number: 310 with model MultivariateRegression in generation 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 311 with model MultivariateRegression in generation 3 of 10\n",
      "Model Number: 312 with model MultivariateRegression in generation 3 of 10\n",
      "Model Number: 313 with model MultivariateRegression in generation 3 of 10\n",
      "Model Number: 314 with model ZeroesNaive in generation 3 of 10\n",
      "Model Number: 315 with model ZeroesNaive in generation 3 of 10\n",
      "Model Number: 316 with model SectionalMotif in generation 3 of 10\n",
      "Model Number: 317 with model SectionalMotif in generation 3 of 10\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (51)') in model 317: SectionalMotif\n",
      "Model Number: 318 with model SectionalMotif in generation 3 of 10\n",
      "Model Number: 319 with model SectionalMotif in generation 3 of 10\n",
      "Model Number: 320 with model NVAR in generation 3 of 10\n",
      "Model Number: 321 with model NVAR in generation 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\autots\\tools\\probabilistic.py:57: RuntimeWarning: invalid value encountered in true_divide\n",
      "  (prior_mu / prior_sigma ** 2) + ((n * data_mu) / prior_sigma ** 2)\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\autots\\tools\\probabilistic.py:58: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  ) / ((1 / prior_sigma ** 2) + (n / prior_sigma ** 2))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 322 with model NVAR in generation 3 of 10\n",
      "Model Number: 323 with model NVAR in generation 3 of 10\n",
      "Model Number: 324 with model DatepartRegression in generation 3 of 10\n",
      "Model Number: 325 with model DatepartRegression in generation 3 of 10\n",
      "Model Number: 326 with model DatepartRegression in generation 3 of 10\n",
      "Model Number: 327 with model MultivariateMotif in generation 3 of 10\n",
      "Model Number: 328 with model MultivariateMotif in generation 3 of 10\n",
      "Model Number: 329 with model MultivariateMotif in generation 3 of 10\n",
      "Model Number: 330 with model MultivariateMotif in generation 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 331 with model LastValueNaive in generation 3 of 10\n",
      "Model Number: 332 with model LastValueNaive in generation 3 of 10\n",
      "Model Number: 333 with model LastValueNaive in generation 3 of 10\n",
      "Model Number: 334 with model Theta in generation 3 of 10\n",
      "Model Number: 335 with model Theta in generation 3 of 10\n",
      "Model Number: 336 with model Theta in generation 3 of 10\n",
      "Model Number: 337 with model Theta in generation 3 of 10\n",
      "Model Number: 338 with model SeasonalNaive in generation 3 of 10\n",
      "Model Number: 339 with model SeasonalNaive in generation 3 of 10\n",
      "Model Number: 340 with model SeasonalNaive in generation 3 of 10\n",
      "Model Number: 341 with model SeasonalNaive in generation 3 of 10\n",
      "Model Number: 342 with model UnobservedComponents in generation 3 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 342: UnobservedComponents\n",
      "Model Number: 343 with model UnobservedComponents in generation 3 of 10\n",
      "Model Number: 344 with model UnobservedComponents in generation 3 of 10\n",
      "Model Number: 345 with model GLS in generation 3 of 10\n",
      "Model Number: 346 with model GLS in generation 3 of 10\n",
      "Model Number: 347 with model GLS in generation 3 of 10\n",
      "Model Number: 348 with model WindowRegression in generation 3 of 10\n",
      "Model Number: 349 with model WindowRegression in generation 3 of 10\n",
      "Model Number: 350 with model WindowRegression in generation 3 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 350: WindowRegression\n",
      "Model Number: 351 with model ETS in generation 3 of 10\n",
      "Model Number: 352 with model ETS in generation 3 of 10\n",
      "Model Number: 353 with model ETS in generation 3 of 10\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 354 with model ETS in generation 3 of 10\n",
      "Model Number: 355 with model GluonTS in generation 3 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 355: GluonTS\n",
      "Model Number: 356 with model GluonTS in generation 3 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 356: GluonTS\n",
      "Model Number: 357 with model GluonTS in generation 3 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 357: GluonTS\n",
      "Model Number: 358 with model GluonTS in generation 3 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 358: GluonTS\n",
      "Model Number: 359 with model VAR in generation 3 of 10\n",
      "Template Eval Error: IndexError('tuple index out of range') in model 359: VAR\n",
      "Model Number: 360 with model VAR in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 360: VAR\n",
      "Model Number: 361 with model VAR in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 361: VAR\n",
      "Model Number: 362 with model VAR in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 362: VAR\n",
      "Model Number: 363 with model VECM in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 363: VECM\n",
      "Model Number: 364 with model VECM in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 364: VECM\n",
      "Model Number: 365 with model VECM in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 365: VECM\n",
      "Model Number: 366 with model VECM in generation 3 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 366: VECM\n",
      "Model Number: 367 with model FBProphet in generation 3 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 367: FBProphet\n",
      "Model Number: 368 with model FBProphet in generation 3 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 368: FBProphet\n",
      "Model Number: 369 with model FBProphet in generation 3 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 369: FBProphet\n",
      "Model Number: 370 with model FBProphet in generation 3 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 370: FBProphet\n",
      "Model Number: 371 with model ARDL in generation 3 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 371: ARDL\n",
      "Model Number: 372 with model ARDL in generation 3 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 372: ARDL\n",
      "Model Number: 373 with model ARDL in generation 3 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 373: ARDL\n",
      "Model Number: 374 with model ARDL in generation 3 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 374: ARDL\n",
      "New Generation: 4 of 10\n",
      "Model Number: 375 with model UnivariateMotif in generation 4 of 10\n",
      "Model Number: 376 with model UnivariateMotif in generation 4 of 10\n",
      "Model Number: 377 with model UnivariateMotif in generation 4 of 10\n",
      "Model Number: 378 with model UnivariateMotif in generation 4 of 10\n",
      "Model Number: 379 with model NVAR in generation 4 of 10\n",
      "Model Number: 380 with model NVAR in generation 4 of 10\n",
      "Model Number: 381 with model NVAR in generation 4 of 10\n",
      "Model Number: 382 with model NVAR in generation 4 of 10\n",
      "Model Number: 383 with model AverageValueNaive in generation 4 of 10\n",
      "Model Number: 384 with model AverageValueNaive in generation 4 of 10\n",
      "Model Number: 385 with model AverageValueNaive in generation 4 of 10\n",
      "Model Number: 386 with model GLM in generation 4 of 10\n",
      "Model Number: 387 with model GLM in generation 4 of 10\n",
      "Model Number: 388 with model GLM in generation 4 of 10\n",
      "Model Number: 389 with model GLM in generation 4 of 10\n",
      "Model Number: 390 with model MultivariateRegression in generation 4 of 10\n",
      "Model Number: 391 with model MultivariateRegression in generation 4 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'lightgbm'\") in model 391: MultivariateRegression\n",
      "Model Number: 392 with model MultivariateRegression in generation 4 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'lightgbm'\") in model 392: MultivariateRegression\n",
      "Model Number: 393 with model MultivariateRegression in generation 4 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but not future_regressor supplied.\") in model 393: MultivariateRegression\n",
      "Model Number: 394 with model ZeroesNaive in generation 4 of 10\n",
      "Model Number: 395 with model ZeroesNaive in generation 4 of 10\n",
      "Model Number: 396 with model ZeroesNaive in generation 4 of 10\n",
      "Model Number: 397 with model SectionalMotif in generation 4 of 10\n",
      "Model Number: 398 with model SectionalMotif in generation 4 of 10\n",
      "Model Number: 399 with model SectionalMotif in generation 4 of 10\n",
      "Model Number: 400 with model SectionalMotif in generation 4 of 10\n",
      "Model Number: 401 with model MultivariateMotif in generation 4 of 10\n",
      "Model Number: 402 with model MultivariateMotif in generation 4 of 10\n",
      "Model Number: 403 with model MultivariateMotif in generation 4 of 10\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (81)') in model 403: MultivariateMotif\n",
      "Model Number: 404 with model MultivariateMotif in generation 4 of 10\n",
      "Model Number: 405 with model DatepartRegression in generation 4 of 10\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 405: DatepartRegression\n",
      "Model Number: 406 with model DatepartRegression in generation 4 of 10\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 406: DatepartRegression\n",
      "Model Number: 407 with model DatepartRegression in generation 4 of 10\n",
      "Model Number: 408 with model LastValueNaive in generation 4 of 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 409 with model LastValueNaive in generation 4 of 10\n",
      "Model Number: 410 with model LastValueNaive in generation 4 of 10\n",
      "Model Number: 411 with model Theta in generation 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:421: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_regression.py:421: UserWarning: One or more samples have no neighbors within specified radius; predicting NaN.\n",
      "  warnings.warn(empty_warning_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 412 with model Theta in generation 4 of 10\n",
      "Model Number: 413 with model Theta in generation 4 of 10\n",
      "Model Number: 414 with model Theta in generation 4 of 10\n",
      "Model Number: 415 with model GLS in generation 4 of 10\n",
      "Model Number: 416 with model GLS in generation 4 of 10\n",
      "Model Number: 417 with model GLS in generation 4 of 10\n",
      "Model Number: 418 with model SeasonalNaive in generation 4 of 10\n",
      "Model Number: 419 with model SeasonalNaive in generation 4 of 10\n",
      "Model Number: 420 with model SeasonalNaive in generation 4 of 10\n",
      "Model Number: 421 with model SeasonalNaive in generation 4 of 10\n",
      "Model Number: 422 with model ETS in generation 4 of 10\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 423 with model ETS in generation 4 of 10\n",
      "ETS error ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "ETS failed on Close with ValueError('endog must be strictly positive when usingmultiplicative trend or seasonal components.')\n",
      "Model Number: 424 with model ETS in generation 4 of 10\n",
      "Model Number: 425 with model ETS in generation 4 of 10\n",
      "Model Number: 426 with model UnobservedComponents in generation 4 of 10\n",
      "Model Number: 427 with model UnobservedComponents in generation 4 of 10\n",
      "Model Number: 428 with model UnobservedComponents in generation 4 of 10\n",
      "Model Number: 429 with model WindowRegression in generation 4 of 10\n",
      "Model Number: 430 with model WindowRegression in generation 4 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 430: WindowRegression\n",
      "Model Number: 431 with model WindowRegression in generation 4 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 431: WindowRegression\n",
      "Model Number: 432 with model GluonTS in generation 4 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 432: GluonTS\n",
      "Model Number: 433 with model GluonTS in generation 4 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 433: GluonTS\n",
      "Model Number: 434 with model GluonTS in generation 4 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 434: GluonTS\n",
      "Model Number: 435 with model VAR in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 435: VAR\n",
      "Model Number: 436 with model VAR in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 436: VAR\n",
      "Model Number: 437 with model VAR in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 437: VAR\n",
      "Model Number: 438 with model VAR in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 438: VAR\n",
      "Model Number: 439 with model VECM in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 439: VECM\n",
      "Model Number: 440 with model VECM in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 440: VECM\n",
      "Model Number: 441 with model VECM in generation 4 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 441: VECM\n",
      "Model Number: 442 with model VECM in generation 4 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 442: VECM\n",
      "Model Number: 443 with model FBProphet in generation 4 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 443: FBProphet\n",
      "Model Number: 444 with model FBProphet in generation 4 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 444: FBProphet\n",
      "Model Number: 445 with model FBProphet in generation 4 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 445: FBProphet\n",
      "Model Number: 446 with model FBProphet in generation 4 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 446: FBProphet\n",
      "Model Number: 447 with model ARDL in generation 4 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 447: ARDL\n",
      "Model Number: 448 with model ARDL in generation 4 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 448: ARDL\n",
      "Model Number: 449 with model ARDL in generation 4 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 449: ARDL\n",
      "Model Number: 450 with model ARDL in generation 4 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 450: ARDL\n",
      "New Generation: 5 of 10\n",
      "Model Number: 451 with model Theta in generation 5 of 10\n",
      "Model Number: 452 with model Theta in generation 5 of 10\n",
      "Model Number: 453 with model Theta in generation 5 of 10\n",
      "Model Number: 454 with model Theta in generation 5 of 10\n",
      "Model Number: 455 with model NVAR in generation 5 of 10\n",
      "Model Number: 456 with model NVAR in generation 5 of 10\n",
      "Model Number: 457 with model NVAR in generation 5 of 10\n",
      "Model Number: 458 with model NVAR in generation 5 of 10\n",
      "Model Number: 459 with model UnivariateMotif in generation 5 of 10\n",
      "Model Number: 460 with model UnivariateMotif in generation 5 of 10\n",
      "Model Number: 461 with model UnivariateMotif in generation 5 of 10\n",
      "Model Number: 462 with model UnivariateMotif in generation 5 of 10\n",
      "Model Number: 463 with model AverageValueNaive in generation 5 of 10\n",
      "Model Number: 464 with model AverageValueNaive in generation 5 of 10\n",
      "Model Number: 465 with model AverageValueNaive in generation 5 of 10\n",
      "Template Eval Error: ValueError('Model AverageValueNaive returned NaN for one or more series. fail_on_forecast_nan=True') in model 465: AverageValueNaive\n",
      "Model Number: 466 with model GLM in generation 5 of 10\n",
      "Model Number: 467 with model GLM in generation 5 of 10\n",
      "Model Number: 468 with model GLM in generation 5 of 10\n",
      "Model Number: 469 with model GLM in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1389: RuntimeWarning: All-NaN slice encountered\n",
      "  result = np.apply_along_axis(_nanquantile_1d, axis, a, q,\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1444: RuntimeWarning: invalid value encountered in log\n",
      "  endog * np.log(endog / mu) + (mu - endog))\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 470 with model MultivariateRegression in generation 5 of 10\n",
      "Template Eval Error: Exception('Transformer MaxAbsScaler failed on fit') in model 470: MultivariateRegression\n",
      "Model Number: 471 with model MultivariateRegression in generation 5 of 10\n",
      "Model Number: 472 with model MultivariateRegression in generation 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:1078: RuntimeWarning: All-NaN slice encountered\n",
      "  max_abs = np.nanmax(np.abs(X), axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 473 with model MultivariateRegression in generation 5 of 10\n",
      "Model Number: 474 with model MultivariateMotif in generation 5 of 10\n",
      "Model Number: 475 with model MultivariateMotif in generation 5 of 10\n",
      "Model Number: 476 with model MultivariateMotif in generation 5 of 10\n",
      "Model Number: 477 with model MultivariateMotif in generation 5 of 10\n",
      "Model Number: 478 with model ZeroesNaive in generation 5 of 10\n",
      "Model Number: 479 with model ZeroesNaive in generation 5 of 10\n",
      "Model Number: 480 with model SeasonalNaive in generation 5 of 10\n",
      "Model Number: 481 with model SeasonalNaive in generation 5 of 10\n",
      "Model Number: 482 with model SeasonalNaive in generation 5 of 10\n",
      "Model Number: 483 with model SeasonalNaive in generation 5 of 10\n",
      "Model Number: 484 with model DatepartRegression in generation 5 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 484: DatepartRegression\n",
      "Model Number: 485 with model DatepartRegression in generation 5 of 10\n",
      "Model Number: 486 with model DatepartRegression in generation 5 of 10\n",
      "Model Number: 487 with model SectionalMotif in generation 5 of 10\n",
      "Template Eval Error: ValueError('kth(=100) out of bounds (25)') in model 487: SectionalMotif\n",
      "Model Number: 488 with model SectionalMotif in generation 5 of 10\n",
      "Model Number: 489 with model SectionalMotif in generation 5 of 10\n",
      "Model Number: 490 with model SectionalMotif in generation 5 of 10\n",
      "Model Number: 491 with model LastValueNaive in generation 5 of 10\n",
      "Model Number: 492 with model LastValueNaive in generation 5 of 10\n",
      "Model Number: 493 with model GLS in generation 5 of 10\n",
      "Model Number: 494 with model GLS in generation 5 of 10\n",
      "Model Number: 495 with model GLS in generation 5 of 10\n",
      "Model Number: 496 with model ETS in generation 5 of 10\n",
      "Model Number: 497 with model ETS in generation 5 of 10\n",
      "Model Number: 498 with model ETS in generation 5 of 10\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
      "Model Number: 499 with model ETS in generation 5 of 10\n",
      "Model Number: 500 with model UnobservedComponents in generation 5 of 10\n",
      "Model Number: 501 with model UnobservedComponents in generation 5 of 10\n",
      "Model Number: 502 with model UnobservedComponents in generation 5 of 10\n",
      "Model Number: 503 with model WindowRegression in generation 5 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 503: WindowRegression\n",
      "Model Number: 504 with model WindowRegression in generation 5 of 10\n",
      "Model Number: 505 with model WindowRegression in generation 5 of 10\n",
      "Model Number: 506 with model GluonTS in generation 5 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 506: GluonTS\n",
      "Model Number: 507 with model GluonTS in generation 5 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 507: GluonTS\n",
      "Model Number: 508 with model GluonTS in generation 5 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 508: GluonTS\n",
      "Model Number: 509 with model GluonTS in generation 5 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 509: GluonTS\n",
      "Model Number: 510 with model VAR in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 510: VAR\n",
      "Model Number: 511 with model VAR in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 511: VAR\n",
      "Model Number: 512 with model VAR in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 512: VAR\n",
      "Model Number: 513 with model VAR in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 513: VAR\n",
      "Model Number: 514 with model VECM in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 514: VECM\n",
      "Model Number: 515 with model VECM in generation 5 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 515: VECM\n",
      "Model Number: 516 with model VECM in generation 5 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 516: VECM\n",
      "Model Number: 517 with model VECM in generation 5 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 517: VECM\n",
      "Model Number: 518 with model FBProphet in generation 5 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 518: FBProphet\n",
      "Model Number: 519 with model FBProphet in generation 5 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 519: FBProphet\n",
      "Model Number: 520 with model FBProphet in generation 5 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 520: FBProphet\n",
      "Model Number: 521 with model FBProphet in generation 5 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 521: FBProphet\n",
      "Model Number: 522 with model ARDL in generation 5 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 522: ARDL\n",
      "Model Number: 523 with model ARDL in generation 5 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 523: ARDL\n",
      "Model Number: 524 with model ARDL in generation 5 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 524: ARDL\n",
      "Model Number: 525 with model ARDL in generation 5 of 10\n",
      "Template Eval Error: Exception('Transformer RobustScaler failed on fit') in model 525: ARDL\n",
      "New Generation: 6 of 10\n",
      "Model Number: 526 with model Theta in generation 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1113: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1368: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 527 with model Theta in generation 6 of 10\n",
      "Model Number: 528 with model Theta in generation 6 of 10\n",
      "Model Number: 529 with model NVAR in generation 6 of 10\n",
      "Model Number: 530 with model NVAR in generation 6 of 10\n",
      "Model Number: 531 with model NVAR in generation 6 of 10\n",
      "Model Number: 532 with model NVAR in generation 6 of 10\n",
      "Model Number: 533 with model UnivariateMotif in generation 6 of 10\n",
      "Model Number: 534 with model UnivariateMotif in generation 6 of 10\n",
      "Template Eval Error: Exception('Transformer HPFilter failed on fit') in model 534: UnivariateMotif\n",
      "Model Number: 535 with model UnivariateMotif in generation 6 of 10\n",
      "Model Number: 536 with model UnivariateMotif in generation 6 of 10\n",
      "Model Number: 537 with model AverageValueNaive in generation 6 of 10\n",
      "Model Number: 538 with model AverageValueNaive in generation 6 of 10\n",
      "Model Number: 539 with model GLM in generation 6 of 10\n",
      "Template Eval Error: ValueError('regression_type=user and no future_regressor passed') in model 539: GLM\n",
      "Model Number: 540 with model GLM in generation 6 of 10\n",
      "Template Eval Error: ValueError('NaN, inf or invalid value detected in weights, estimation infeasible.') in model 540: GLM\n",
      "Model Number: 541 with model GLM in generation 6 of 10\n",
      "Model Number: 542 with model MultivariateRegression in generation 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1444: RuntimeWarning: invalid value encountered in log\n",
      "  endog * np.log(endog / mu) + (mu - endog))\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1444: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  endog * np.log(endog / mu) + (mu - endog))\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\generalized_linear_model.py:798: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return np.sum(resid / self.family.variance(mu)) / self.df_resid\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:134: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1. / (self.link.deriv(mu)**2 * self.variance(mu))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 543 with model MultivariateRegression in generation 6 of 10\n",
      "Model Number: 544 with model MultivariateRegression in generation 6 of 10\n",
      "Model Number: 545 with model MultivariateRegression in generation 6 of 10\n",
      "Model Number: 546 with model MultivariateMotif in generation 6 of 10\n",
      "Model Number: 547 with model MultivariateMotif in generation 6 of 10\n",
      "Model Number: 548 with model MultivariateMotif in generation 6 of 10\n",
      "Model Number: 549 with model MultivariateMotif in generation 6 of 10\n",
      "Model Number: 550 with model ZeroesNaive in generation 6 of 10\n",
      "Model Number: 551 with model ZeroesNaive in generation 6 of 10\n",
      "Model Number: 552 with model ZeroesNaive in generation 6 of 10\n",
      "Model Number: 553 with model SeasonalNaive in generation 6 of 10\n",
      "Model Number: 554 with model SeasonalNaive in generation 6 of 10\n",
      "Model Number: 555 with model SeasonalNaive in generation 6 of 10\n",
      "Model Number: 556 with model SeasonalNaive in generation 6 of 10\n",
      "Model Number: 557 with model DatepartRegression in generation 6 of 10\n",
      "Model Number: 558 with model DatepartRegression in generation 6 of 10\n",
      "Epoch 1/50\n",
      "14/14 [==============================] - 1s 12ms/step - loss: 288.3755 - val_loss: 152.3786\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 443.4152 - val_loss: 147.2449\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 256.3064 - val_loss: 141.4932\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 449.2196 - val_loss: 134.4418\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 239.9274 - val_loss: 134.5423\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 691.8464 - val_loss: 131.2916\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 346.1065 - val_loss: 127.3849\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 789.9539 - val_loss: 120.9866\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 523.4872 - val_loss: 116.2221\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 461.7461 - val_loss: 113.8302\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 454.6037 - val_loss: 110.2826\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 357.0605 - val_loss: 109.0368\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 277.5517 - val_loss: 108.0557\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 174.1661 - val_loss: 108.6758\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 392.6626 - val_loss: 106.2350\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 409.1685 - val_loss: 108.6130\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 390.8234 - val_loss: 105.9472\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 548.5803 - val_loss: 104.0821\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 258.0232 - val_loss: 100.6777\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 179.3671 - val_loss: 102.1064\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 373.1243 - val_loss: 100.4945\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 261.5447 - val_loss: 99.1184\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 352.9099 - val_loss: 98.8071\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 266.2937 - val_loss: 99.9019\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 372.2805 - val_loss: 100.0769\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 210.1533 - val_loss: 98.6871\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 390.2689 - val_loss: 98.6551\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 178.5247 - val_loss: 99.5507\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 293.5156 - val_loss: 100.4842\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 268.5546 - val_loss: 101.3210\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 258.5443 - val_loss: 102.3573\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 631.6716 - val_loss: 102.6838\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 285.6020 - val_loss: 102.8211\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 414.0984 - val_loss: 100.9097\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 277.1750 - val_loss: 100.4869\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 535.4819 - val_loss: 100.5763\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 274.7256 - val_loss: 100.8165\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B776F843A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 558: DatepartRegression\n",
      "Model Number: 559 with model DatepartRegression in generation 6 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 559: DatepartRegression\n",
      "Model Number: 560 with model SectionalMotif in generation 6 of 10\n",
      "Model Number: 561 with model SectionalMotif in generation 6 of 10\n",
      "Model Number: 562 with model SectionalMotif in generation 6 of 10\n",
      "Model Number: 563 with model SectionalMotif in generation 6 of 10\n",
      "Model Number: 564 with model LastValueNaive in generation 6 of 10\n",
      "Model Number: 565 with model LastValueNaive in generation 6 of 10\n",
      "Model Number: 566 with model LastValueNaive in generation 6 of 10\n",
      "Model Number: 567 with model GLS in generation 6 of 10\n",
      "Model Number: 568 with model GLS in generation 6 of 10\n",
      "Model Number: 569 with model GLS in generation 6 of 10\n",
      "Model Number: 570 with model ETS in generation 6 of 10\n",
      "Model Number: 571 with model ETS in generation 6 of 10\n",
      "Model Number: 572 with model ETS in generation 6 of 10\n",
      "Model Number: 573 with model ETS in generation 6 of 10\n",
      "Model Number: 574 with model UnobservedComponents in generation 6 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 574: UnobservedComponents\n",
      "Model Number: 575 with model UnobservedComponents in generation 6 of 10\n",
      "Model Number: 576 with model UnobservedComponents in generation 6 of 10\n",
      "Model Number: 577 with model WindowRegression in generation 6 of 10\n",
      "Model Number: 578 with model WindowRegression in generation 6 of 10\n",
      "Model Number: 579 with model WindowRegression in generation 6 of 10\n",
      "Model Number: 580 with model GluonTS in generation 6 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 580: GluonTS\n",
      "Model Number: 581 with model GluonTS in generation 6 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 581: GluonTS\n",
      "Model Number: 582 with model GluonTS in generation 6 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 582: GluonTS\n",
      "Model Number: 583 with model GluonTS in generation 6 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 583: GluonTS\n",
      "Model Number: 584 with model VAR in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 584: VAR\n",
      "Model Number: 585 with model VAR in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 585: VAR\n",
      "Model Number: 586 with model VAR in generation 6 of 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 586: VAR\n",
      "Model Number: 587 with model VAR in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 587: VAR\n",
      "Model Number: 588 with model VECM in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 588: VECM\n",
      "Model Number: 589 with model VECM in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 589: VECM\n",
      "Model Number: 590 with model VECM in generation 6 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 590: VECM\n",
      "Model Number: 591 with model VECM in generation 6 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 591: VECM\n",
      "Model Number: 592 with model FBProphet in generation 6 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 592: FBProphet\n",
      "Model Number: 593 with model FBProphet in generation 6 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 593: FBProphet\n",
      "Model Number: 594 with model FBProphet in generation 6 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 594: FBProphet\n",
      "Model Number: 595 with model FBProphet in generation 6 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 595: FBProphet\n",
      "Model Number: 596 with model ARDL in generation 6 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 596: ARDL\n",
      "Model Number: 597 with model ARDL in generation 6 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 597: ARDL\n",
      "Model Number: 598 with model ARDL in generation 6 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 598: ARDL\n",
      "Model Number: 599 with model ARDL in generation 6 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 599: ARDL\n",
      "New Generation: 7 of 10\n",
      "Model Number: 600 with model Theta in generation 7 of 10\n",
      "Model Number: 601 with model Theta in generation 7 of 10\n",
      "Model Number: 602 with model Theta in generation 7 of 10\n",
      "Model Number: 603 with model NVAR in generation 7 of 10\n",
      "Model Number: 604 with model NVAR in generation 7 of 10\n",
      "Model Number: 605 with model NVAR in generation 7 of 10\n",
      "Model Number: 606 with model NVAR in generation 7 of 10\n",
      "Model Number: 607 with model UnivariateMotif in generation 7 of 10\n",
      "Model Number: 608 with model UnivariateMotif in generation 7 of 10\n",
      "Model Number: 609 with model UnivariateMotif in generation 7 of 10\n",
      "Model Number: 610 with model UnivariateMotif in generation 7 of 10\n",
      "Model Number: 611 with model AverageValueNaive in generation 7 of 10\n",
      "Template Eval Error: Exception('Transformer MinMaxScaler failed on fit') in model 611: AverageValueNaive\n",
      "Model Number: 612 with model AverageValueNaive in generation 7 of 10\n",
      "Model Number: 613 with model AverageValueNaive in generation 7 of 10\n",
      "Template Eval Error: Exception('Transformer HPFilter failed on fit') in model 613: AverageValueNaive\n",
      "Model Number: 614 with model GLM in generation 7 of 10\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 614: GLM\n",
      "Model Number: 615 with model GLM in generation 7 of 10\n",
      "Model Number: 616 with model GLM in generation 7 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 616: GLM\n",
      "Model Number: 617 with model GLM in generation 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:400: RuntimeWarning: All-NaN slice encountered\n",
      "  data_min = np.nanmin(X, axis=0)\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:401: RuntimeWarning: All-NaN slice encountered\n",
      "  data_max = np.nanmax(X, axis=0)\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1231: RuntimeWarning: divide by zero encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1231: RuntimeWarning: invalid value encountered in multiply\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 618 with model SeasonalNaive in generation 7 of 10\n",
      "Model Number: 619 with model SeasonalNaive in generation 7 of 10\n",
      "Model Number: 620 with model SeasonalNaive in generation 7 of 10\n",
      "Model Number: 621 with model SeasonalNaive in generation 7 of 10\n",
      "Model Number: 622 with model MultivariateRegression in generation 7 of 10\n",
      "Model Number: 623 with model MultivariateRegression in generation 7 of 10\n",
      "Model Number: 624 with model MultivariateRegression in generation 7 of 10\n",
      "Model Number: 625 with model MultivariateRegression in generation 7 of 10\n",
      "Model Number: 626 with model MultivariateMotif in generation 7 of 10\n",
      "Model Number: 627 with model MultivariateMotif in generation 7 of 10\n",
      "Model Number: 628 with model MultivariateMotif in generation 7 of 10\n",
      "Model Number: 629 with model MultivariateMotif in generation 7 of 10\n",
      "Model Number: 630 with model ZeroesNaive in generation 7 of 10\n",
      "Model Number: 631 with model ZeroesNaive in generation 7 of 10\n",
      "Model Number: 632 with model ZeroesNaive in generation 7 of 10\n",
      "Model Number: 633 with model SectionalMotif in generation 7 of 10\n",
      "Model Number: 634 with model SectionalMotif in generation 7 of 10\n",
      "Model Number: 635 with model SectionalMotif in generation 7 of 10\n",
      "Model Number: 636 with model SectionalMotif in generation 7 of 10\n",
      "Model Number: 637 with model DatepartRegression in generation 7 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 637: DatepartRegression\n",
      "Model Number: 638 with model DatepartRegression in generation 7 of 10\n",
      "Epoch 1/50\n",
      "14/14 [==============================] - 3s 28ms/step - loss: nan - val_loss: nan               \n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: nan - val_loss: nan\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001B707198DC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 638: DatepartRegression\n",
      "Model Number: 639 with model DatepartRegression in generation 7 of 10\n",
      "Model Number: 640 with model LastValueNaive in generation 7 of 10\n",
      "Model Number: 641 with model LastValueNaive in generation 7 of 10\n",
      "Model Number: 642 with model GLS in generation 7 of 10\n",
      "Model Number: 643 with model ETS in generation 7 of 10\n",
      "Model Number: 644 with model ETS in generation 7 of 10\n",
      "Model Number: 645 with model ETS in generation 7 of 10\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
      "Model Number: 646 with model ETS in generation 7 of 10\n",
      "Model Number: 647 with model WindowRegression in generation 7 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 647: WindowRegression\n",
      "Model Number: 648 with model WindowRegression in generation 7 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 648: WindowRegression\n",
      "Model Number: 649 with model WindowRegression in generation 7 of 10\n",
      "Model Number: 650 with model UnobservedComponents in generation 7 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 650: UnobservedComponents\n",
      "Model Number: 651 with model UnobservedComponents in generation 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 652 with model UnobservedComponents in generation 7 of 10\n",
      "Template Eval Error: LinAlgError('Singular matrix') in model 652: UnobservedComponents\n",
      "Model Number: 653 with model GluonTS in generation 7 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 653: GluonTS\n",
      "Model Number: 654 with model GluonTS in generation 7 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 654: GluonTS\n",
      "Model Number: 655 with model GluonTS in generation 7 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 655: GluonTS\n",
      "Model Number: 656 with model GluonTS in generation 7 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 656: GluonTS\n",
      "Model Number: 657 with model VAR in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 657: VAR\n",
      "Model Number: 658 with model VAR in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 658: VAR\n",
      "Model Number: 659 with model VAR in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 659: VAR\n",
      "Model Number: 660 with model VAR in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 660: VAR\n",
      "Model Number: 661 with model VECM in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 661: VECM\n",
      "Model Number: 662 with model VECM in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 662: VECM\n",
      "Model Number: 663 with model VECM in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 663: VECM\n",
      "Model Number: 664 with model VECM in generation 7 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 664: VECM\n",
      "Model Number: 665 with model FBProphet in generation 7 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 665: FBProphet\n",
      "Model Number: 666 with model FBProphet in generation 7 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 666: FBProphet\n",
      "Model Number: 667 with model FBProphet in generation 7 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 667: FBProphet\n",
      "Model Number: 668 with model FBProphet in generation 7 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 668: FBProphet\n",
      "Model Number: 669 with model ARDL in generation 7 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 669: ARDL\n",
      "Model Number: 670 with model ARDL in generation 7 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 670: ARDL\n",
      "Model Number: 671 with model ARDL in generation 7 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 671: ARDL\n",
      "Model Number: 672 with model ARDL in generation 7 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 672: ARDL\n",
      "New Generation: 8 of 10\n",
      "Model Number: 673 with model Theta in generation 8 of 10\n",
      "Model Number: 674 with model Theta in generation 8 of 10\n",
      "Model Number: 675 with model Theta in generation 8 of 10\n",
      "Model Number: 676 with model Theta in generation 8 of 10\n",
      "Model Number: 677 with model NVAR in generation 8 of 10\n",
      "Model Number: 678 with model NVAR in generation 8 of 10\n",
      "Model Number: 679 with model NVAR in generation 8 of 10\n",
      "Model Number: 680 with model NVAR in generation 8 of 10\n",
      "Model Number: 681 with model UnivariateMotif in generation 8 of 10\n",
      "Model Number: 682 with model UnivariateMotif in generation 8 of 10\n",
      "Model Number: 683 with model UnivariateMotif in generation 8 of 10\n",
      "Model Number: 684 with model UnivariateMotif in generation 8 of 10\n",
      "Model Number: 685 with model AverageValueNaive in generation 8 of 10\n",
      "Model Number: 686 with model AverageValueNaive in generation 8 of 10\n",
      "Model Number: 687 with model AverageValueNaive in generation 8 of 10\n",
      "Model Number: 688 with model SectionalMotif in generation 8 of 10\n",
      "Model Number: 689 with model SectionalMotif in generation 8 of 10\n",
      "Model Number: 690 with model SectionalMotif in generation 8 of 10\n",
      "Model Number: 691 with model SectionalMotif in generation 8 of 10\n",
      "Model Number: 692 with model GLM in generation 8 of 10\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 692: GLM\n",
      "Model Number: 693 with model GLM in generation 8 of 10\n",
      "Model Number: 694 with model GLM in generation 8 of 10\n",
      "Model Number: 695 with model GLM in generation 8 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 695: GLM\n",
      "Model Number: 696 with model SeasonalNaive in generation 8 of 10\n",
      "Model Number: 697 with model SeasonalNaive in generation 8 of 10\n",
      "Model Number: 698 with model SeasonalNaive in generation 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1231: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 699 with model SeasonalNaive in generation 8 of 10\n",
      "Model Number: 700 with model MultivariateRegression in generation 8 of 10\n",
      "Template Eval Error: ValueError('Loss squared_error is not supported for HistGradientBoostingRegressor. Accepted losses: least_squares, least_absolute_deviation, poisson.') in model 700: MultivariateRegression\n",
      "Model Number: 701 with model MultivariateRegression in generation 8 of 10\n",
      "Model Number: 702 with model MultivariateRegression in generation 8 of 10\n",
      "Model Number: 703 with model MultivariateRegression in generation 8 of 10\n",
      "Model Number: 704 with model MultivariateMotif in generation 8 of 10\n",
      "Model Number: 705 with model MultivariateMotif in generation 8 of 10\n",
      "Model Number: 706 with model MultivariateMotif in generation 8 of 10\n",
      "Model Number: 707 with model MultivariateMotif in generation 8 of 10\n",
      "Model Number: 708 with model ZeroesNaive in generation 8 of 10\n",
      "Model Number: 709 with model ZeroesNaive in generation 8 of 10\n",
      "Model Number: 710 with model ZeroesNaive in generation 8 of 10\n",
      "Model Number: 711 with model DatepartRegression in generation 8 of 10\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 3s 54ms/step - loss: 333.0592 - val_loss: 319.3982\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 308.3938 - val_loss: 297.7844\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 304.0674 - val_loss: 276.3808\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 262.0391 - val_loss: 254.9068\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 261.1376 - val_loss: 233.5813\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 235.2814 - val_loss: 212.5598\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 211.2918 - val_loss: 192.5420\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 196.0249 - val_loss: 172.3784\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 170.7099 - val_loss: 152.5177\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 165.9834 - val_loss: 133.5365\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 144.6099 - val_loss: 115.1314\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 141.5063 - val_loss: 98.3283\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 124.0780 - val_loss: 83.2630\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 119.8803 - val_loss: 69.2839\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 99.2684 - val_loss: 56.6249\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 106.0032 - val_loss: 45.9533\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 116.2335 - val_loss: 37.7836\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 101.0728 - val_loss: 29.6128\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 104.0185 - val_loss: 22.6094\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 103.4376 - val_loss: 17.2021\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 100.6838 - val_loss: 11.9755\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 95.4466 - val_loss: 9.2453\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 100.9876 - val_loss: 7.3250\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 103.7868 - val_loss: 6.2144\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 92.3823 - val_loss: 5.0646\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 106.0177 - val_loss: 4.7416\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 104.5811 - val_loss: 3.8976\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 102.9358 - val_loss: 3.3672\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 93.7788 - val_loss: 3.5360\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 97.4866 - val_loss: 2.7474\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 104.6657 - val_loss: 2.2761\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 104.4298 - val_loss: 1.6209\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 107.3899 - val_loss: 1.4915\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 97.2292 - val_loss: 2.0695\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 98.0580 - val_loss: 2.7224\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 101.3004 - val_loss: 1.9645\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 88.5981 - val_loss: 1.5438\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 88.8100 - val_loss: 1.6043\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 91.5451 - val_loss: 1.5318\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 99.4680 - val_loss: 1.6304\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 89.7611 - val_loss: 1.5918\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 97.6419 - val_loss: 1.5193\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 107.0449 - val_loss: 1.6905\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 711: DatepartRegression\n",
      "Model Number: 712 with model DatepartRegression in generation 8 of 10\n",
      "Epoch 1/500\n",
      "9/9 [==============================] - 4s 5ms/step - loss: 35561.3398\n",
      "Epoch 2/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35558.2812\n",
      "Epoch 3/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35556.8633\n",
      "Epoch 4/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35556.2734\n",
      "Epoch 5/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35555.8984\n",
      "Epoch 6/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35555.6133\n",
      "Epoch 7/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35555.3516\n",
      "Epoch 8/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35555.1055\n",
      "Epoch 9/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35554.8594\n",
      "Epoch 10/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35554.6250\n",
      "Epoch 11/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35554.3828\n",
      "Epoch 12/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35554.1445\n",
      "Epoch 13/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35553.9102\n",
      "Epoch 14/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35553.6758\n",
      "Epoch 15/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35553.4414\n",
      "Epoch 16/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35553.2070\n",
      "Epoch 17/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35552.9727\n",
      "Epoch 18/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35552.7383\n",
      "Epoch 19/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35552.5000\n",
      "Epoch 20/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35552.2695\n",
      "Epoch 21/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35552.0391\n",
      "Epoch 22/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35551.8047\n",
      "Epoch 23/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35551.5703\n",
      "Epoch 24/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35551.3359\n",
      "Epoch 25/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35551.1016\n",
      "Epoch 26/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35550.8672\n",
      "Epoch 27/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35550.6328\n",
      "Epoch 28/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35550.4023\n",
      "Epoch 29/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35550.1680\n",
      "Epoch 30/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35549.9336\n",
      "Epoch 31/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35549.6992\n",
      "Epoch 32/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35549.4609\n",
      "Epoch 33/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35549.2305\n",
      "Epoch 34/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35548.9961\n",
      "Epoch 35/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35548.7617\n",
      "Epoch 36/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35548.5312\n",
      "Epoch 37/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35548.2891\n",
      "Epoch 38/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35548.0586\n",
      "Epoch 39/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35547.8281\n",
      "Epoch 40/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35547.5898\n",
      "Epoch 41/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35547.3555\n",
      "Epoch 42/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35547.1211\n",
      "Epoch 43/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35546.8867\n",
      "Epoch 44/500\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 35546.6523\n",
      "Epoch 45/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35546.4219\n",
      "Epoch 46/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35546.1875\n",
      "Epoch 47/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35545.9570\n",
      "Epoch 48/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35545.7188\n",
      "Epoch 49/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35545.4844\n",
      "Epoch 50/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35545.2500\n",
      "Epoch 51/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35545.0156\n",
      "Epoch 52/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35544.7852\n",
      "Epoch 53/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35544.5508\n",
      "Epoch 54/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35544.3164\n",
      "Epoch 55/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35544.0820\n",
      "Epoch 56/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35543.8477\n",
      "Epoch 57/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35543.6133\n",
      "Epoch 58/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35543.3789\n",
      "Epoch 59/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35543.1484\n",
      "Epoch 60/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35542.9102\n",
      "Epoch 61/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35542.6758\n",
      "Epoch 62/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35542.4414\n",
      "Epoch 63/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35542.2070\n",
      "Epoch 64/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35541.9727\n",
      "Epoch 65/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35541.7422\n",
      "Epoch 66/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35541.5078\n",
      "Epoch 67/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35541.2734\n",
      "Epoch 68/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35541.0391\n",
      "Epoch 69/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35540.8047\n",
      "Epoch 70/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35540.5742\n",
      "Epoch 71/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35540.3398\n",
      "Epoch 72/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35540.1055\n",
      "Epoch 73/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35539.8672\n",
      "Epoch 74/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35539.6367\n",
      "Epoch 75/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35539.3984\n",
      "Epoch 76/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35539.1680\n",
      "Epoch 77/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35538.9336\n",
      "Epoch 78/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35538.6992\n",
      "Epoch 79/500\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 35538.4648\n",
      "Epoch 80/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35538.2344\n",
      "Epoch 81/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35537.9922\n",
      "Epoch 82/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35537.7578\n",
      "Epoch 83/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35537.5273\n",
      "Epoch 84/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35537.2969\n",
      "Epoch 85/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35537.0625\n",
      "Epoch 86/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35536.8242\n",
      "Epoch 87/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35536.5898\n",
      "Epoch 88/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35536.3594\n",
      "Epoch 89/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35536.1250\n",
      "Epoch 90/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35535.8906\n",
      "Epoch 91/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35535.6562\n",
      "Epoch 92/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35535.4258\n",
      "Epoch 93/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35535.1914\n",
      "Epoch 94/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35534.9570\n",
      "Epoch 95/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35534.7188\n",
      "Epoch 96/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35534.4883\n",
      "Epoch 97/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35534.2539\n",
      "Epoch 98/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35534.0234\n",
      "Epoch 99/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35533.7852\n",
      "Epoch 100/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35533.5508\n",
      "Epoch 101/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35533.3164\n",
      "Epoch 102/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35533.0820\n",
      "Epoch 103/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35532.8477\n",
      "Epoch 104/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35532.6172\n",
      "Epoch 105/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35532.3789\n",
      "Epoch 106/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35532.1445\n",
      "Epoch 107/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35531.9141\n",
      "Epoch 108/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35531.6758\n",
      "Epoch 109/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35531.4453\n",
      "Epoch 110/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35531.2148\n",
      "Epoch 111/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35530.9766\n",
      "Epoch 112/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35530.7383\n",
      "Epoch 113/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35530.5039\n",
      "Epoch 114/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35530.2734\n",
      "Epoch 115/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35530.0430\n",
      "Epoch 116/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35529.8086\n",
      "Epoch 117/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35529.5781\n",
      "Epoch 118/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35529.3398\n",
      "Epoch 119/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35529.1055\n",
      "Epoch 120/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35528.8750\n",
      "Epoch 121/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35528.6406\n",
      "Epoch 122/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35528.4062\n",
      "Epoch 123/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35528.1680\n",
      "Epoch 124/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35527.9375\n",
      "Epoch 125/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35527.6992\n",
      "Epoch 126/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35527.4648\n",
      "Epoch 127/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35527.2344\n",
      "Epoch 128/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35526.9961\n",
      "Epoch 129/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35526.7617\n",
      "Epoch 130/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step - loss: 35526.5312\n",
      "Epoch 131/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35526.2969\n",
      "Epoch 132/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35526.0625\n",
      "Epoch 133/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35525.8320\n",
      "Epoch 134/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35525.5938\n",
      "Epoch 135/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35525.3555\n",
      "Epoch 136/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35525.1250\n",
      "Epoch 137/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35524.8945\n",
      "Epoch 138/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35524.6562\n",
      "Epoch 139/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35524.4219\n",
      "Epoch 140/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35524.1914\n",
      "Epoch 141/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35523.9609\n",
      "Epoch 142/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35523.7227\n",
      "Epoch 143/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35523.4883\n",
      "Epoch 144/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35523.2539\n",
      "Epoch 145/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35523.0195\n",
      "Epoch 146/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35522.7891\n",
      "Epoch 147/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35522.5508\n",
      "Epoch 148/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35522.3164\n",
      "Epoch 149/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35522.0820\n",
      "Epoch 150/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35521.8555\n",
      "Epoch 151/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35521.6172\n",
      "Epoch 152/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35521.3828\n",
      "Epoch 153/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35521.1484\n",
      "Epoch 154/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35520.9141\n",
      "Epoch 155/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35520.6797\n",
      "Epoch 156/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35520.4453\n",
      "Epoch 157/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35520.2109\n",
      "Epoch 158/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35519.9805\n",
      "Epoch 159/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35519.7461\n",
      "Epoch 160/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35519.5078\n",
      "Epoch 161/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35519.2773\n",
      "Epoch 162/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35519.0430\n",
      "Epoch 163/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35518.8047\n",
      "Epoch 164/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35518.5781\n",
      "Epoch 165/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35518.3438\n",
      "Epoch 166/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35518.1094\n",
      "Epoch 167/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35517.8711\n",
      "Epoch 168/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35517.6406\n",
      "Epoch 169/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35517.4062\n",
      "Epoch 170/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35517.1719\n",
      "Epoch 171/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35516.9336\n",
      "Epoch 172/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35516.6992\n",
      "Epoch 173/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35516.4727\n",
      "Epoch 174/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35516.2344\n",
      "Epoch 175/500\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 35516.0039\n",
      "Epoch 176/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35515.7695\n",
      "Epoch 177/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35515.5352\n",
      "Epoch 178/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35515.2969\n",
      "Epoch 179/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35515.0664\n",
      "Epoch 180/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35514.8320\n",
      "Epoch 181/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35514.5977\n",
      "Epoch 182/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35514.3633\n",
      "Epoch 183/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35514.1250\n",
      "Epoch 184/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35513.8945\n",
      "Epoch 185/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35513.6602\n",
      "Epoch 186/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35513.4258\n",
      "Epoch 187/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35513.1914\n",
      "Epoch 188/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35512.9609\n",
      "Epoch 189/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35512.7266\n",
      "Epoch 190/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35512.4922\n",
      "Epoch 191/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35512.2578\n",
      "Epoch 192/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35512.0234\n",
      "Epoch 193/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35511.7930\n",
      "Epoch 194/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35511.5547\n",
      "Epoch 195/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35511.3242\n",
      "Epoch 196/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35511.0859\n",
      "Epoch 197/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35510.8555\n",
      "Epoch 198/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35510.6211\n",
      "Epoch 199/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35510.3789\n",
      "Epoch 200/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35510.1523\n",
      "Epoch 201/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35509.9141\n",
      "Epoch 202/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35509.6836\n",
      "Epoch 203/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35509.4492\n",
      "Epoch 204/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35509.2109\n",
      "Epoch 205/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35508.9766\n",
      "Epoch 206/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35508.7500\n",
      "Epoch 207/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35508.5078\n",
      "Epoch 208/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35508.2773\n",
      "Epoch 209/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35508.0430\n",
      "Epoch 210/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35507.8086\n",
      "Epoch 211/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35507.5781\n",
      "Epoch 212/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35507.3438\n",
      "Epoch 213/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35507.1133\n",
      "Epoch 214/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35506.8750\n",
      "Epoch 215/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35506.6406\n",
      "Epoch 216/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35506.4062\n",
      "Epoch 217/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35506.1719\n",
      "Epoch 218/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35505.9375\n",
      "Epoch 219/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35505.7031\n",
      "Epoch 220/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35505.4766\n",
      "Epoch 221/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35505.2383\n",
      "Epoch 222/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35505.0039\n",
      "Epoch 223/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35504.7695\n",
      "Epoch 224/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35504.5391\n",
      "Epoch 225/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35504.3008\n",
      "Epoch 226/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35504.0664\n",
      "Epoch 227/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35503.8281\n",
      "Epoch 228/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35503.5938\n",
      "Epoch 229/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35503.3594\n",
      "Epoch 230/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35503.1289\n",
      "Epoch 231/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35502.8945\n",
      "Epoch 232/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35502.6602\n",
      "Epoch 233/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35502.4258\n",
      "Epoch 234/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35502.1914\n",
      "Epoch 235/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35501.9609\n",
      "Epoch 236/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35501.7305\n",
      "Epoch 237/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35501.4961\n",
      "Epoch 238/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35501.2617\n",
      "Epoch 239/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35501.0273\n",
      "Epoch 240/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35500.7930\n",
      "Epoch 241/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35500.5547\n",
      "Epoch 242/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35500.3242\n",
      "Epoch 243/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35500.0938\n",
      "Epoch 244/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35499.8555\n",
      "Epoch 245/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35499.6211\n",
      "Epoch 246/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35499.3867\n",
      "Epoch 247/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35499.1484\n",
      "Epoch 248/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35498.9219\n",
      "Epoch 249/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35498.6836\n",
      "Epoch 250/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35498.4492\n",
      "Epoch 251/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35498.2148\n",
      "Epoch 252/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35497.9805\n",
      "Epoch 253/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35497.7500\n",
      "Epoch 254/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35497.5156\n",
      "Epoch 255/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35497.2773\n",
      "Epoch 256/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35497.0430\n",
      "Epoch 257/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35496.8125\n",
      "Epoch 258/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35496.5781\n",
      "Epoch 259/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35496.3438\n",
      "Epoch 260/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35496.1133\n",
      "Epoch 261/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35495.8789\n",
      "Epoch 262/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35495.6445\n",
      "Epoch 263/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35495.4102\n",
      "Epoch 264/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35495.1797\n",
      "Epoch 265/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35494.9453\n",
      "Epoch 266/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35494.7070\n",
      "Epoch 267/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35494.4766\n",
      "Epoch 268/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35494.2383\n",
      "Epoch 269/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35494.0039\n",
      "Epoch 270/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35493.7734\n",
      "Epoch 271/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35493.5391\n",
      "Epoch 272/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35493.3047\n",
      "Epoch 273/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35493.0703\n",
      "Epoch 274/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35492.8359\n",
      "Epoch 275/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35492.6016\n",
      "Epoch 276/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35492.3672\n",
      "Epoch 277/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35492.1328\n",
      "Epoch 278/500\n",
      "9/9 [==============================] - 0s 6ms/step - loss: 35491.8984\n",
      "Epoch 279/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35491.6641\n",
      "Epoch 280/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35491.4336\n",
      "Epoch 281/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35491.1953\n",
      "Epoch 282/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35490.9609\n",
      "Epoch 283/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35490.7305\n",
      "Epoch 284/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35490.4961\n",
      "Epoch 285/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35490.2617\n",
      "Epoch 286/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35490.0273\n",
      "Epoch 287/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35489.7930\n",
      "Epoch 288/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35489.5625\n",
      "Epoch 289/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35489.3281\n",
      "Epoch 290/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35489.0938\n",
      "Epoch 291/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35488.8594\n",
      "Epoch 292/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35488.6211\n",
      "Epoch 293/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35488.3906\n",
      "Epoch 294/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35488.1562\n",
      "Epoch 295/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35487.9219\n",
      "Epoch 296/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35487.6914\n",
      "Epoch 297/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35487.4570\n",
      "Epoch 298/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35487.2188\n",
      "Epoch 299/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35486.9844\n",
      "Epoch 300/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35486.7500\n",
      "Epoch 301/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35486.5156\n",
      "Epoch 302/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35486.2812\n",
      "Epoch 303/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35486.0469\n",
      "Epoch 304/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35485.8125\n",
      "Epoch 305/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35485.5781\n",
      "Epoch 306/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35485.3477\n",
      "Epoch 307/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35485.1172\n",
      "Epoch 308/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35484.8828\n",
      "Epoch 309/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35484.6484\n",
      "Epoch 310/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35484.4141\n",
      "Epoch 311/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35484.1797\n",
      "Epoch 312/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35483.9453\n",
      "Epoch 313/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35483.7109\n",
      "Epoch 314/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35483.4766\n",
      "Epoch 315/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35483.2422\n",
      "Epoch 316/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35483.0039\n",
      "Epoch 317/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35482.7734\n",
      "Epoch 318/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35482.5430\n",
      "Epoch 319/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35482.3086\n",
      "Epoch 320/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35482.0703\n",
      "Epoch 321/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35481.8398\n",
      "Epoch 322/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35481.6055\n",
      "Epoch 323/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35481.3711\n",
      "Epoch 324/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step - loss: 35481.1367\n",
      "Epoch 325/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35480.9062\n",
      "Epoch 326/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35480.6680\n",
      "Epoch 327/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35480.4336\n",
      "Epoch 328/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35480.1992\n",
      "Epoch 329/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35479.9688\n",
      "Epoch 330/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35479.7305\n",
      "Epoch 331/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35479.5000\n",
      "Epoch 332/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35479.2656\n",
      "Epoch 333/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35479.0312\n",
      "Epoch 334/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35478.7969\n",
      "Epoch 335/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35478.5625\n",
      "Epoch 336/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35478.3320\n",
      "Epoch 337/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35478.0977\n",
      "Epoch 338/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35477.8594\n",
      "Epoch 339/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35477.6289\n",
      "Epoch 340/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35477.3906\n",
      "Epoch 341/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35477.1602\n",
      "Epoch 342/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35476.9258\n",
      "Epoch 343/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35476.6914\n",
      "Epoch 344/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35476.4570\n",
      "Epoch 345/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35476.2227\n",
      "Epoch 346/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35475.9883\n",
      "Epoch 347/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35475.7539\n",
      "Epoch 348/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35475.5156\n",
      "Epoch 349/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35475.2852\n",
      "Epoch 350/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35475.0469\n",
      "Epoch 351/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35474.8203\n",
      "Epoch 352/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35474.5859\n",
      "Epoch 353/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35474.3516\n",
      "Epoch 354/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35474.1172\n",
      "Epoch 355/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35473.8828\n",
      "Epoch 356/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35473.6484\n",
      "Epoch 357/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35473.4180\n",
      "Epoch 358/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35473.1836\n",
      "Epoch 359/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35472.9453\n",
      "Epoch 360/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35472.7148\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35472.4766\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35472.2422\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35472.0156\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35471.7773\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35471.5391\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35471.3086\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35471.0742\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35470.8438\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35470.6055\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35470.3711\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35470.1367\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35469.9062\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35469.6680\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35469.4336\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35469.1992\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35468.9648\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35468.7344\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35468.5000\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35468.2695\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35468.0352\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35467.8008\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35467.5664\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35467.3320\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35467.1016\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35466.8633\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35466.6328\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35466.3945\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35466.1562\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35465.9297\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35465.6953\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35465.4609\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35465.2266\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35464.9883\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35464.7578\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35464.5195\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35464.2852\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35464.0508\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - 0s 5ms/step - loss: 35463.8242\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35463.5859\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35463.3516\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35463.1172\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35462.8828\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35462.6523\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35462.4180\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35462.1836\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35461.9531\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35461.7188\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35461.4844\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35461.2461\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35461.0117\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35460.7773\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35460.5469\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35460.3125\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35460.0781\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35459.8477\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35459.6094\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35459.3789\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35459.1445\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35458.9102\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35458.6719\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35458.4375\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35458.2031\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35457.9688\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35457.7344\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35457.5039\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35457.2695\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35457.0391\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35456.8086\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35456.5703\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35456.3359\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35456.1055\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35455.8672\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35455.6367\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35455.3984\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35455.1641\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35454.9297\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35454.6992\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35454.4648\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35454.2266\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35453.9961\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35453.7578\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35453.5273\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35453.2930\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35453.0547\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35452.8242\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35452.5898\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35452.3516\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35452.1172\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35451.8828\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35451.6562\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35451.4219\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35451.1875\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35450.9531\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35450.7188\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35450.4844\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35450.2500\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35450.0195\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35449.7852\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35449.5508\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35449.3125\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35449.0781\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35448.8477\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35448.6172\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35448.3828\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35448.1445\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35447.9062\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35447.6797\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35447.4414\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35447.2070\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35446.9727\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35446.7383\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35446.5039\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35446.2695\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35446.0391\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35445.8047\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35445.5742\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35445.3398\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35445.1055\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35444.8711\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35444.6367\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35444.4062\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35444.1719\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35443.9297\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35443.6992\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35443.4648\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35443.2305\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35442.9961\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35442.7617\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35442.5273\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35442.2930\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35442.0586\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35441.8281\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35441.5898\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35441.3594\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35441.1250\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35440.8867\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35440.6523\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35440.4219\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35440.1914\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 35439.9570\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 712: DatepartRegression\n",
      "Model Number: 713 with model DatepartRegression in generation 8 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 713: DatepartRegression\n",
      "Model Number: 714 with model LastValueNaive in generation 8 of 10\n",
      "Model Number: 715 with model LastValueNaive in generation 8 of 10\n",
      "Model Number: 716 with model GLS in generation 8 of 10\n",
      "Model Number: 717 with model GLS in generation 8 of 10\n",
      "Model Number: 718 with model ETS in generation 8 of 10\n",
      "Model Number: 719 with model ETS in generation 8 of 10\n",
      "Model Number: 720 with model ETS in generation 8 of 10\n",
      "Model Number: 721 with model ETS in generation 8 of 10\n",
      "Model Number: 722 with model WindowRegression in generation 8 of 10\n",
      "Model Number: 723 with model WindowRegression in generation 8 of 10\n",
      "Model Number: 724 with model WindowRegression in generation 8 of 10\n",
      "Model Number: 725 with model UnobservedComponents in generation 8 of 10\n",
      "Model Number: 726 with model UnobservedComponents in generation 8 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 726: UnobservedComponents\n",
      "Model Number: 727 with model UnobservedComponents in generation 8 of 10\n",
      "Model Number: 728 with model GluonTS in generation 8 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 728: GluonTS\n",
      "Model Number: 729 with model GluonTS in generation 8 of 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 729: GluonTS\n",
      "Model Number: 730 with model GluonTS in generation 8 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 730: GluonTS\n",
      "Model Number: 731 with model GluonTS in generation 8 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 731: GluonTS\n",
      "Model Number: 732 with model VAR in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 732: VAR\n",
      "Model Number: 733 with model VAR in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 733: VAR\n",
      "Model Number: 734 with model VAR in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 734: VAR\n",
      "Model Number: 735 with model VAR in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 735: VAR\n",
      "Model Number: 736 with model VECM in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 736: VECM\n",
      "Model Number: 737 with model VECM in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 737: VECM\n",
      "Model Number: 738 with model VECM in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 738: VECM\n",
      "Model Number: 739 with model VECM in generation 8 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 739: VECM\n",
      "Model Number: 740 with model FBProphet in generation 8 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 740: FBProphet\n",
      "Model Number: 741 with model FBProphet in generation 8 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 741: FBProphet\n",
      "Model Number: 742 with model FBProphet in generation 8 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 742: FBProphet\n",
      "Model Number: 743 with model FBProphet in generation 8 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 743: FBProphet\n",
      "Model Number: 744 with model ARDL in generation 8 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 744: ARDL\n",
      "Model Number: 745 with model ARDL in generation 8 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 745: ARDL\n",
      "Model Number: 746 with model ARDL in generation 8 of 10\n",
      "Template Eval Error: Exception('Transformer Detrend failed on fit') in model 746: ARDL\n",
      "Model Number: 747 with model ARDL in generation 8 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 747: ARDL\n",
      "New Generation: 9 of 10\n",
      "Model Number: 748 with model Theta in generation 9 of 10\n",
      "Model Number: 749 with model Theta in generation 9 of 10\n",
      "Model Number: 750 with model Theta in generation 9 of 10\n",
      "Model Number: 751 with model Theta in generation 9 of 10\n",
      "Model Number: 752 with model UnivariateMotif in generation 9 of 10\n",
      "Model Number: 753 with model UnivariateMotif in generation 9 of 10\n",
      "Model Number: 754 with model UnivariateMotif in generation 9 of 10\n",
      "Model Number: 755 with model UnivariateMotif in generation 9 of 10\n",
      "Model Number: 756 with model NVAR in generation 9 of 10\n",
      "Model Number: 757 with model NVAR in generation 9 of 10\n",
      "Model Number: 758 with model NVAR in generation 9 of 10\n",
      "Model Number: 759 with model NVAR in generation 9 of 10\n",
      "Model Number: 760 with model SectionalMotif in generation 9 of 10\n",
      "Model Number: 761 with model SectionalMotif in generation 9 of 10\n",
      "Model Number: 762 with model SectionalMotif in generation 9 of 10\n",
      "Model Number: 763 with model SectionalMotif in generation 9 of 10\n",
      "Model Number: 764 with model AverageValueNaive in generation 9 of 10\n",
      "Model Number: 765 with model AverageValueNaive in generation 9 of 10\n",
      "Model Number: 766 with model AverageValueNaive in generation 9 of 10\n",
      "Model Number: 767 with model GLM in generation 9 of 10\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 767: GLM\n",
      "Model Number: 768 with model GLM in generation 9 of 10\n",
      "Model Number: 769 with model GLM in generation 9 of 10\n",
      "Model Number: 770 with model GLM in generation 9 of 10\n",
      "Template Eval Error: ValueError('The first guess on the deviance function returned a nan.  This could be a boundary  problem and should be reported.') in model 770: GLM\n",
      "Model Number: 771 with model SeasonalNaive in generation 9 of 10\n",
      "Model Number: 772 with model SeasonalNaive in generation 9 of 10\n",
      "Model Number: 773 with model SeasonalNaive in generation 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1231: RuntimeWarning: invalid value encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1231: RuntimeWarning: divide by zero encountered in log\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\family.py:1231: RuntimeWarning: invalid value encountered in multiply\n",
      "  resid_dev -= endog_alpha * np.log(endog_alpha / mu_alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 774 with model SeasonalNaive in generation 9 of 10\n",
      "Model Number: 775 with model MultivariateRegression in generation 9 of 10\n",
      "Model Number: 776 with model MultivariateRegression in generation 9 of 10\n",
      "Model Number: 777 with model MultivariateRegression in generation 9 of 10\n",
      "Model Number: 778 with model MultivariateRegression in generation 9 of 10\n",
      "Model Number: 779 with model MultivariateMotif in generation 9 of 10\n",
      "Model Number: 780 with model MultivariateMotif in generation 9 of 10\n",
      "Model Number: 781 with model MultivariateMotif in generation 9 of 10\n",
      "Model Number: 782 with model MultivariateMotif in generation 9 of 10\n",
      "Model Number: 783 with model ZeroesNaive in generation 9 of 10\n",
      "Model Number: 784 with model ZeroesNaive in generation 9 of 10\n",
      "Model Number: 785 with model ZeroesNaive in generation 9 of 10\n",
      "Model Number: 786 with model DatepartRegression in generation 9 of 10\n",
      "Epoch 1/500\n",
      "17/17 [==============================] - 3s 6ms/step - loss: 0.1830\n",
      "Epoch 2/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.1011\n",
      "Epoch 3/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0933\n",
      "Epoch 4/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0901\n",
      "Epoch 5/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0848\n",
      "Epoch 6/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0787\n",
      "Epoch 7/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0771\n",
      "Epoch 8/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0712\n",
      "Epoch 9/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0699\n",
      "Epoch 10/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0679\n",
      "Epoch 11/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0680\n",
      "Epoch 12/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0629\n",
      "Epoch 13/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0621\n",
      "Epoch 14/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0583\n",
      "Epoch 15/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0583\n",
      "Epoch 16/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0593\n",
      "Epoch 17/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0573\n",
      "Epoch 18/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0632\n",
      "Epoch 19/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0606\n",
      "Epoch 20/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0546\n",
      "Epoch 21/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0543\n",
      "Epoch 22/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0542\n",
      "Epoch 23/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0529\n",
      "Epoch 24/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0510\n",
      "Epoch 25/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0490\n",
      "Epoch 26/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0488\n",
      "Epoch 27/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0467\n",
      "Epoch 28/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0462\n",
      "Epoch 29/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0453\n",
      "Epoch 30/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0409\n",
      "Epoch 31/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0368\n",
      "Epoch 32/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0357\n",
      "Epoch 33/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0335\n",
      "Epoch 34/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0278\n",
      "Epoch 35/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0283\n",
      "Epoch 36/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0305\n",
      "Epoch 37/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0344\n",
      "Epoch 38/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0321\n",
      "Epoch 39/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0270\n",
      "Epoch 40/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0223\n",
      "Epoch 41/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0220\n",
      "Epoch 42/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0230\n",
      "Epoch 43/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0202\n",
      "Epoch 44/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0164\n",
      "Epoch 45/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0155\n",
      "Epoch 46/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0145\n",
      "Epoch 47/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0136\n",
      "Epoch 48/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0136\n",
      "Epoch 49/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0129\n",
      "Epoch 50/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0138\n",
      "Epoch 51/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0143\n",
      "Epoch 52/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0131\n",
      "Epoch 53/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0149\n",
      "Epoch 54/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0134\n",
      "Epoch 55/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0107\n",
      "Epoch 56/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0123\n",
      "Epoch 57/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0094\n",
      "Epoch 58/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0114\n",
      "Epoch 59/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0112\n",
      "Epoch 60/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0104\n",
      "Epoch 61/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0103\n",
      "Epoch 62/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0104\n",
      "Epoch 63/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0103\n",
      "Epoch 64/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0089\n",
      "Epoch 65/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0111\n",
      "Epoch 66/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0098\n",
      "Epoch 67/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0075\n",
      "Epoch 68/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0101\n",
      "Epoch 69/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0097\n",
      "Epoch 70/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0105\n",
      "Epoch 71/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0091\n",
      "Epoch 72/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0113\n",
      "Epoch 73/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0147\n",
      "Epoch 74/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0094\n",
      "Epoch 75/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0082\n",
      "Epoch 76/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0097\n",
      "Epoch 77/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0093\n",
      "Epoch 78/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0118\n",
      "Epoch 79/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0121\n",
      "Epoch 80/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0122\n",
      "Epoch 81/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0096\n",
      "Epoch 82/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0096\n",
      "Epoch 83/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0092\n",
      "Epoch 84/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0078\n",
      "Epoch 85/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0072\n",
      "Epoch 86/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0079\n",
      "Epoch 87/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0097\n",
      "Epoch 88/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0079\n",
      "Epoch 89/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0071\n",
      "Epoch 90/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0075\n",
      "Epoch 91/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0072\n",
      "Epoch 92/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073\n",
      "Epoch 93/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0085\n",
      "Epoch 94/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0074\n",
      "Epoch 95/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0087\n",
      "Epoch 96/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0089\n",
      "Epoch 97/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0090\n",
      "Epoch 98/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0075\n",
      "Epoch 99/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0068\n",
      "Epoch 100/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0066\n",
      "Epoch 101/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067\n",
      "Epoch 102/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0061\n",
      "Epoch 103/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0083\n",
      "Epoch 104/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0066\n",
      "Epoch 105/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0064\n",
      "Epoch 106/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0068\n",
      "Epoch 107/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0068\n",
      "Epoch 108/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0067\n",
      "Epoch 109/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0066\n",
      "Epoch 110/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0079\n",
      "Epoch 111/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069\n",
      "Epoch 112/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0063\n",
      "Epoch 113/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069\n",
      "Epoch 114/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0071\n",
      "Epoch 115/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0060\n",
      "Epoch 116/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0062\n",
      "Epoch 117/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0056\n",
      "Epoch 118/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0057\n",
      "Epoch 119/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 120/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0056\n",
      "Epoch 121/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0068\n",
      "Epoch 122/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0061\n",
      "Epoch 123/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0057\n",
      "Epoch 124/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0066\n",
      "Epoch 125/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0061\n",
      "Epoch 126/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0061\n",
      "Epoch 127/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0052\n",
      "Epoch 128/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0062\n",
      "Epoch 129/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 130/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0062\n",
      "Epoch 131/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059\n",
      "Epoch 132/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0066\n",
      "Epoch 133/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0056\n",
      "Epoch 134/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0068\n",
      "Epoch 135/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0064\n",
      "Epoch 136/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0069\n",
      "Epoch 137/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059\n",
      "Epoch 138/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058\n",
      "Epoch 139/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0060\n",
      "Epoch 140/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059\n",
      "Epoch 141/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0054\n",
      "Epoch 142/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 143/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0055\n",
      "Epoch 144/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0073\n",
      "Epoch 145/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0069\n",
      "Epoch 146/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0064\n",
      "Epoch 147/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 148/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 149/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 150/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058\n",
      "Epoch 151/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0060\n",
      "Epoch 152/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0062\n",
      "Epoch 153/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0048\n",
      "Epoch 154/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0046\n",
      "Epoch 155/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0045\n",
      "Epoch 156/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 157/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0055\n",
      "Epoch 158/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0047\n",
      "Epoch 159/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0057\n",
      "Epoch 160/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0048\n",
      "Epoch 161/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0052\n",
      "Epoch 162/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0048\n",
      "Epoch 163/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0056\n",
      "Epoch 164/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0059\n",
      "Epoch 165/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0058\n",
      "Epoch 166/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 167/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0046\n",
      "Epoch 168/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0052\n",
      "Epoch 169/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0056\n",
      "Epoch 170/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 171/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0063\n",
      "Epoch 172/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0049\n",
      "Epoch 173/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0064\n",
      "Epoch 174/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0056\n",
      "Epoch 175/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0060\n",
      "Epoch 176/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0048\n",
      "Epoch 177/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0044\n",
      "Epoch 178/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0069\n",
      "Epoch 179/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 180/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0045\n",
      "Epoch 181/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0048\n",
      "Epoch 182/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0049\n",
      "Epoch 183/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0046\n",
      "Epoch 184/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 185/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0047\n",
      "Epoch 186/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0045\n",
      "Epoch 187/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0037\n",
      "Epoch 188/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0046\n",
      "Epoch 189/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0046\n",
      "Epoch 190/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0040\n",
      "Epoch 191/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 192/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 193/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0048\n",
      "Epoch 194/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0052\n",
      "Epoch 195/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0061\n",
      "Epoch 196/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047\n",
      "Epoch 197/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0039\n",
      "Epoch 198/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 199/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0051\n",
      "Epoch 200/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0052\n",
      "Epoch 201/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0046\n",
      "Epoch 202/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0043\n",
      "Epoch 203/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0054\n",
      "Epoch 204/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0042\n",
      "Epoch 205/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 206/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0041\n",
      "Epoch 207/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 208/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0048\n",
      "Epoch 209/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058\n",
      "Epoch 210/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0054\n",
      "Epoch 211/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0046\n",
      "Epoch 212/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0046\n",
      "Epoch 213/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0054\n",
      "Epoch 214/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0047\n",
      "Epoch 215/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 216/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 217/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 218/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0041\n",
      "Epoch 219/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0044\n",
      "Epoch 220/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 221/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 222/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0041\n",
      "Epoch 223/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0037\n",
      "Epoch 224/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 225/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0058\n",
      "Epoch 226/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0053\n",
      "Epoch 227/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036\n",
      "Epoch 228/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040\n",
      "Epoch 229/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0037\n",
      "Epoch 230/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0037\n",
      "Epoch 231/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040\n",
      "Epoch 232/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0045\n",
      "Epoch 233/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 234/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0041\n",
      "Epoch 235/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040\n",
      "Epoch 236/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0044\n",
      "Epoch 237/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036\n",
      "Epoch 238/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0050\n",
      "Epoch 239/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0041\n",
      "Epoch 240/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0041\n",
      "Epoch 241/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 242/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0047\n",
      "Epoch 243/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0047\n",
      "Epoch 244/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0035\n",
      "Epoch 245/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0038\n",
      "Epoch 246/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0044\n",
      "Epoch 247/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040\n",
      "Epoch 248/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0042\n",
      "Epoch 249/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0043\n",
      "Epoch 250/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0038\n",
      "Epoch 251/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0043\n",
      "Epoch 252/500\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 0.0040\n",
      "Epoch 253/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0038\n",
      "Epoch 254/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0037\n",
      "Epoch 255/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0041\n",
      "Epoch 256/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0042\n",
      "Epoch 257/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0034\n",
      "Epoch 258/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 259/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 260/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0041\n",
      "Epoch 261/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0033\n",
      "Epoch 262/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0030\n",
      "Epoch 263/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0032\n",
      "Epoch 264/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0039\n",
      "Epoch 265/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 266/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0041\n",
      "Epoch 267/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 268/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0036\n",
      "Epoch 269/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0035\n",
      "Epoch 270/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0043\n",
      "Epoch 271/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0041\n",
      "Epoch 272/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0034\n",
      "Epoch 273/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0042\n",
      "Epoch 274/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 275/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 276/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 277/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0030\n",
      "Epoch 278/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0038\n",
      "Epoch 279/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040\n",
      "Epoch 280/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 281/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0034\n",
      "Epoch 282/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0034\n",
      "Epoch 283/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 284/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 285/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0033\n",
      "Epoch 286/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 287/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0034\n",
      "Epoch 288/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 289/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0043\n",
      "Epoch 290/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040\n",
      "Epoch 291/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 292/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0037\n",
      "Epoch 293/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0037\n",
      "Epoch 294/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0035\n",
      "Epoch 295/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 296/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0030\n",
      "Epoch 297/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036\n",
      "Epoch 298/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 299/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 300/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0030\n",
      "Epoch 301/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 302/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0032\n",
      "Epoch 303/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 304/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 305/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036\n",
      "Epoch 306/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 307/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 308/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 309/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 310/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036\n",
      "Epoch 311/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0044\n",
      "Epoch 312/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0044\n",
      "Epoch 313/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 314/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0039\n",
      "Epoch 315/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036\n",
      "Epoch 316/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 317/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0027\n",
      "Epoch 318/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0027\n",
      "Epoch 319/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 320/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 321/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 322/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0035\n",
      "Epoch 323/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 324/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 325/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 326/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 327/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 328/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0035\n",
      "Epoch 329/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0027\n",
      "Epoch 330/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 331/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 332/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0030\n",
      "Epoch 333/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 334/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0036\n",
      "Epoch 335/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040\n",
      "Epoch 336/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0040\n",
      "Epoch 337/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0030\n",
      "Epoch 338/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0025\n",
      "Epoch 339/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0028\n",
      "Epoch 340/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 341/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 342/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 343/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 344/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 345/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 346/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 347/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0030\n",
      "Epoch 348/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0027\n",
      "Epoch 349/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0035\n",
      "Epoch 350/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 351/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 352/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 353/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0029\n",
      "Epoch 354/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0033\n",
      "Epoch 355/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0030\n",
      "Epoch 356/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0035\n",
      "Epoch 357/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 358/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0032\n",
      "Epoch 359/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0043\n",
      "Epoch 360/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0026\n",
      "Epoch 361/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0029\n",
      "Epoch 362/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0022\n",
      "Epoch 363/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0022\n",
      "Epoch 364/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 365/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0023\n",
      "Epoch 366/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0029\n",
      "Epoch 367/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0028\n",
      "Epoch 368/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0023\n",
      "Epoch 369/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0026\n",
      "Epoch 370/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0028\n",
      "Epoch 371/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0025\n",
      "Epoch 372/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0028\n",
      "Epoch 373/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0024\n",
      "Epoch 374/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0026\n",
      "Epoch 375/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0027\n",
      "Epoch 376/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0033\n",
      "Epoch 377/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0030\n",
      "Epoch 378/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 379/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0028\n",
      "Epoch 380/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0023\n",
      "Epoch 381/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0027\n",
      "Epoch 382/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0023\n",
      "Epoch 383/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0028\n",
      "Epoch 384/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0029\n",
      "Epoch 385/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 386/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 387/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0020\n",
      "Epoch 388/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 389/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0023\n",
      "Epoch 390/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0027\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 392/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 393/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0022\n",
      "Epoch 394/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 395/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 396/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 397/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 398/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 399/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0023\n",
      "Epoch 400/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0027\n",
      "Epoch 401/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0028\n",
      "Epoch 402/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0019\n",
      "Epoch 403/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 404/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 405/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0025\n",
      "Epoch 406/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0027\n",
      "Epoch 407/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0023\n",
      "Epoch 408/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0022\n",
      "Epoch 409/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 410/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 411/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 412/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 413/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 414/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0027\n",
      "Epoch 415/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 416/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 417/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0027\n",
      "Epoch 418/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0022\n",
      "Epoch 419/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 420/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0024\n",
      "Epoch 421/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0038\n",
      "Epoch 422/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0030\n",
      "Epoch 423/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0023\n",
      "Epoch 424/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 425/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0027\n",
      "Epoch 426/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0024\n",
      "Epoch 427/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0028\n",
      "Epoch 428/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0031\n",
      "Epoch 429/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0027\n",
      "Epoch 430/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0024\n",
      "Epoch 431/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0026\n",
      "Epoch 432/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0022\n",
      "Epoch 433/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0027\n",
      "Epoch 434/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0029\n",
      "Epoch 435/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0021\n",
      "Epoch 436/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0023\n",
      "Epoch 437/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0024\n",
      "Epoch 438/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0023\n",
      "Epoch 439/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0018\n",
      "Epoch 440/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0020\n",
      "Epoch 441/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 442/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0022\n",
      "Epoch 443/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0024\n",
      "Epoch 444/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0022\n",
      "Epoch 445/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0025\n",
      "Epoch 446/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0025\n",
      "Epoch 447/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0019\n",
      "Epoch 448/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 449/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0020\n",
      "Epoch 450/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0021\n",
      "Epoch 451/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0020\n",
      "Epoch 452/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0020\n",
      "Epoch 453/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0020\n",
      "Epoch 454/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0024\n",
      "Epoch 455/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0021\n",
      "Epoch 456/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0025\n",
      "Epoch 457/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0028\n",
      "Epoch 458/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0036\n",
      "Epoch 459/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0024\n",
      "Epoch 460/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0026\n",
      "Epoch 461/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0028\n",
      "Epoch 462/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0021\n",
      "Epoch 463/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0019\n",
      "Epoch 464/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0020\n",
      "Epoch 465/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0031\n",
      "Epoch 466/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0027\n",
      "Epoch 467/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0024\n",
      "Epoch 468/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0024\n",
      "Epoch 469/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0022\n",
      "Epoch 470/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0019\n",
      "Epoch 471/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0017\n",
      "Epoch 472/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0019\n",
      "Epoch 473/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0018\n",
      "Epoch 474/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 475/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0020\n",
      "Epoch 476/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 477/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0021\n",
      "Epoch 478/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0020\n",
      "Epoch 479/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0021\n",
      "Epoch 480/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0025\n",
      "Epoch 481/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0023\n",
      "Epoch 482/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0022\n",
      "Epoch 483/500\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 0.0033\n",
      "Epoch 484/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0028\n",
      "Epoch 485/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0022\n",
      "Epoch 486/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0019\n",
      "Epoch 487/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0025\n",
      "Epoch 488/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0020\n",
      "Epoch 489/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0016\n",
      "Epoch 490/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0018\n",
      "Epoch 491/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0020\n",
      "Epoch 492/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0018\n",
      "Epoch 493/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0018\n",
      "Epoch 494/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0019\n",
      "Epoch 495/500\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 0.0018\n",
      "Epoch 496/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0023\n",
      "Epoch 497/500\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 0.0021\n",
      "Epoch 498/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0022\n",
      "Epoch 499/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0019\n",
      "Epoch 500/500\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 0.0022\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 786: DatepartRegression\n",
      "Model Number: 787 with model DatepartRegression in generation 9 of 10\n",
      "Model Number: 788 with model DatepartRegression in generation 9 of 10\n",
      "Epoch 1/50\n",
      "7/7 [==============================] - 5s 86ms/step - loss: 199.7068 - val_loss: 105.3551\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 150.0166 - val_loss: 101.8759\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 145.3816 - val_loss: 100.5471\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 171.5115 - val_loss: 110.5166\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 156.2622 - val_loss: 114.4339\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 152.0513 - val_loss: 109.8047\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 132.1023 - val_loss: 123.4155\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 137.0713 - val_loss: 115.2385\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 130.9780 - val_loss: 101.5746\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 141.8281 - val_loss: 102.2682\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 146.1315 - val_loss: 105.9101\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 147.6172 - val_loss: 100.9379\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 147.9378 - val_loss: 100.1173\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 137.1414 - val_loss: 124.7506\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 148.4028 - val_loss: 114.7277\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 134.1630 - val_loss: 112.8259\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 144.5415 - val_loss: 106.8564\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 147.3787 - val_loss: 99.7271\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 140.5648 - val_loss: 103.5767\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 134.4527 - val_loss: 124.5029\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 151.6569 - val_loss: 111.1975\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 128.5661 - val_loss: 106.2869\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 126.3983 - val_loss: 102.2487\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 120.0419 - val_loss: 101.5651\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 130.2310 - val_loss: 99.5668\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 139.9799 - val_loss: 115.5487\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 131.1346 - val_loss: 107.7227\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 130.4384 - val_loss: 100.5676\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 117.6376 - val_loss: 103.8419\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 128.2466 - val_loss: 109.4305\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 138.0018 - val_loss: 99.5735\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 144.4764 - val_loss: 102.1503\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 123.9354 - val_loss: 107.0165\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 135.0822 - val_loss: 100.3060\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 133.7577 - val_loss: 105.3553\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 788: DatepartRegression\n",
      "Model Number: 789 with model LastValueNaive in generation 9 of 10\n",
      "Model Number: 790 with model LastValueNaive in generation 9 of 10\n",
      "Model Number: 791 with model LastValueNaive in generation 9 of 10\n",
      "Model Number: 792 with model ETS in generation 9 of 10\n",
      "Model Number: 793 with model ETS in generation 9 of 10\n",
      "Model Number: 794 with model ETS in generation 9 of 10\n",
      "Model Number: 795 with model ETS in generation 9 of 10\n",
      "Model Number: 796 with model GLS in generation 9 of 10\n",
      "Model Number: 797 with model GLS in generation 9 of 10\n",
      "Model Number: 798 with model GLS in generation 9 of 10\n",
      "Model Number: 799 with model WindowRegression in generation 9 of 10\n",
      "Model Number: 800 with model WindowRegression in generation 9 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 800: WindowRegression\n",
      "Model Number: 801 with model WindowRegression in generation 9 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 801: WindowRegression\n",
      "Model Number: 802 with model UnobservedComponents in generation 9 of 10\n",
      "Model Number: 803 with model UnobservedComponents in generation 9 of 10\n",
      "Model Number: 804 with model UnobservedComponents in generation 9 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor supplied\") in model 804: UnobservedComponents\n",
      "Model Number: 805 with model GluonTS in generation 9 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 805: GluonTS\n",
      "Model Number: 806 with model GluonTS in generation 9 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 806: GluonTS\n",
      "Model Number: 807 with model GluonTS in generation 9 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 807: GluonTS\n",
      "Model Number: 808 with model GluonTS in generation 9 of 10\n",
      "Template Eval Error: ImportError('GluonTS installation not found or installed version is incompatible with AutoTS.') in model 808: GluonTS\n",
      "Model Number: 809 with model VAR in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 809: VAR\n",
      "Model Number: 810 with model VAR in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 810: VAR\n",
      "Model Number: 811 with model VAR in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 811: VAR\n",
      "Model Number: 812 with model VAR in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VAR') in model 812: VAR\n",
      "Model Number: 813 with model VECM in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 813: VECM\n",
      "Model Number: 814 with model VECM in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 814: VECM\n",
      "Model Number: 815 with model VECM in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 815: VECM\n",
      "Model Number: 816 with model VECM in generation 9 of 10\n",
      "Template Eval Error: ValueError('Only gave one variable to VECM') in model 816: VECM\n",
      "Model Number: 817 with model FBProphet in generation 9 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 817: FBProphet\n",
      "Model Number: 818 with model FBProphet in generation 9 of 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 818: FBProphet\n",
      "Model Number: 819 with model FBProphet in generation 9 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 819: FBProphet\n",
      "Model Number: 820 with model FBProphet in generation 9 of 10\n",
      "Template Eval Error: ModuleNotFoundError(\"No module named 'prophet'\") in model 820: FBProphet\n",
      "Model Number: 821 with model ARDL in generation 9 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 821: ARDL\n",
      "Model Number: 822 with model ARDL in generation 9 of 10\n",
      "Template Eval Error: ImportError(\"cannot import name 'ARDL' from 'statsmodels.tsa.api' (C:\\\\Users\\\\zachg\\\\anaconda3\\\\lib\\\\site-packages\\\\statsmodels\\\\tsa\\\\api.py)\") in model 822: ARDL\n",
      "Model Number: 823 with model ARDL in generation 9 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 823: ARDL\n",
      "Model Number: 824 with model ARDL in generation 9 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but future_regressor not supplied\") in model 824: ARDL\n",
      "New Generation: 10 of 10\n",
      "Model Number: 825 with model Theta in generation 10 of 10\n",
      "Model Number: 826 with model Theta in generation 10 of 10\n",
      "Model Number: 827 with model Theta in generation 10 of 10\n",
      "Model Number: 828 with model Theta in generation 10 of 10\n",
      "Model Number: 829 with model UnivariateMotif in generation 10 of 10\n",
      "Model Number: 830 with model UnivariateMotif in generation 10 of 10\n",
      "Model Number: 831 with model UnivariateMotif in generation 10 of 10\n",
      "Model Number: 832 with model UnivariateMotif in generation 10 of 10\n",
      "Model Number: 833 with model NVAR in generation 10 of 10\n",
      "Model Number: 834 with model NVAR in generation 10 of 10\n",
      "Model Number: 835 with model NVAR in generation 10 of 10\n",
      "Model Number: 836 with model NVAR in generation 10 of 10\n",
      "Model Number: 837 with model SectionalMotif in generation 10 of 10\n",
      "Model Number: 838 with model SectionalMotif in generation 10 of 10\n",
      "Model Number: 839 with model SectionalMotif in generation 10 of 10\n",
      "Model Number: 840 with model SectionalMotif in generation 10 of 10\n",
      "Model Number: 841 with model AverageValueNaive in generation 10 of 10\n",
      "Model Number: 842 with model AverageValueNaive in generation 10 of 10\n",
      "Model Number: 843 with model AverageValueNaive in generation 10 of 10\n",
      "Model Number: 844 with model SeasonalNaive in generation 10 of 10\n",
      "Model Number: 845 with model SeasonalNaive in generation 10 of 10\n",
      "Model Number: 846 with model SeasonalNaive in generation 10 of 10\n",
      "Model Number: 847 with model SeasonalNaive in generation 10 of 10\n",
      "Model Number: 848 with model GLM in generation 10 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 848: GLM\n",
      "Model Number: 849 with model GLM in generation 10 of 10\n",
      "Model Number: 850 with model GLM in generation 10 of 10\n",
      "Template Eval Error: TypeError(\"ufunc 'isfinite' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''\") in model 850: GLM\n",
      "Model Number: 851 with model MultivariateRegression in generation 10 of 10\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]Model Number: 852 with model MultivariateRegression in generation 10 of 10\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]Model Number: 853 with model MultivariateRegression in generation 10 of 10\n",
      "[LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 854 with model MultivariateRegression in generation 10 of 10\n",
      "Model Number: 855 with model MultivariateMotif in generation 10 of 10\n",
      "Model Number: 856 with model MultivariateMotif in generation 10 of 10\n",
      "Model Number: 857 with model MultivariateMotif in generation 10 of 10\n",
      "Model Number: 858 with model MultivariateMotif in generation 10 of 10\n",
      "Template Eval Error: ValueError('Model MultivariateMotif returned NaN for one or more series. fail_on_forecast_nan=True') in model 858: MultivariateMotif\n",
      "Model Number: 859 with model ZeroesNaive in generation 10 of 10\n",
      "Model Number: 860 with model ZeroesNaive in generation 10 of 10\n",
      "Template Eval Error: KeyError(Timestamp('2020-10-01 00:00:00', freq='D')) in model 860: ZeroesNaive\n",
      "Model Number: 861 with model ZeroesNaive in generation 10 of 10\n",
      "Model Number: 862 with model DatepartRegression in generation 10 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 862: DatepartRegression\n",
      "Model Number: 863 with model DatepartRegression in generation 10 of 10\n",
      "Template Eval Error: ValueError(\"regression_type='User' but no future_regressor passed\") in model 863: DatepartRegression\n",
      "Model Number: 864 with model DatepartRegression in generation 10 of 10\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 2s 55ms/step - loss: 198181.1562 - val_loss: 381629.9688\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 198216.3125 - val_loss: 381765.4062\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 198101.8438 - val_loss: 381900.5312\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 198068.9844 - val_loss: 382030.8125\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 197872.7500 - val_loss: 382169.7812\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 197815.9062 - val_loss: 382304.0312\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 198054.0469 - val_loss: 382438.0000\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 197764.6094 - val_loss: 382567.0000\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 197805.3281 - val_loss: 382693.1875\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 18ms/step - loss: 197675.8750 - val_loss: 382819.9688\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 197578.5469 - val_loss: 382960.1250\n",
      "Template Eval Error: ValueError('Model DatepartRegression returned NaN for one or more series. fail_on_forecast_nan=True') in model 864: DatepartRegression\n",
      "Model Number: 865 with model LastValueNaive in generation 10 of 10\n",
      "Model Number: 866 with model LastValueNaive in generation 10 of 10\n",
      "Model Number: 867 with model LastValueNaive in generation 10 of 10\n",
      "Template Eval Error: Exception('Transformer RobustScaler failed on fit') in model 867: LastValueNaive\n",
      "Model Number: 868 with model GLS in generation 10 of 10\n",
      "Model Number: 869 with model GLS in generation 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1113: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(a, func=_nanmedian, axis=axis, out=out,\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1368: RuntimeWarning: All-NaN slice encountered\n",
      "  r, k = function_base._ureduce(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Number: 870 with model GLS in generation 10 of 10\n",
      "Model Number: 871 with model ETS in generation 10 of 10\n",
      "Model Number: 872 with model ETS in generation 10 of 10\n",
      "Model Number: 873 with model ETS in generation 10 of 10\n",
      "Model Number: 874 with model ETS in generation 10 of 10\n",
      "Model Number: 875 with model WindowRegression in generation 10 of 10\n",
      "Model Number: 876 with model WindowRegression in generation 10 of 10\n",
      "Model Number: 877 with model WindowRegression in generation 10 of 10\n",
      "Model Number: 878 with model Ensemble in generation 11 of 0\n",
      "Model Number: 879 with model Ensemble in generation 11 of 0\n",
      "Model Number: 880 with model Ensemble in generation 11 of 0\n",
      "Model Number: 881 with model Ensemble in generation 11 of 0\n",
      "Model Number: 882 with model Ensemble in generation 11 of 0\n",
      "Model Number: 883 with model Ensemble in generation 11 of 0\n",
      "Model Number: 884 with model Ensemble in generation 11 of 0\n",
      "Model Number: 885 with model Ensemble in generation 11 of 0\n",
      "Validation Round: 1\n",
      "Model Number: 1 of 133 with model Ensemble for Validation 1\n",
      "1 - Ensemble with avg smape 10.59: \n",
      "Model Number: 2 of 133 with model Ensemble for Validation 1\n",
      "2 - Ensemble with avg smape 11.01: \n",
      "Model Number: 3 of 133 with model Ensemble for Validation 1\n",
      "3 - Ensemble with avg smape 12.02: \n",
      "Model Number: 4 of 133 with model Ensemble for Validation 1\n",
      "4 - Ensemble with avg smape 12.1: \n",
      "Model Number: 5 of 133 with model Theta for Validation 1\n",
      "5 - Theta with avg smape 11.2: \n",
      "Model Number: 6 of 133 with model Theta for Validation 1\n",
      "6 - Theta with avg smape 11.39: \n",
      "Model Number: 7 of 133 with model Ensemble for Validation 1\n",
      "7 - Ensemble with avg smape 11.45: \n",
      "Model Number: 8 of 133 with model Theta for Validation 1\n",
      "8 - Theta with avg smape 11.75: \n",
      "Model Number: 9 of 133 with model Ensemble for Validation 1\n",
      "9 - Ensemble with avg smape 11.75: \n",
      "Model Number: 10 of 133 with model Theta for Validation 1\n",
      "10 - Theta with avg smape 11.85: \n",
      "Model Number: 11 of 133 with model Theta for Validation 1\n",
      "11 - Theta with avg smape 12.03: \n",
      "Model Number: 12 of 133 with model Theta for Validation 1\n",
      "12 - Theta with avg smape 12.08: \n",
      "Model Number: 13 of 133 with model Ensemble for Validation 1\n",
      "13 - Ensemble with avg smape 10.91: \n",
      "Model Number: 14 of 133 with model UnivariateMotif for Validation 1\n",
      "14 - UnivariateMotif with avg smape 10.35: \n",
      "Model Number: 15 of 133 with model NVAR for Validation 1\n",
      "15 - NVAR with avg smape 11.9: \n",
      "Model Number: 16 of 133 with model NVAR for Validation 1\n",
      "16 - NVAR with avg smape 11.95: \n",
      "Model Number: 17 of 133 with model NVAR for Validation 1\n",
      "17 - NVAR with avg smape 10.2: \n",
      "Model Number: 18 of 133 with model SectionalMotif for Validation 1\n",
      "18 - SectionalMotif with avg smape 14.78: \n",
      "Model Number: 19 of 133 with model UnivariateMotif for Validation 1\n",
      "19 - UnivariateMotif with avg smape 10.22: \n",
      "Model Number: 20 of 133 with model UnivariateMotif for Validation 1\n",
      "20 - UnivariateMotif with avg smape 10.98: \n",
      "Model Number: 21 of 133 with model UnivariateMotif for Validation 1\n",
      "21 - UnivariateMotif with avg smape 13.35: \n",
      "Model Number: 22 of 133 with model SectionalMotif for Validation 1\n",
      "22 - SectionalMotif with avg smape 5.38: \n",
      "Model Number: 23 of 133 with model AverageValueNaive for Validation 1\n",
      "23 - AverageValueNaive with avg smape 11.01: \n",
      "Model Number: 24 of 133 with model AverageValueNaive for Validation 1\n",
      "24 - AverageValueNaive with avg smape 11.01: \n",
      "Model Number: 25 of 133 with model Theta for Validation 1\n",
      "25 - Theta with avg smape 11.37: \n",
      "Model Number: 26 of 133 with model UnivariateMotif for Validation 1\n",
      "26 - UnivariateMotif with avg smape 14.11: \n",
      "Model Number: 27 of 133 with model AverageValueNaive for Validation 1\n",
      "27 - AverageValueNaive with avg smape 12.23: \n",
      "Model Number: 28 of 133 with model AverageValueNaive for Validation 1\n",
      "28 - AverageValueNaive with avg smape 10.92: \n",
      "Model Number: 29 of 133 with model SeasonalNaive for Validation 1\n",
      "29 - SeasonalNaive with avg smape 12.58: \n",
      "Model Number: 30 of 133 with model AverageValueNaive for Validation 1\n",
      "30 - AverageValueNaive with avg smape 12.62: \n",
      "Model Number: 31 of 133 with model AverageValueNaive for Validation 1\n",
      "31 - AverageValueNaive with avg smape 12.36: \n",
      "Model Number: 32 of 133 with model UnivariateMotif for Validation 1\n",
      "32 - UnivariateMotif with avg smape 12.34: \n",
      "Model Number: 33 of 133 with model AverageValueNaive for Validation 1\n",
      "33 - AverageValueNaive with avg smape 12.28: \n",
      "Model Number: 34 of 133 with model AverageValueNaive for Validation 1\n",
      "34 - AverageValueNaive with avg smape 12.28: \n",
      "Model Number: 35 of 133 with model GLM for Validation 1\n",
      "35 - GLM with avg smape 12.37: \n",
      "Model Number: 36 of 133 with model GLM for Validation 1\n",
      "36 - GLM with avg smape 12.37: \n",
      "Model Number: 37 of 133 with model ZeroesNaive for Validation 1\n",
      "37 - ZeroesNaive with avg smape 11.25: \n",
      "Model Number: 38 of 133 with model Theta for Validation 1\n",
      "38 - Theta with avg smape 6.63: \n",
      "Model Number: 39 of 133 with model SeasonalNaive for Validation 1\n",
      "39 - SeasonalNaive with avg smape 12.31: \n",
      "Model Number: 40 of 133 with model SectionalMotif for Validation 1\n",
      "40 - SectionalMotif with avg smape 13.68: \n",
      "Model Number: 41 of 133 with model GLM for Validation 1\n",
      "41 - GLM with avg smape 10.31: \n",
      "Model Number: 42 of 133 with model GLM for Validation 1\n",
      "42 - GLM with avg smape 10.31: \n",
      "Model Number: 43 of 133 with model UnivariateMotif for Validation 1\n",
      "43 - UnivariateMotif with avg smape 10.55: \n",
      "Model Number: 44 of 133 with model UnivariateMotif for Validation 1\n",
      "44 - UnivariateMotif with avg smape 10.83: \n",
      "Model Number: 45 of 133 with model SectionalMotif for Validation 1\n",
      "45 - SectionalMotif with avg smape 6.41: \n",
      "Model Number: 46 of 133 with model MultivariateRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 - MultivariateRegression with avg smape 12.17: \n",
      "Model Number: 47 of 133 with model GLM for Validation 1\n",
      "47 - GLM with avg smape 9.93: \n",
      "Model Number: 48 of 133 with model MultivariateMotif for Validation 1\n",
      "48 - MultivariateMotif with avg smape 5.38: \n",
      "Model Number: 49 of 133 with model SectionalMotif for Validation 1\n",
      "49 - SectionalMotif with avg smape 12.66: \n",
      "Model Number: 50 of 133 with model SeasonalNaive for Validation 1\n",
      "50 - SeasonalNaive with avg smape 13.13: \n",
      "Model Number: 51 of 133 with model ZeroesNaive for Validation 1\n",
      "51 - ZeroesNaive with avg smape 10.31: \n",
      "Model Number: 52 of 133 with model NVAR for Validation 1\n",
      "52 - NVAR with avg smape 13.29: \n",
      "Model Number: 53 of 133 with model NVAR for Validation 1\n",
      "53 - NVAR with avg smape 12.28: \n",
      "Model Number: 54 of 133 with model SectionalMotif for Validation 1\n",
      "54 - SectionalMotif with avg smape 12.03: \n",
      "Model Number: 55 of 133 with model MultivariateMotif for Validation 1\n",
      "55 - MultivariateMotif with avg smape 15.84: \n",
      "Model Number: 56 of 133 with model NVAR for Validation 1\n",
      "56 - NVAR with avg smape 11.83: \n",
      "Model Number: 57 of 133 with model NVAR for Validation 1\n",
      "57 - NVAR with avg smape 11.83: \n",
      "Model Number: 58 of 133 with model NVAR for Validation 1\n",
      "58 - NVAR with avg smape 11.83: \n",
      "Model Number: 59 of 133 with model SeasonalNaive for Validation 1\n",
      "59 - SeasonalNaive with avg smape 12.09: \n",
      "Model Number: 60 of 133 with model MultivariateMotif for Validation 1\n",
      "60 - MultivariateMotif with avg smape 12.15: \n",
      "Model Number: 61 of 133 with model SectionalMotif for Validation 1\n",
      "61 - SectionalMotif with avg smape 12.65: \n",
      "Model Number: 62 of 133 with model SectionalMotif for Validation 1\n",
      "62 - SectionalMotif with avg smape 12.36: \n",
      "Model Number: 63 of 133 with model DatepartRegression for Validation 1\n",
      "63 - DatepartRegression with avg smape 11.77: \n",
      "Model Number: 64 of 133 with model GLM for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 - GLM with avg smape 11.99: \n",
      "Model Number: 65 of 133 with model MultivariateMotif for Validation 1\n",
      "65 - MultivariateMotif with avg smape 9.03: \n",
      "Model Number: 66 of 133 with model MultivariateRegression for Validation 1\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]66 - MultivariateRegression with avg smape 12.55: \n",
      "Model Number: 67 of 133 with model MultivariateMotif for Validation 1\n",
      "67 - MultivariateMotif with avg smape 5.32: \n",
      "Model Number: 68 of 133 with model MultivariateRegression for Validation 1\n",
      "68 - MultivariateRegression with avg smape 6.22: \n",
      "Model Number: 69 of 133 with model MultivariateMotif for Validation 1\n",
      "69 - MultivariateMotif with avg smape 5.66: \n",
      "Model Number: 70 of 133 with model DatepartRegression for Validation 1\n",
      "70 - DatepartRegression with avg smape 3.39: \n",
      "Model Number: 71 of 133 with model ZeroesNaive for Validation 1\n",
      "71 - ZeroesNaive with avg smape 10.09: \n",
      "Model Number: 72 of 133 with model MultivariateMotif for Validation 1\n",
      "72 - MultivariateMotif with avg smape 7.19: \n",
      "Model Number: 73 of 133 with model MultivariateMotif for Validation 1\n",
      "73 - MultivariateMotif with avg smape 13.74: \n",
      "Model Number: 74 of 133 with model ZeroesNaive for Validation 1\n",
      "74 - ZeroesNaive with avg smape 10.41: \n",
      "Model Number: 75 of 133 with model ZeroesNaive for Validation 1\n",
      "75 - ZeroesNaive with avg smape 10.41: \n",
      "Model Number: 76 of 133 with model MultivariateRegression for Validation 1\n",
      "76 - MultivariateRegression with avg smape 7.72: \n",
      "Model Number: 77 of 133 with model MultivariateRegression for Validation 1\n",
      "77 - MultivariateRegression with avg smape 7.71: \n",
      "Model Number: 78 of 133 with model SeasonalNaive for Validation 1\n",
      "78 - SeasonalNaive with avg smape 9.67: \n",
      "Model Number: 79 of 133 with model SeasonalNaive for Validation 1\n",
      "79 - SeasonalNaive with avg smape 9.43: \n",
      "Model Number: 80 of 133 with model LastValueNaive for Validation 1\n",
      "80 - LastValueNaive with avg smape 15.34: \n",
      "Model Number: 81 of 133 with model ZeroesNaive for Validation 1\n",
      "81 - ZeroesNaive with avg smape 8.74: \n",
      "Model Number: 82 of 133 with model MultivariateRegression for Validation 1\n",
      "82 - MultivariateRegression with avg smape 13.16: \n",
      "Model Number: 83 of 133 with model MultivariateRegression for Validation 1\n",
      "83 - MultivariateRegression with avg smape 11.9: \n",
      "Model Number: 84 of 133 with model ZeroesNaive for Validation 1\n",
      "84 - ZeroesNaive with avg smape 8.36: \n",
      "Model Number: 85 of 133 with model ZeroesNaive for Validation 1\n",
      "85 - ZeroesNaive with avg smape 8.36: \n",
      "Model Number: 86 of 133 with model MultivariateRegression for Validation 1\n",
      "86 - MultivariateRegression with avg smape 7.71: \n",
      "Model Number: 87 of 133 with model GLM for Validation 1\n",
      "87 - GLM with avg smape 11.18: \n",
      "Model Number: 88 of 133 with model LastValueNaive for Validation 1\n",
      "88 - LastValueNaive with avg smape 10.68: \n",
      "Model Number: 89 of 133 with model SeasonalNaive for Validation 1\n",
      "89 - SeasonalNaive with avg smape 13.77: \n",
      "Model Number: 90 of 133 with model GLS for Validation 1\n",
      "90 - GLS with avg smape 13.86: \n",
      "Model Number: 91 of 133 with model GLS for Validation 1\n",
      "91 - GLS with avg smape 14.2: \n",
      "Model Number: 92 of 133 with model Ensemble for Validation 1\n",
      "92 - Ensemble with avg smape 10.65: \n",
      "Model Number: 93 of 133 with model LastValueNaive for Validation 1\n",
      "93 - LastValueNaive with avg smape 16.33: \n",
      "Model Number: 94 of 133 with model LastValueNaive for Validation 1\n",
      "94 - LastValueNaive with avg smape 16.64: \n",
      "Model Number: 95 of 133 with model LastValueNaive for Validation 1\n",
      "95 - LastValueNaive with avg smape 14.24: \n",
      "Model Number: 96 of 133 with model LastValueNaive for Validation 1\n",
      "96 - LastValueNaive with avg smape 14.24: \n",
      "Model Number: 97 of 133 with model LastValueNaive for Validation 1\n",
      "97 - LastValueNaive with avg smape 14.24: \n",
      "Model Number: 98 of 133 with model LastValueNaive for Validation 1\n",
      "98 - LastValueNaive with avg smape 14.24: \n",
      "Model Number: 99 of 133 with model SeasonalNaive for Validation 1\n",
      "99 - SeasonalNaive with avg smape 10.4: \n",
      "Model Number: 100 of 133 with model ETS for Validation 1\n",
      "100 - ETS with avg smape 15.13: \n",
      "Model Number: 101 of 133 with model ETS for Validation 1\n",
      "101 - ETS with avg smape 15.13: \n",
      "Model Number: 102 of 133 with model ETS for Validation 1\n",
      "102 - ETS with avg smape 15.21: \n",
      "Model Number: 103 of 133 with model ETS for Validation 1\n",
      "103 - ETS with avg smape 15.49: \n",
      "Model Number: 104 of 133 with model GLS for Validation 1\n",
      "104 - GLS with avg smape 17.01: \n",
      "Model Number: 105 of 133 with model WindowRegression for Validation 1\n",
      "105 - WindowRegression with avg smape 14.19: \n",
      "Model Number: 106 of 133 with model WindowRegression for Validation 1\n",
      "106 - WindowRegression with avg smape 13.99: \n",
      "Model Number: 107 of 133 with model DatepartRegression for Validation 1\n",
      "107 - DatepartRegression with avg smape 13.33: \n",
      "Model Number: 108 of 133 with model WindowRegression for Validation 1\n",
      "108 - WindowRegression with avg smape 13.3: \n",
      "Model Number: 109 of 133 with model DatepartRegression for Validation 1\n",
      "109 - DatepartRegression with avg smape 12.49: \n",
      "Model Number: 110 of 133 with model WindowRegression for Validation 1\n",
      "110 - WindowRegression with avg smape 13.36: \n",
      "Model Number: 111 of 133 with model GLM for Validation 1\n",
      "111 - GLM with avg smape 6.25: \n",
      "Model Number: 112 of 133 with model ETS for Validation 1\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
      "112 - ETS with avg smape 11.73: \n",
      "Model Number: 113 of 133 with model ETS for Validation 1\n",
      "113 - ETS with avg smape 10.86: \n",
      "Model Number: 114 of 133 with model ETS for Validation 1\n",
      "114 - ETS with avg smape 10.87: \n",
      "Model Number: 115 of 133 with model ETS for Validation 1\n",
      "115 - ETS with avg smape 10.85: \n",
      "Model Number: 116 of 133 with model UnobservedComponents for Validation 1\n",
      "116 - UnobservedComponents with avg smape 11.81: \n",
      "Model Number: 117 of 133 with model WindowRegression for Validation 1\n",
      "117 - WindowRegression with avg smape 10.93: \n",
      "Model Number: 118 of 133 with model UnobservedComponents for Validation 1\n",
      "118 - UnobservedComponents with avg smape 18.82: \n",
      "Model Number: 119 of 133 with model UnobservedComponents for Validation 1\n",
      "119 - UnobservedComponents with avg smape 10.68: \n",
      "Model Number: 120 of 133 with model UnobservedComponents for Validation 1\n",
      "120 - UnobservedComponents with avg smape 12.13: \n",
      "Model Number: 121 of 133 with model WindowRegression for Validation 1\n",
      "121 - WindowRegression with avg smape 18.23: \n",
      "Model Number: 122 of 133 with model WindowRegression for Validation 1\n",
      "122 - WindowRegression with avg smape 13.11: \n",
      "Model Number: 123 of 133 with model UnobservedComponents for Validation 1\n",
      "123 - UnobservedComponents with avg smape 13.25: \n",
      "Model Number: 124 of 133 with model DatepartRegression for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done 178 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 - DatepartRegression with avg smape 7.75: \n",
      "Model Number: 125 of 133 with model GLS for Validation 1\n",
      "125 - GLS with avg smape 13.24: \n",
      "Model Number: 126 of 133 with model GLS for Validation 1\n",
      "126 - GLS with avg smape 13.24: \n",
      "Model Number: 127 of 133 with model GLS for Validation 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=11)]: Using backend ThreadingBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=11)]: Done 178 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=11)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 - GLS with avg smape 13.24: \n",
      "Model Number: 128 of 133 with model GLS for Validation 1\n",
      "128 - GLS with avg smape 13.24: \n",
      "Model Number: 129 of 133 with model UnobservedComponents for Validation 1\n",
      "129 - UnobservedComponents with avg smape 10.8: \n",
      "Model Number: 130 of 133 with model WindowRegression for Validation 1\n",
      "130 - WindowRegression with avg smape 15.16: \n",
      "Model Number: 131 of 133 with model UnobservedComponents for Validation 1\n",
      "131 - UnobservedComponents with avg smape 11.73: \n",
      "Model Number: 132 of 133 with model GLS for Validation 1\n",
      "132 - GLS with avg smape 18.36: \n",
      "Model Number: 133 of 133 with model UnobservedComponents for Validation 1\n",
      "133 - UnobservedComponents with avg smape 3.4: \n",
      "Validation Round: 2\n",
      "Model Number: 1 of 133 with model Ensemble for Validation 2\n",
      "1 - Ensemble with avg smape 4.64: \n",
      "Model Number: 2 of 133 with model Ensemble for Validation 2\n",
      "2 - Ensemble with avg smape 4.94: \n",
      "Model Number: 3 of 133 with model Ensemble for Validation 2\n",
      "3 - Ensemble with avg smape 6.24: \n",
      "Model Number: 4 of 133 with model Ensemble for Validation 2\n",
      "4 - Ensemble with avg smape 6.38: \n",
      "Model Number: 5 of 133 with model Theta for Validation 2\n",
      "5 - Theta with avg smape 5.02: \n",
      "Model Number: 6 of 133 with model Theta for Validation 2\n",
      "6 - Theta with avg smape 4.97: \n",
      "Model Number: 7 of 133 with model Ensemble for Validation 2\n",
      "7 - Ensemble with avg smape 4.95: \n",
      "Model Number: 8 of 133 with model Theta for Validation 2\n",
      "8 - Theta with avg smape 4.87: \n",
      "Model Number: 9 of 133 with model Ensemble for Validation 2\n",
      "9 - Ensemble with avg smape 4.86: \n",
      "Model Number: 10 of 133 with model Theta for Validation 2\n",
      "10 - Theta with avg smape 4.85: \n",
      "Model Number: 11 of 133 with model Theta for Validation 2\n",
      "11 - Theta with avg smape 4.86: \n",
      "Model Number: 12 of 133 with model Theta for Validation 2\n",
      "12 - Theta with avg smape 4.87: \n",
      "Model Number: 13 of 133 with model Ensemble for Validation 2\n",
      "13 - Ensemble with avg smape 5.27: \n",
      "Model Number: 14 of 133 with model UnivariateMotif for Validation 2\n",
      "14 - UnivariateMotif with avg smape 5.03: \n",
      "Model Number: 15 of 133 with model NVAR for Validation 2\n",
      "15 - NVAR with avg smape 4.85: \n",
      "Model Number: 16 of 133 with model NVAR for Validation 2\n",
      "16 - NVAR with avg smape 4.78: \n",
      "Model Number: 17 of 133 with model NVAR for Validation 2\n",
      "17 - NVAR with avg smape 5.11: \n",
      "Model Number: 18 of 133 with model SectionalMotif for Validation 2\n",
      "18 - SectionalMotif with avg smape 13.39: \n",
      "Model Number: 19 of 133 with model UnivariateMotif for Validation 2\n",
      "19 - UnivariateMotif with avg smape 5.2: \n",
      "Model Number: 20 of 133 with model UnivariateMotif for Validation 2\n",
      "20 - UnivariateMotif with avg smape 4.98: \n",
      "Model Number: 21 of 133 with model UnivariateMotif for Validation 2\n",
      "21 - UnivariateMotif with avg smape 4.72: \n",
      "Model Number: 22 of 133 with model SectionalMotif for Validation 2\n",
      "22 - SectionalMotif with avg smape 7.49: \n",
      "Model Number: 23 of 133 with model AverageValueNaive for Validation 2\n",
      "23 - AverageValueNaive with avg smape 5.03: \n",
      "Model Number: 24 of 133 with model AverageValueNaive for Validation 2\n",
      "24 - AverageValueNaive with avg smape 5.03: \n",
      "Model Number: 25 of 133 with model Theta for Validation 2\n",
      "25 - Theta with avg smape 5.07: \n",
      "Model Number: 26 of 133 with model UnivariateMotif for Validation 2\n",
      "26 - UnivariateMotif with avg smape 5.35: \n",
      "Model Number: 27 of 133 with model AverageValueNaive for Validation 2\n",
      "27 - AverageValueNaive with avg smape 4.74: \n",
      "Model Number: 28 of 133 with model AverageValueNaive for Validation 2\n",
      "28 - AverageValueNaive with avg smape 5.04: \n",
      "Model Number: 29 of 133 with model SeasonalNaive for Validation 2\n",
      "29 - SeasonalNaive with avg smape 4.89: \n",
      "Model Number: 30 of 133 with model AverageValueNaive for Validation 2\n",
      "30 - AverageValueNaive with avg smape 4.83: \n",
      "Model Number: 31 of 133 with model AverageValueNaive for Validation 2\n",
      "31 - AverageValueNaive with avg smape 4.8: \n",
      "Model Number: 32 of 133 with model UnivariateMotif for Validation 2\n",
      "32 - UnivariateMotif with avg smape 6.68: \n",
      "Model Number: 33 of 133 with model AverageValueNaive for Validation 2\n",
      "33 - AverageValueNaive with avg smape 4.78: \n",
      "Model Number: 34 of 133 with model AverageValueNaive for Validation 2\n",
      "34 - AverageValueNaive with avg smape 4.78: \n",
      "Model Number: 35 of 133 with model GLM for Validation 2\n",
      "35 - GLM with avg smape 4.8: \n",
      "Model Number: 36 of 133 with model GLM for Validation 2\n",
      "36 - GLM with avg smape 4.8: \n",
      "Model Number: 37 of 133 with model ZeroesNaive for Validation 2\n",
      "37 - ZeroesNaive with avg smape 4.99: \n",
      "Model Number: 38 of 133 with model Theta for Validation 2\n",
      "38 - Theta with avg smape 6.54: \n",
      "Model Number: 39 of 133 with model SeasonalNaive for Validation 2\n",
      "39 - SeasonalNaive with avg smape 4.8: \n",
      "Model Number: 40 of 133 with model SectionalMotif for Validation 2\n",
      "40 - SectionalMotif with avg smape 4.93: \n",
      "Model Number: 41 of 133 with model GLM for Validation 2\n",
      "41 - GLM with avg smape 5.34: \n",
      "Model Number: 42 of 133 with model GLM for Validation 2\n",
      "42 - GLM with avg smape 5.34: \n",
      "Model Number: 43 of 133 with model UnivariateMotif for Validation 2\n",
      "43 - UnivariateMotif with avg smape 5.0: \n",
      "Model Number: 44 of 133 with model UnivariateMotif for Validation 2\n",
      "44 - UnivariateMotif with avg smape 4.15: \n",
      "Model Number: 45 of 133 with model SectionalMotif for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\statsmodels\\genmod\\families\\links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 - SectionalMotif with avg smape 9.97: \n",
      "Model Number: 46 of 133 with model MultivariateRegression for Validation 2\n",
      "46 - MultivariateRegression with avg smape 4.38: \n",
      "Model Number: 47 of 133 with model GLM for Validation 2\n",
      "47 - GLM with avg smape 5.56: \n",
      "Model Number: 48 of 133 with model MultivariateMotif for Validation 2\n",
      "48 - MultivariateMotif with avg smape 6.64: \n",
      "Model Number: 49 of 133 with model SectionalMotif for Validation 2\n",
      "49 - SectionalMotif with avg smape 4.67: \n",
      "Model Number: 50 of 133 with model SeasonalNaive for Validation 2\n",
      "50 - SeasonalNaive with avg smape 5.94: \n",
      "Model Number: 51 of 133 with model ZeroesNaive for Validation 2\n",
      "51 - ZeroesNaive with avg smape 5.34: \n",
      "Model Number: 52 of 133 with model NVAR for Validation 2\n",
      "52 - NVAR with avg smape 5.38: \n",
      "Model Number: 53 of 133 with model NVAR for Validation 2\n",
      "53 - NVAR with avg smape 4.89: \n",
      "Model Number: 54 of 133 with model SectionalMotif for Validation 2\n",
      "54 - SectionalMotif with avg smape 5.0: \n",
      "Model Number: 55 of 133 with model MultivariateMotif for Validation 2\n",
      "55 - MultivariateMotif with avg smape 20.1: \n",
      "Model Number: 56 of 133 with model NVAR for Validation 2\n",
      "56 - NVAR with avg smape 5.57: \n",
      "Model Number: 57 of 133 with model NVAR for Validation 2\n",
      "57 - NVAR with avg smape 5.57: \n",
      "Model Number: 58 of 133 with model NVAR for Validation 2\n",
      "58 - NVAR with avg smape 5.57: \n",
      "Model Number: 59 of 133 with model SeasonalNaive for Validation 2\n",
      "59 - SeasonalNaive with avg smape 5.8: \n",
      "Model Number: 60 of 133 with model MultivariateMotif for Validation 2\n",
      "60 - MultivariateMotif with avg smape 10.58: \n",
      "Model Number: 61 of 133 with model SectionalMotif for Validation 2\n",
      "61 - SectionalMotif with avg smape 4.76: \n",
      "Model Number: 62 of 133 with model SectionalMotif for Validation 2\n",
      "62 - SectionalMotif with avg smape 4.58: \n",
      "Model Number: 63 of 133 with model DatepartRegression for Validation 2\n",
      "63 - DatepartRegression with avg smape 5.05: \n",
      "Model Number: 64 of 133 with model GLM for Validation 2\n",
      "64 - GLM with avg smape 5.06: \n",
      "Model Number: 65 of 133 with model MultivariateMotif for Validation 2\n",
      "65 - MultivariateMotif with avg smape 8.55: \n",
      "Model Number: 66 of 133 with model MultivariateRegression for Validation 2\n",
      "[LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear][LibLinear]66 - MultivariateRegression with avg smape 5.38: \n",
      "Model Number: 67 of 133 with model MultivariateMotif for Validation 2"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "C:\\Users\\zachg\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "67 - MultivariateMotif with avg smape 10.49: \n",
      "Model Number: 68 of 133 with model MultivariateRegression for Validation 2\n",
      "68 - MultivariateRegression with avg smape 7.75: \n",
      "Model Number: 69 of 133 with model MultivariateMotif for Validation 2\n",
      "69 - MultivariateMotif with avg smape 12.69: \n",
      "Model Number: 70 of 133 with model DatepartRegression for Validation 2\n",
      "70 - DatepartRegression with avg smape 7.95: \n",
      "Model Number: 71 of 133 with model ZeroesNaive for Validation 2\n",
      "71 - ZeroesNaive with avg smape 5.34: \n",
      "Model Number: 72 of 133 with model MultivariateMotif for Validation 2\n",
      "72 - MultivariateMotif with avg smape 10.87: \n",
      "Model Number: 73 of 133 with model MultivariateMotif for Validation 2\n",
      "73 - MultivariateMotif with avg smape 6.49: \n",
      "Model Number: 74 of 133 with model ZeroesNaive for Validation 2\n",
      "74 - ZeroesNaive with avg smape 5.74: \n",
      "Model Number: 75 of 133 with model ZeroesNaive for Validation 2\n",
      "75 - ZeroesNaive with avg smape 5.74: \n",
      "Model Number: 76 of 133 with model MultivariateRegression for Validation 2\n",
      "76 - MultivariateRegression with avg smape 9.76: \n",
      "Model Number: 77 of 133 with model MultivariateRegression for Validation 2\n",
      "77 - MultivariateRegression with avg smape 9.76: \n",
      "Model Number: 78 of 133 with model SeasonalNaive for Validation 2\n",
      "78 - SeasonalNaive with avg smape 6.76: \n",
      "Model Number: 79 of 133 with model SeasonalNaive for Validation 2\n",
      "79 - SeasonalNaive with avg smape 6.82: \n",
      "Model Number: 80 of 133 with model LastValueNaive for Validation 2\n",
      "80 - LastValueNaive with avg smape 5.21: \n",
      "Model Number: 81 of 133 with model ZeroesNaive for Validation 2\n",
      "81 - ZeroesNaive with avg smape 5.55: \n",
      "Model Number: 82 of 133 with model MultivariateRegression for Validation 2\n",
      "82 - MultivariateRegression with avg smape 6.84: \n",
      "Model Number: 83 of 133 with model MultivariateRegression for Validation 2\n",
      "83 - MultivariateRegression with avg smape 5.78: \n",
      "Model Number: 84 of 133 with model ZeroesNaive for Validation 2\n",
      "84 - ZeroesNaive with avg smape 6.53: \n",
      "Model Number: 85 of 133 with model ZeroesNaive for Validation 2\n",
      "85 - ZeroesNaive with avg smape 6.53: \n",
      "Model Number: 86 of 133 with model MultivariateRegression for Validation 2\n",
      "86 - MultivariateRegression with avg smape 7.27: \n",
      "Model Number: 87 of 133 with model GLM for Validation 2\n",
      "87 - GLM with avg smape 6.08: \n",
      "Model Number: 88 of 133 with model LastValueNaive for Validation 2\n",
      "88 - LastValueNaive with avg smape 5.09: \n",
      "Model Number: 89 of 133 with model SeasonalNaive for Validation 2\n",
      "89 - SeasonalNaive with avg smape 9.85: \n",
      "Model Number: 90 of 133 with model GLS for Validation 2\n",
      "90 - GLS with avg smape 5.33: \n",
      "Model Number: 91 of 133 with model GLS for Validation 2\n",
      "91 - GLS with avg smape 5.73: \n",
      "Model Number: 92 of 133 with model Ensemble for Validation 2\n",
      "92 - Ensemble with avg smape 5.16: \n",
      "Model Number: 93 of 133 with model LastValueNaive for Validation 2\n",
      "93 - LastValueNaive with avg smape 4.1: \n",
      "Model Number: 94 of 133 with model LastValueNaive for Validation 2\n",
      "94 - LastValueNaive with avg smape 3.84: \n",
      "Model Number: 95 of 133 with model LastValueNaive for Validation 2\n",
      "95 - LastValueNaive with avg smape 4.33: \n",
      "Model Number: 96 of 133 with model LastValueNaive for Validation 2\n",
      "96 - LastValueNaive with avg smape 4.33: \n",
      "Model Number: 97 of 133 with model LastValueNaive for Validation 2\n",
      "97 - LastValueNaive with avg smape 4.33: \n",
      "Model Number: 98 of 133 with model LastValueNaive for Validation 2\n",
      "98 - LastValueNaive with avg smape 4.33: \n",
      "Model Number: 99 of 133 with model SeasonalNaive for Validation 2\n",
      "99 - SeasonalNaive with avg smape 7.68: \n",
      "Model Number: 100 of 133 with model ETS for Validation 2\n",
      "100 - ETS with avg smape 7.26: \n",
      "Model Number: 101 of 133 with model ETS for Validation 2\n",
      "101 - ETS with avg smape 7.26: \n",
      "Model Number: 102 of 133 with model ETS for Validation 2\n",
      "102 - ETS with avg smape 7.07: \n",
      "Model Number: 103 of 133 with model ETS for Validation 2\n",
      "103 - ETS with avg smape 6.52: \n",
      "Model Number: 104 of 133 with model GLS for Validation 2\n",
      "104 - GLS with avg smape 5.14: \n",
      "Model Number: 105 of 133 with model WindowRegression for Validation 2\n",
      "105 - WindowRegression with avg smape 4.35: \n",
      "Model Number: 106 of 133 with model WindowRegression for Validation 2\n",
      "106 - WindowRegression with avg smape 6.37: \n",
      "Model Number: 107 of 133 with model DatepartRegression for Validation 2\n",
      "107 - DatepartRegression with avg smape 5.04: \n",
      "Model Number: 108 of 133 with model WindowRegression for Validation 2\n",
      "108 - WindowRegression with avg smape 5.15: \n",
      "Model Number: 109 of 133 with model DatepartRegression for Validation 2\n",
      "109 - DatepartRegression with avg smape 4.64: \n",
      "Model Number: 110 of 133 with model WindowRegression for Validation 2\n",
      "110 - WindowRegression with avg smape 5.1: \n",
      "Model Number: 111 of 133 with model GLM for Validation 2\n",
      "111 - GLM with avg smape 4.31: \n",
      "Model Number: 112 of 133 with model ETS for Validation 2\n",
      "ETS error ValueError('Can only dampen the trend component')\n",
      "ETS failed on Close with ValueError('Can only dampen the trend component')\n",
      "112 - ETS with avg smape 6.35: \n",
      "Model Number: 113 of 133 with model ETS for Validation 2\n",
      "113 - ETS with avg smape 5.31: \n",
      "Model Number: 114 of 133 with model ETS for Validation 2\n",
      "114 - ETS with avg smape 5.32: \n",
      "Model Number: 115 of 133 with model ETS for Validation 2\n",
      "115 - ETS with avg smape 5.31: \n",
      "Model Number: 116 of 133 with model UnobservedComponents for Validation 2\n",
      "116 - UnobservedComponents with avg smape 4.91: \n",
      "Model Number: 117 of 133 with model WindowRegression for Validation 2\n",
      "117 - WindowRegression with avg smape 4.91: \n",
      "Model Number: 118 of 133 with model UnobservedComponents for Validation 2\n",
      "118 - UnobservedComponents with avg smape 5.38: \n",
      "Model Number: 119 of 133 with model UnobservedComponents for Validation 2\n",
      "119 - UnobservedComponents with avg smape 5.09: \n",
      "Model Number: 120 of 133 with model UnobservedComponents for Validation 2\n",
      "120 - UnobservedComponents with avg smape 4.76: \n",
      "Model Number: 121 of 133 with model WindowRegression for Validation 2\n",
      "121 - WindowRegression with avg smape 5.27: \n",
      "Model Number: 122 of 133 with model WindowRegression for Validation 2\n",
      "122 - WindowRegression with avg smape 5.65: \n",
      "Model Number: 123 of 133 with model UnobservedComponents for Validation 2\n",
      "123 - UnobservedComponents with avg smape 5.31: \n",
      "Model Number: 124 of 133 with model DatepartRegression for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend ThreadingBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-2)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=-2)]: Done 178 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124 - DatepartRegression with avg smape 9.92: \n",
      "Model Number: 125 of 133 with model GLS for Validation 2\n",
      "125 - GLS with avg smape 5.32: \n",
      "Model Number: 126 of 133 with model GLS for Validation 2\n",
      "126 - GLS with avg smape 5.32: \n",
      "Model Number: 127 of 133 with model GLS for Validation 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done 300 out of 300 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=11)]: Using backend ThreadingBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=11)]: Done  28 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=11)]: Done 178 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=11)]: Done 300 out of 300 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 - GLS with avg smape 5.32: \n",
      "Model Number: 128 of 133 with model GLS for Validation 2\n",
      "128 - GLS with avg smape 5.32: \n",
      "Model Number: 129 of 133 with model UnobservedComponents for Validation 2\n",
      "129 - UnobservedComponents with avg smape 5.9: \n",
      "Model Number: 130 of 133 with model WindowRegression for Validation 2\n",
      "130 - WindowRegression with avg smape 4.48: \n",
      "Model Number: 131 of 133 with model UnobservedComponents for Validation 2\n",
      "131 - UnobservedComponents with avg smape 6.35: \n",
      "Model Number: 132 of 133 with model GLS for Validation 2\n",
      "132 - GLS with avg smape 5.63: \n",
      "Model Number: 133 of 133 with model UnobservedComponents for Validation 2\n",
      "133 - UnobservedComponents with avg smape 11.23: \n",
      "Bitcoin Price Prediction\n",
      "                   Close\n",
      "2021-07-07  34405.248662\n",
      "2021-07-08  34794.301302\n",
      "2021-07-09  35276.827200\n",
      "2021-07-10  35848.925852\n",
      "2021-07-11  36505.014698\n",
      "2021-07-12  37238.229376\n",
      "2021-07-13  38041.136356\n",
      "2021-07-14  38903.870180\n",
      "2021-07-15  39813.701463\n",
      "2021-07-16  40757.946341\n"
     ]
    }
   ],
   "source": [
    "from autots import AutoTS\n",
    "\n",
    "# Set forecast length for amount of time you want to predict future value.\n",
    "# Compare predicted Bitcoin for real data elsewhere.\n",
    "model = AutoTS(forecast_length=10, frequency='infer', ensemble='simple')\n",
    "model = model.fit(bitcoin2020_df, date_col='Date', value_col='Close', id_col=None)\n",
    " \n",
    "prediction = model.predict()\n",
    "forecast = prediction.forecast\n",
    "print(\"Bitcoin Price Prediction\")\n",
    "print(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b34013c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_df_two = pd.read_csv(\"./Resources/BTC-USD.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ccf14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-17</td>\n",
       "      <td>465.864014</td>\n",
       "      <td>468.174011</td>\n",
       "      <td>452.421997</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>457.334015</td>\n",
       "      <td>21056800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-09-18</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>456.859985</td>\n",
       "      <td>413.104004</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>424.440002</td>\n",
       "      <td>34483200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-09-19</td>\n",
       "      <td>424.102997</td>\n",
       "      <td>427.834991</td>\n",
       "      <td>384.532013</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>394.795990</td>\n",
       "      <td>37919700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-09-20</td>\n",
       "      <td>394.673004</td>\n",
       "      <td>423.295990</td>\n",
       "      <td>389.882996</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>408.903992</td>\n",
       "      <td>36863600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-09-21</td>\n",
       "      <td>408.084991</td>\n",
       "      <td>412.425995</td>\n",
       "      <td>393.181000</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>398.821014</td>\n",
       "      <td>26580100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>2022-02-12</td>\n",
       "      <td>42412.300781</td>\n",
       "      <td>42992.550781</td>\n",
       "      <td>41852.574219</td>\n",
       "      <td>42244.468750</td>\n",
       "      <td>42244.468750</td>\n",
       "      <td>18152390304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>2022-02-13</td>\n",
       "      <td>42236.566406</td>\n",
       "      <td>42693.054688</td>\n",
       "      <td>41950.941406</td>\n",
       "      <td>42197.515625</td>\n",
       "      <td>42197.515625</td>\n",
       "      <td>14741589015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>2022-02-14</td>\n",
       "      <td>42157.398438</td>\n",
       "      <td>42775.777344</td>\n",
       "      <td>41681.957031</td>\n",
       "      <td>42586.917969</td>\n",
       "      <td>42586.917969</td>\n",
       "      <td>20827783012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>2022-02-15</td>\n",
       "      <td>42586.464844</td>\n",
       "      <td>44667.218750</td>\n",
       "      <td>42491.035156</td>\n",
       "      <td>44575.203125</td>\n",
       "      <td>44575.203125</td>\n",
       "      <td>22721659051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2709</th>\n",
       "      <td>2022-02-16</td>\n",
       "      <td>44503.093750</td>\n",
       "      <td>44503.093750</td>\n",
       "      <td>43475.257813</td>\n",
       "      <td>43734.277344</td>\n",
       "      <td>43734.277344</td>\n",
       "      <td>18829363200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2710 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date          Open          High           Low         Close  \\\n",
       "0     2014-09-17    465.864014    468.174011    452.421997    457.334015   \n",
       "1     2014-09-18    456.859985    456.859985    413.104004    424.440002   \n",
       "2     2014-09-19    424.102997    427.834991    384.532013    394.795990   \n",
       "3     2014-09-20    394.673004    423.295990    389.882996    408.903992   \n",
       "4     2014-09-21    408.084991    412.425995    393.181000    398.821014   \n",
       "...          ...           ...           ...           ...           ...   \n",
       "2705  2022-02-12  42412.300781  42992.550781  41852.574219  42244.468750   \n",
       "2706  2022-02-13  42236.566406  42693.054688  41950.941406  42197.515625   \n",
       "2707  2022-02-14  42157.398438  42775.777344  41681.957031  42586.917969   \n",
       "2708  2022-02-15  42586.464844  44667.218750  42491.035156  44575.203125   \n",
       "2709  2022-02-16  44503.093750  44503.093750  43475.257813  43734.277344   \n",
       "\n",
       "         Adj Close       Volume  \n",
       "0       457.334015     21056800  \n",
       "1       424.440002     34483200  \n",
       "2       394.795990     37919700  \n",
       "3       408.903992     36863600  \n",
       "4       398.821014     26580100  \n",
       "...            ...          ...  \n",
       "2705  42244.468750  18152390304  \n",
       "2706  42197.515625  14741589015  \n",
       "2707  42586.917969  20827783012  \n",
       "2708  44575.203125  22721659051  \n",
       "2709  43734.277344  18829363200  \n",
       "\n",
       "[2710 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_df_two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a57bdc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31796.810547"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_df_two.loc[2496,'Close']\n",
    "# 2496 is row name for last date we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07bb2ce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "accurate_results = [33798,33520,34240,33155,32702,32822,31780,31421,31533,31796]\n",
    "prediction_results = [34405,34794,35276,35848,36505,37238,38041,38903,39813,40757]\n",
    "\n",
    "# Plot a simple line chart\n",
    "plt.plot(x, accurate_results, color='green', label='Accurate Results')\n",
    "\n",
    "# Plot another line on the same chart/graph\n",
    "plt.plot(x, prediction_results, color='red', label='Predicted Results')\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e13d154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
